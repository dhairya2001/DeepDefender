{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IsYR7yxzZS4F",
    "outputId": "e8de7a98-ca0e-49dd-e1aa-a6aa8249afbc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import timm\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "DATASET_PATH = \"FF++/\"\n",
    "REAL_PATH = os.path.join(DATASET_PATH, \"real\")\n",
    "FAKE_PATH = os.path.join(DATASET_PATH, \"fake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q6n2KQDoBfhQ",
    "outputId": "c4f125b5-b93a-426e-bc67-af765ef9bdf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "LapMrQvPvXRF"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'real_dir': 'FF++/real',\n",
    "    'fake_dir': 'FF++/fake',\n",
    "    'output_dir': 'output/',\n",
    "    'eval_dir' : 'FF++/eval_videos/',\n",
    "    'sample_rate': 1,\n",
    "    'max_frames': 5000,\n",
    "    'resize_width': 224,\n",
    "    'resize_height': 224,\n",
    "    'limit': None,\n",
    "    'batch_size': 1024,\n",
    "    'feature_dim': 20,\n",
    "    'hidden_dims': [512, 256, 128, 128, 64],\n",
    "    'dropout_rate': 0.5,\n",
    "    'learning_rate': 0.001,\n",
    "    'weight_decay': 1e-5,\n",
    "    'mixed_precision': True,\n",
    "    'grad_accum_steps': 4,\n",
    "    'num_epochs': 1000,\n",
    "    'patience': 500,\n",
    "    'val_split': 0.5,\n",
    "    'test_split': 0.1\n",
    "}\n",
    "\n",
    "os.makedirs(config['output_dir'], exist_ok=True)\n",
    "features_dir = os.path.join(config['output_dir'], 'features')\n",
    "models_dir = os.path.join(config['output_dir'], 'models')\n",
    "os.makedirs(features_dir, exist_ok=True)\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "deep_dir = os.path.join(config['output_dir'], 'models/deep')\n",
    "os.makedirs(deep_dir, exist_ok=True)\n",
    "\n",
    "vit_dir = os.path.join(config['output_dir'], 'models/vit')\n",
    "os.makedirs(vit_dir, exist_ok=True)\n",
    "\n",
    "fine_tuned_vit_dir = os.path.join(config['output_dir'], 'models/fine_tuned_vit')\n",
    "os.makedirs(fine_tuned_vit_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "6Jr9_pVkp88M"
   },
   "outputs": [],
   "source": [
    "def adaptive_sampling(video_path, sample_rate=3, max_frames=50, resize_shape=(320, 240)):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    duration = total_frames / fps\n",
    "\n",
    "    if duration < 5:\n",
    "        sample_rate = max(1, sample_rate // 2)\n",
    "    else:\n",
    "        sample_rate = sample_rate\n",
    "\n",
    "    motion_samples = []\n",
    "    prev_frame = None\n",
    "\n",
    "    sample_points = np.linspace(0, total_frames-1, 10, dtype=int)\n",
    "    for frame_idx in sample_points:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        frame = cv2.resize(frame, resize_shape)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        if prev_frame is not None:\n",
    "            diff = cv2.absdiff(frame, prev_frame)\n",
    "            motion_samples.append(np.mean(diff))\n",
    "\n",
    "        prev_frame = frame\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if motion_samples:\n",
    "        avg_motion = np.mean(motion_samples)\n",
    "        if avg_motion > 30:\n",
    "            sample_rate = max(1, sample_rate - 1)\n",
    "        elif avg_motion < 10:\n",
    "            sample_rate = sample_rate + 1\n",
    "\n",
    "    return min(sample_rate, total_frames // max_frames + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "rktJJ9hrqKBq"
   },
   "outputs": [],
   "source": [
    "def extract_frames(video_path, sample_rate=3, max_frames=50, resize_shape=(320, 240)):\n",
    "    sample_rate = adaptive_sampling(video_path, sample_rate, max_frames, resize_shape)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video file {video_path}\")\n",
    "        return []\n",
    "\n",
    "    frames = []\n",
    "    frame_idx = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_idx % sample_rate == 0:\n",
    "            frame = cv2.resize(frame, resize_shape)\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            frames.append(gray)\n",
    "            if len(frames) >= max_frames:\n",
    "                break\n",
    "\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "KHj6xQWqtFj-"
   },
   "outputs": [],
   "source": [
    "def compute_optical_flow(frames):\n",
    "    if len(frames) < 2:\n",
    "        return []\n",
    "\n",
    "    flows = []\n",
    "\n",
    "    for i in range(len(frames) - 1):\n",
    "        flow = cv2.calcOpticalFlowFarneback(\n",
    "            frames[i], frames[i + 1],\n",
    "            None, 0.5, 3, 15, 3, 5, 1.2, 0\n",
    "        )\n",
    "        flows.append(flow)\n",
    "\n",
    "    return flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "QFRnVazStVIs"
   },
   "outputs": [],
   "source": [
    "def extract_flow_features(flows):\n",
    "    if not flows:\n",
    "        return None\n",
    "\n",
    "    features = {\n",
    "        'mag_mean': [],\n",
    "        'mag_std': [],\n",
    "        'mag_max': [],\n",
    "        'dir_std': [],\n",
    "        'spatial_coherence': [],\n",
    "        'temporal_consistency': []\n",
    "    }\n",
    "\n",
    "    prev_mag = None\n",
    "\n",
    "    for i, flow in enumerate(flows):\n",
    "        mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "\n",
    "        features['mag_mean'].append(np.mean(mag))\n",
    "        features['mag_std'].append(np.std(mag))\n",
    "        features['mag_max'].append(np.max(mag))\n",
    "\n",
    "        features['dir_std'].append(np.std(ang))\n",
    "        mag_grad_x = cv2.Sobel(mag, cv2.CV_32F, 1, 0, ksize=3)\n",
    "        mag_grad_y = cv2.Sobel(mag, cv2.CV_32F, 0, 1, ksize=3)\n",
    "        spatial_coherence = 1.0 / (1.0 + np.mean(mag_grad_x**2 + mag_grad_y**2))\n",
    "        features['spatial_coherence'].append(spatial_coherence)\n",
    "        if prev_mag is not None:\n",
    "            temp_diff = np.mean(np.abs(mag - prev_mag))\n",
    "            temp_consistency = 1.0 / (1.0 + temp_diff)\n",
    "            features['temporal_consistency'].append(temp_consistency)\n",
    "\n",
    "        prev_mag = mag.copy()\n",
    "\n",
    "    if len(features['temporal_consistency']) < len(flows) - 1:\n",
    "        features['temporal_consistency'].append(features['temporal_consistency'][-1] if features['temporal_consistency'] else 0)\n",
    "    if flows:\n",
    "        for key in ['mag_mean', 'mag_std', 'mag_max']:\n",
    "            values = np.array(features[key])\n",
    "            if len(values) > 0:\n",
    "                features[f'{key}_trend'] = np.polyfit(np.arange(len(values)), values, 1)[0] if len(values) > 1 else 0\n",
    "                features[f'{key}_var'] = np.var(values) if len(values) > 1 else 0\n",
    "\n",
    "        all_mags = np.concatenate([flow_field.reshape(-1, 2) for flow_field in flows], axis=0)\n",
    "        hist, _ = np.histogramdd(all_mags, bins=10, range=[[-20, 20], [-20, 20]])\n",
    "        hist = hist / np.sum(hist)\n",
    "        hist = hist[hist > 0]\n",
    "        features['flow_entropy'] = -np.sum(hist * np.log2(hist))\n",
    "\n",
    "    for key in list(features.keys()):\n",
    "        if isinstance(features[key], list):\n",
    "            features[key] = np.mean(features[key]) if features[key] else 0\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "FuOEaAJ4tphR"
   },
   "outputs": [],
   "source": [
    "def process_video(video_path, sample_rate=3, max_frames=50, resize_shape=(320, 240)):\n",
    "    frames = extract_frames(video_path, sample_rate, max_frames, resize_shape)\n",
    "    if not frames:\n",
    "        return None\n",
    "\n",
    "    flows = compute_optical_flow(frames)\n",
    "    return extract_flow_features(flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "dPP8D4rjtynF"
   },
   "outputs": [],
   "source": [
    "def process_videos(video_dir, label, output_dir, sample_rate=3, max_frames=50,\n",
    "                   resize_width=320, resize_height=240, limit=None):\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    video_paths = list(Path(video_dir).glob('**/*.mp4'))\n",
    "    video_paths.extend(list(Path(video_dir).glob('**/*.avi')))\n",
    "    video_paths.extend(list(Path(video_dir).glob('**/*.mov')))\n",
    "\n",
    "    if limit:\n",
    "        video_paths = video_paths[:limit]\n",
    "\n",
    "    features_list = []\n",
    "    labels = []\n",
    "    filenames = []\n",
    "\n",
    "    resize_shape = (resize_width, resize_height)\n",
    "\n",
    "    for video_path in tqdm(video_paths, desc=f\"Processing {label} videos\"):\n",
    "        try:\n",
    "            features = process_video(str(video_path), sample_rate, max_frames, resize_shape)\n",
    "            if features:\n",
    "                features_list.append(features)\n",
    "                labels.append(label)\n",
    "                filenames.append(video_path.name)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {video_path}: {e}\")\n",
    "\n",
    "    features_array = []\n",
    "    feature_names = []\n",
    "\n",
    "    if features_list:\n",
    "        feature_names = list(features_list[0].keys())\n",
    "        features_array = np.zeros((len(features_list), len(feature_names)))\n",
    "        for i, features in enumerate(features_list):\n",
    "            for j, name in enumerate(feature_names):\n",
    "                features_array[i, j] = features[name]\n",
    "\n",
    "    output_path = os.path.join(output_dir, f\"{label}_features.npz\")\n",
    "    np.savez(\n",
    "        output_path,\n",
    "        features=features_array,\n",
    "        labels=np.array(labels),\n",
    "        filenames=filenames,\n",
    "        feature_names=feature_names\n",
    "    )\n",
    "\n",
    "    print(f\"Saved {len(features_list)} {label} video features to {output_path}\")\n",
    "\n",
    "    return features_array, np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "LbQ4OV8qCIyA"
   },
   "outputs": [],
   "source": [
    "class FlowFeatureDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "def load_features(data_dir):\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if filename.endswith('_features.npz'):\n",
    "            data = np.load(os.path.join(data_dir, filename), allow_pickle=True)\n",
    "            features = data['features']\n",
    "            labels = data['labels']\n",
    "\n",
    "            if len(features) > 0:\n",
    "                features_list.append(features)\n",
    "                labels_list.append(labels)\n",
    "\n",
    "    if not features_list:\n",
    "        return None, None\n",
    "    features = np.vstack(features_list)\n",
    "    labels = np.concatenate(labels_list)\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "def prepare_dataloaders(data_dir, batch_size=32, val_split=0.2, test_split=0.1, random_state=42):\n",
    "    features, labels = load_features(data_dir)\n",
    "\n",
    "    if features is None:\n",
    "        return None, None, None, None\n",
    "\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "        features, labels, test_size=test_split, random_state=random_state, stratify=labels\n",
    "    )\n",
    "\n",
    "    train_features, val_features, train_labels, val_labels = train_test_split(\n",
    "        train_features, train_labels,\n",
    "        test_size=val_split / (1 - test_split),\n",
    "        random_state=random_state,\n",
    "        stratify=train_labels\n",
    "    )\n",
    "    scaler = StandardScaler()\n",
    "    train_features = scaler.fit_transform(train_features)\n",
    "    val_features = scaler.transform(val_features)\n",
    "    test_features = scaler.transform(test_features)\n",
    "\n",
    "    train_dataset = FlowFeatureDataset(train_features, train_labels)\n",
    "    val_dataset = FlowFeatureDataset(val_features, val_labels)\n",
    "    test_dataset = FlowFeatureDataset(test_features, test_labels)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True\n",
    "    )\n",
    "    feature_dim = train_features.shape[1]\n",
    "\n",
    "    return train_loader, val_loader, test_loader, feature_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "dI-B6ryFCK9F"
   },
   "outputs": [],
   "source": [
    "class DeepFlowClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[256, 256, 128, 128, 64], dropout_rate=0.4):\n",
    "        super(DeepFlowClassifier, self).__init__()\n",
    "\n",
    "        self.input_layer = nn.Linear(input_dim, hidden_dims[0])\n",
    "        self.batch_norm_input = nn.BatchNorm1d(hidden_dims[0])\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            self.layers.append(nn.Linear(hidden_dims[i], hidden_dims[i + 1]))\n",
    "            self.batch_norms.append(nn.BatchNorm1d(hidden_dims[i + 1]))\n",
    "\n",
    "        self.output_layer = nn.Linear(hidden_dims[-1], 2)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.residual_adaptations = nn.ModuleList()\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            if hidden_dims[i] != hidden_dims[i + 1]:\n",
    "                self.residual_adaptations.append(nn.Linear(hidden_dims[i], hidden_dims[i + 1]))\n",
    "            else:\n",
    "                self.residual_adaptations.append(None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.batch_norm_input(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        for i, (layer, bn) in enumerate(zip(self.layers, self.batch_norms)):\n",
    "            identity = x\n",
    "            x = layer(x)\n",
    "            x = bn(x)\n",
    "            x = F.relu(x)\n",
    "            if self.residual_adaptations[i] is not None:\n",
    "                identity = self.residual_adaptations[i](identity)\n",
    "\n",
    "            x = x + identity\n",
    "            x = self.dropout(x)\n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def create_deep_flow_classifier(input_dim, hidden_dims=[128, 64, 32], dropout_rate=0.4):\n",
    "    model = DeepFlowClassifier(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dims=hidden_dims,\n",
    "        dropout_rate=dropout_rate\n",
    "    )\n",
    "\n",
    "    print(f\"Created DeepFlowClassifier with {sum(p.numel() for p in model.parameters())} parameters\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "_iS4O6NtCTFC"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, criterion, device,\n",
    "               mixed_precision=True, gradient_accumulation_steps=1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    scaler = GradScaler() if mixed_precision else None\n",
    "\n",
    "    pbar = tqdm(total=len(train_loader), desc=\"Training\")\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for i, (features, labels) in enumerate(train_loader):\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with autocast(enabled=mixed_precision):\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss = loss / gradient_accumulation_steps\n",
    "\n",
    "        if mixed_precision:\n",
    "            scaler.scale(loss).backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        if (i + 1) % gradient_accumulation_steps == 0 or (i + 1) == len(train_loader):\n",
    "            if mixed_precision:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                optimizer.step()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item() * gradient_accumulation_steps\n",
    "\n",
    "        pbar.update(1)\n",
    "        pbar.set_postfix({'loss': total_loss / (i + 1)})\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, labels in val_loader:\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='binary')\n",
    "    recall = recall_score(all_labels, all_preds, average='binary')\n",
    "    f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "\n",
    "    return total_loss / len(val_loader), accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "z2J0jIdFCVy3"
   },
   "outputs": [],
   "source": [
    "def test(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_loader:\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='binary')\n",
    "    recall = recall_score(all_labels, all_preds, average='binary')\n",
    "    f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    return total_loss / len(test_loader), accuracy, precision, recall, f1, cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "4k6YoDE0tO1O"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, test_loader, config, save_dir='models', device=None):\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = model.to(device)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=config['learning_rate'],\n",
    "        weight_decay=config['weight_decay']\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=0.5, patience=5, verbose=True\n",
    "    )\n",
    "\n",
    "    best_val_f1 = 0.0\n",
    "    best_epoch = 0\n",
    "    patience_counter = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    val_f1_scores = []\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(config['num_epochs']):\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss = train_epoch(\n",
    "            model, train_loader, optimizer, criterion, device,\n",
    "            mixed_precision=config['mixed_precision'],\n",
    "            gradient_accumulation_steps=config['grad_accum_steps']\n",
    "        )\n",
    "\n",
    "        val_loss, val_accuracy, val_precision, val_recall, val_f1 = validate(\n",
    "            model, val_loader, criterion, device\n",
    "        )\n",
    "\n",
    "        scheduler.step(val_f1)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        val_f1_scores.append(val_f1)\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            best_epoch = epoch\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict()\n",
    "            torch.save(best_model_state, os.path.join(save_dir, 'best_model.pt'))\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f\"Epoch {epoch+1}/{config['num_epochs']}, Time: {epoch_time:.2f}s\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}, F1: {val_f1:.4f}\")\n",
    "        print(f\"Best Val F1: {best_val_f1:.4f} (Epoch {best_epoch+1})\")\n",
    "        print(f\"Patience: {patience_counter}/{config['patience']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        if patience_counter >= config['patience']:\n",
    "            print(f\"Early stopping after {epoch+1} epochs\")\n",
    "            break\n",
    "    model.load_state_dict(best_model_state)\n",
    "\n",
    "    if test_loader is not None:\n",
    "        test_loss, test_accuracy, test_precision, test_recall, test_f1, cm = test(\n",
    "            model, test_loader, criterion, device\n",
    "        )\n",
    "        print(\"Test Results:\")\n",
    "        print(f\"Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}\")\n",
    "        print(f\"Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(cm)\n",
    "\n",
    "    plot_training_curves(train_losses, val_losses, val_accuracies, val_f1_scores, save_dir)\n",
    "    return best_val_f1, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "CuynaBzMCX6n"
   },
   "outputs": [],
   "source": [
    "def plot_training_curves(train_losses, val_losses, val_accuracies, val_f1_scores, save_dir):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(val_accuracies, label='Accuracy')\n",
    "    plt.plot(val_f1_scores, label='F1 Score')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Metric')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.title('Validation Metrics')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, 'training_curves.png'))\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "Cgda-RFLs42q"
   },
   "outputs": [],
   "source": [
    "def predict_video(video_path, model, device, sample_rate=3, max_frames=50, resize_shape=(320, 240)):\n",
    "    features = process_video(video_path, sample_rate, max_frames, resize_shape)\n",
    "\n",
    "    if features is None:\n",
    "        print(f\"Error processing video: {video_path}\")\n",
    "        return None, None\n",
    "\n",
    "    features_tensor = torch.FloatTensor([list(features.values())]).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(features_tensor)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        prediction = torch.argmax(probabilities, dim=1).item()\n",
    "        confidence = probabilities[0, prediction].item()\n",
    "\n",
    "    return prediction, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "Rlu20080CbDf"
   },
   "outputs": [],
   "source": [
    "def predict_videos(video_dir, model, device, output_csv=None, sample_rate=3, max_frames=50,\n",
    "                  resize_width=320, resize_height=240):\n",
    "\n",
    "    video_paths = list(Path(video_dir).glob('**/*.mp4'))\n",
    "    video_paths.extend(list(Path(video_dir).glob('**/*.avi')))\n",
    "    video_paths.extend(list(Path(video_dir).glob('**/*.mov')))\n",
    "\n",
    "    results = []\n",
    "\n",
    "    resize_shape = (resize_width, resize_height)\n",
    "    for video_path in tqdm(video_paths, desc=\"Predicting\"):\n",
    "        try:\n",
    "            prediction, confidence = predict_video(\n",
    "                str(video_path), model, device, sample_rate, max_frames, resize_shape\n",
    "            )\n",
    "\n",
    "            if prediction is not None:\n",
    "                results.append({\n",
    "                    'video': video_path.name,\n",
    "                    'prediction': 'real' if prediction == 1 else 'fake',\n",
    "                    'confidence': confidence\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {video_path}: {e}\")\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    if output_csv is not None:\n",
    "        results_df.to_csv(output_csv, index=False)\n",
    "        print(f\"Results saved to {output_csv}\")\n",
    "\n",
    "    if results:\n",
    "        real_count = sum(1 for result in results if result['prediction'] == 'real')\n",
    "        fake_count = sum(1 for result in results if result['prediction'] == 'fake')\n",
    "        total_count = len(results)\n",
    "\n",
    "        print(f\"Summary: {total_count} videos processed\")\n",
    "        print(f\"Real: {real_count} ({real_count / total_count * 100:.1f}%)\")\n",
    "        print(f\"Fake: {fake_count} ({fake_count / total_count * 100:.1f}%)\")\n",
    "    else:\n",
    "        print(\"No videos processed successfully.\")\n",
    "\n",
    "    return results_df\n",
    "\n",
    "def visualize_results(results_df, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(x='prediction', data=results_df)\n",
    "    plt.title('Prediction Counts')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'prediction_counts.png'))\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(data=results_df, x='confidence', hue='prediction', bins=20, kde=True)\n",
    "    plt.title('Confidence Distribution')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'confidence_distribution.png'))\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x='prediction', y='confidence', data=results_df)\n",
    "    plt.title('Confidence by Prediction')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'confidence_by_prediction.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Create a small ViT model\n",
    "        self.vit = timm.create_model(\n",
    "            'vit_base_patch16_224',  # pretrained ViT model\n",
    "            pretrained=True,\n",
    "            num_classes=0  # No final classification head\n",
    "        )\n",
    "        \n",
    "        # Freeze ViT encoder if needed (optional)\n",
    "        for param in self.vit.parameters():\n",
    "            param.requires_grad = True  # Set False if you want to freeze\n",
    "\n",
    "        # Project feature vectors to match ViT expected shape\n",
    "        self.input_proj = nn.Linear(input_dim, 768)  # vit_base_patch16 has 768 hidden dim\n",
    "\n",
    "        # Classifier\n",
    "        self.fc = nn.Linear(768, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, feature_dim)\n",
    "\n",
    "        x = self.input_proj(x)  # (batch_size, 768)\n",
    "        B = x.shape[0]\n",
    "        x = x.unsqueeze(1)  # (B, 1, 768) — treat as 1 patch\n",
    "\n",
    "        # Add positional embedding manually\n",
    "        cls_token = self.vit.cls_token.expand(B, -1, -1)  # (B, 1, 768)\n",
    "        x = torch.cat((cls_token, x), dim=1)  # (B, 2, 768)\n",
    "        x = x + self.vit.pos_embed[:, :x.size(1), :]  # Add positional encoding\n",
    "\n",
    "        # Pass through Transformer encoder\n",
    "        x = self.vit.blocks(x)\n",
    "        x = self.vit.norm(x)\n",
    "\n",
    "        # Take [CLS] token output\n",
    "        cls_output = x[:, 0]  # (B, 768)\n",
    "\n",
    "        out = self.fc(cls_output)  # Final classification\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FineTunedViTClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vit = timm.create_model(\n",
    "            'vit_base_patch16_224',\n",
    "            pretrained=True,\n",
    "            num_classes=0\n",
    "        )\n",
    "        \n",
    "        for name, param in self.vit.named_parameters():\n",
    "            if any(f'blocks.{i}.' in name for i in [8, 9, 10, 11]) or 'norm' in name:\n",
    "                param.requires_grad = True\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.input_proj = nn.Linear(input_dim, 768)\n",
    "        self.pre_classifier_norm = nn.LayerNorm(768)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(768, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_proj(x)\n",
    "        B = x.size(0)\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        cls_token = self.vit.cls_token.expand(B, -1, -1)\n",
    "        x = torch.cat((cls_token, x), dim=1)\n",
    "\n",
    "        x = self.vit.blocks(x)\n",
    "        x = self.vit.norm(x)\n",
    "\n",
    "        cls_output = x[:, 0]\n",
    "        cls_output = self.pre_classifier_norm(cls_output)\n",
    "\n",
    "        out = self.fc(cls_output)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(config):\n",
    "    os.makedirs(config['output_dir'], exist_ok=True)\n",
    "    features_dir = os.path.join(config['output_dir'], 'features')\n",
    "    os.makedirs(features_dir, exist_ok=True)\n",
    "\n",
    "    real_features_path = os.path.join(features_dir, '1_features.npz')\n",
    "    fake_features_path = os.path.join(features_dir, '0_features.npz')\n",
    "\n",
    "    if not (os.path.exists(real_features_path) and os.path.exists(fake_features_path)):\n",
    "        print(\"Processing videos...\")\n",
    "\n",
    "        print(\"Processing real videos...\")\n",
    "        real_features, real_labels = process_videos(\n",
    "            config['real_dir'], 1, features_dir,\n",
    "            sample_rate=config['sample_rate'],\n",
    "            max_frames=config['max_frames'],\n",
    "            resize_width=config['resize_width'],\n",
    "            resize_height=config['resize_height'],\n",
    "            limit=config['limit']\n",
    "        )\n",
    "\n",
    "        print(\"Processing fake videos...\")\n",
    "        fake_features, fake_labels = process_videos(\n",
    "            config['fake_dir'], 0, features_dir,\n",
    "            sample_rate=config['sample_rate'],\n",
    "            max_frames=config['max_frames'],\n",
    "            resize_width=config['resize_width'],\n",
    "            resize_height=config['resize_height'],\n",
    "            limit=config['limit']\n",
    "        )\n",
    "\n",
    "        print(\"Video processing complete!\")\n",
    "    else:\n",
    "        print(\"Using existing features...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing features...\n"
     ]
    }
   ],
   "source": [
    "prepare_features(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(config, model_type=\"fine_tuned_vit\"):\n",
    "    features_dir = os.path.join(config['output_dir'], 'features')\n",
    "    models_dir = os.path.join(config['output_dir'], 'models', model_type)\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "    print(\"Preparing dataloaders...\")\n",
    "    train_loader, val_loader, test_loader, feature_dim = prepare_dataloaders(\n",
    "        features_dir,\n",
    "        batch_size=config['batch_size'],\n",
    "        val_split=config['val_split'],\n",
    "        test_split=config['test_split']\n",
    "    )\n",
    "\n",
    "    if train_loader is None:\n",
    "        print(\"Error: No features found.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Feature dimension: {feature_dim}\")\n",
    "    config['feature_dim'] = feature_dim\n",
    "\n",
    "    print(f\"Initializing {model_type} model...\")\n",
    "    if model_type == 'deep':\n",
    "        model = create_deep_flow_classifier(\n",
    "            input_dim=feature_dim,\n",
    "            hidden_dims=config['hidden_dims'],\n",
    "            dropout_rate=config['dropout_rate']\n",
    "        )\n",
    "    elif model_type == 'vit':\n",
    "        model = ViTClassifier(\n",
    "            input_dim=feature_dim,\n",
    "            num_classes=2\n",
    "        )\n",
    "    elif model_type == 'fine_tuned_vit': \n",
    "        model = FineTunedViTClassifier(\n",
    "            input_dim=feature_dim,\n",
    "            num_classes=2\n",
    "        )\n",
    "\n",
    "    print(\"Training model...\")\n",
    "    best_val_f1, model = train_model(\n",
    "        model, train_loader, val_loader, test_loader, config,\n",
    "        save_dir=models_dir, device=device\n",
    "    )\n",
    "\n",
    "    # Save configuration for this model\n",
    "    with open(os.path.join(models_dir, 'config.json'), 'w') as f:\n",
    "        json.dump(config, f, indent=4)\n",
    "\n",
    "    print(f\"Training complete for {model_type}! Best validation F1 score: {best_val_f1:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep CNN\n",
      "Preparing dataloaders...\n",
      "Feature dimension: 13\n",
      "Initializing deep model...\n",
      "Created DeepFlowClassifier with 370946 parameters\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.59it/s, loss=0.854]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Time: 0.04s\n",
      "Train Loss: 0.8539\n",
      "Val Loss: 0.6958, Accuracy: 0.5000, F1: 0.4505\n",
      "Best Val F1: 0.4505 (Epoch 1)\n",
      "Patience: 0/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 28.95it/s, loss=0.824]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000, Time: 0.05s\n",
      "Train Loss: 0.8244\n",
      "Val Loss: 0.6971, Accuracy: 0.5000, F1: 0.0385\n",
      "Best Val F1: 0.4505 (Epoch 1)\n",
      "Patience: 1/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 57.08it/s, loss=0.873]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000, Time: 0.03s\n",
      "Train Loss: 0.8728\n",
      "Val Loss: 0.6997, Accuracy: 0.5100, F1: 0.0392\n",
      "Best Val F1: 0.4505 (Epoch 1)\n",
      "Patience: 2/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.21it/s, loss=0.965]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/1000, Time: 0.03s\n",
      "Train Loss: 0.9652\n",
      "Val Loss: 0.7020, Accuracy: 0.5150, F1: 0.1983\n",
      "Best Val F1: 0.4505 (Epoch 1)\n",
      "Patience: 3/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.51it/s, loss=0.749]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/1000, Time: 0.03s\n",
      "Train Loss: 0.7493\n",
      "Val Loss: 0.7033, Accuracy: 0.5250, F1: 0.4172\n",
      "Best Val F1: 0.4505 (Epoch 1)\n",
      "Patience: 4/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.24it/s, loss=0.738]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/1000, Time: 0.04s\n",
      "Train Loss: 0.7382\n",
      "Val Loss: 0.7032, Accuracy: 0.5350, F1: 0.5181\n",
      "Best Val F1: 0.5181 (Epoch 6)\n",
      "Patience: 0/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.52it/s, loss=0.892]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/1000, Time: 0.03s\n",
      "Train Loss: 0.8922\n",
      "Val Loss: 0.7021, Accuracy: 0.5450, F1: 0.5646\n",
      "Best Val F1: 0.5646 (Epoch 7)\n",
      "Patience: 0/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.51it/s, loss=0.739]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/1000, Time: 0.03s\n",
      "Train Loss: 0.7386\n",
      "Val Loss: 0.7021, Accuracy: 0.5600, F1: 0.6140\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 0/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 57.12it/s, loss=0.879]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/1000, Time: 0.03s\n",
      "Train Loss: 0.8789\n",
      "Val Loss: 0.7032, Accuracy: 0.5250, F1: 0.6091\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 1/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 57.11it/s, loss=0.856]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/1000, Time: 0.03s\n",
      "Train Loss: 0.8561\n",
      "Val Loss: 0.7056, Accuracy: 0.5100, F1: 0.6080\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 2/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 57.07it/s, loss=0.8]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/1000, Time: 0.03s\n",
      "Train Loss: 0.7995\n",
      "Val Loss: 0.7087, Accuracy: 0.5050, F1: 0.6087\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 3/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.19it/s, loss=0.817]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/1000, Time: 0.03s\n",
      "Train Loss: 0.8171\n",
      "Val Loss: 0.7119, Accuracy: 0.4950, F1: 0.6070\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 4/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.57it/s, loss=0.787]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/1000, Time: 0.03s\n",
      "Train Loss: 0.7869\n",
      "Val Loss: 0.7151, Accuracy: 0.4950, F1: 0.6070\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 5/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.59it/s, loss=0.755]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/1000, Time: 0.03s\n",
      "Train Loss: 0.7555\n",
      "Val Loss: 0.7176, Accuracy: 0.5000, F1: 0.6094\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 6/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 53.99it/s, loss=0.729]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/1000, Time: 0.03s\n",
      "Train Loss: 0.7291\n",
      "Val Loss: 0.7190, Accuracy: 0.5000, F1: 0.6094\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 7/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.55it/s, loss=0.803]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/1000, Time: 0.03s\n",
      "Train Loss: 0.8026\n",
      "Val Loss: 0.7207, Accuracy: 0.5000, F1: 0.6094\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 8/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.59it/s, loss=0.793]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/1000, Time: 0.03s\n",
      "Train Loss: 0.7935\n",
      "Val Loss: 0.7225, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 9/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.51it/s, loss=0.793]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/1000, Time: 0.03s\n",
      "Train Loss: 0.7929\n",
      "Val Loss: 0.7245, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 10/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 54.46it/s, loss=0.731]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/1000, Time: 0.03s\n",
      "Train Loss: 0.7312\n",
      "Val Loss: 0.7258, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 11/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.59it/s, loss=0.709]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/1000, Time: 0.04s\n",
      "Train Loss: 0.7085\n",
      "Val Loss: 0.7271, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 12/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.43it/s, loss=0.739]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/1000, Time: 0.03s\n",
      "Train Loss: 0.7388\n",
      "Val Loss: 0.7288, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 13/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.07it/s, loss=0.76]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/1000, Time: 0.03s\n",
      "Train Loss: 0.7600\n",
      "Val Loss: 0.7297, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 14/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.57it/s, loss=0.844]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/1000, Time: 0.03s\n",
      "Train Loss: 0.8436\n",
      "Val Loss: 0.7311, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 15/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 40.79it/s, loss=0.8]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/1000, Time: 0.04s\n",
      "Train Loss: 0.7996\n",
      "Val Loss: 0.7318, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 16/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 38.28it/s, loss=0.736]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/1000, Time: 0.04s\n",
      "Train Loss: 0.7357\n",
      "Val Loss: 0.7331, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 17/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 54.00it/s, loss=0.715]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/1000, Time: 0.03s\n",
      "Train Loss: 0.7145\n",
      "Val Loss: 0.7341, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 18/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 45.38it/s, loss=0.698]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/1000, Time: 0.04s\n",
      "Train Loss: 0.6977\n",
      "Val Loss: 0.7352, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 19/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 43.45it/s, loss=0.753]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/1000, Time: 0.04s\n",
      "Train Loss: 0.7529\n",
      "Val Loss: 0.7358, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 20/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 45.38it/s, loss=0.681]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/1000, Time: 0.04s\n",
      "Train Loss: 0.6805\n",
      "Val Loss: 0.7364, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 21/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.51it/s, loss=0.753]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/1000, Time: 0.03s\n",
      "Train Loss: 0.7529\n",
      "Val Loss: 0.7369, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 22/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 40.77it/s, loss=0.777]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/1000, Time: 0.04s\n",
      "Train Loss: 0.7774\n",
      "Val Loss: 0.7374, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 23/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.60it/s, loss=0.77]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/1000, Time: 0.03s\n",
      "Train Loss: 0.7696\n",
      "Val Loss: 0.7378, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 24/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.52it/s, loss=0.742]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/1000, Time: 0.03s\n",
      "Train Loss: 0.7420\n",
      "Val Loss: 0.7386, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 25/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.91it/s, loss=0.837]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/1000, Time: 0.03s\n",
      "Train Loss: 0.8367\n",
      "Val Loss: 0.7391, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 26/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 58.26it/s, loss=0.702]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/1000, Time: 0.03s\n",
      "Train Loss: 0.7016\n",
      "Val Loss: 0.7394, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 27/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 44.33it/s, loss=0.665]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/1000, Time: 0.03s\n",
      "Train Loss: 0.6650\n",
      "Val Loss: 0.7401, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 28/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 42.50it/s, loss=0.794]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/1000, Time: 0.04s\n",
      "Train Loss: 0.7936\n",
      "Val Loss: 0.7408, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 29/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 46.45it/s, loss=0.716]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/1000, Time: 0.03s\n",
      "Train Loss: 0.7157\n",
      "Val Loss: 0.7408, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 30/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.95it/s, loss=0.835]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/1000, Time: 0.03s\n",
      "Train Loss: 0.8349\n",
      "Val Loss: 0.7410, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 31/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 57.08it/s, loss=0.734]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/1000, Time: 0.03s\n",
      "Train Loss: 0.7343\n",
      "Val Loss: 0.7413, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 32/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 57.08it/s, loss=0.714]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/1000, Time: 0.03s\n",
      "Train Loss: 0.7137\n",
      "Val Loss: 0.7418, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 33/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.49it/s, loss=0.713]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/1000, Time: 0.03s\n",
      "Train Loss: 0.7127\n",
      "Val Loss: 0.7423, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 34/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 50.82it/s, loss=0.808]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/1000, Time: 0.03s\n",
      "Train Loss: 0.8076\n",
      "Val Loss: 0.7422, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 35/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 54.00it/s, loss=0.807]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/1000, Time: 0.03s\n",
      "Train Loss: 0.8070\n",
      "Val Loss: 0.7420, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 36/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 57.09it/s, loss=0.791]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/1000, Time: 0.03s\n",
      "Train Loss: 0.7910\n",
      "Val Loss: 0.7422, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 37/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 54.01it/s, loss=0.691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/1000, Time: 0.03s\n",
      "Train Loss: 0.6911\n",
      "Val Loss: 0.7424, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 38/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.47it/s, loss=0.759]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/1000, Time: 0.03s\n",
      "Train Loss: 0.7586\n",
      "Val Loss: 0.7420, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 39/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.24it/s, loss=0.731]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/1000, Time: 0.03s\n",
      "Train Loss: 0.7305\n",
      "Val Loss: 0.7417, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 40/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.95it/s, loss=0.682]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/1000, Time: 0.03s\n",
      "Train Loss: 0.6815\n",
      "Val Loss: 0.7417, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 41/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.26it/s, loss=0.782]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/1000, Time: 0.03s\n",
      "Train Loss: 0.7822\n",
      "Val Loss: 0.7419, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 42/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 43.44it/s, loss=0.731]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/1000, Time: 0.04s\n",
      "Train Loss: 0.7312\n",
      "Val Loss: 0.7421, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 43/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 46.46it/s, loss=0.796]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/1000, Time: 0.04s\n",
      "Train Loss: 0.7961\n",
      "Val Loss: 0.7420, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 44/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 53.41it/s, loss=0.75]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/1000, Time: 0.03s\n",
      "Train Loss: 0.7498\n",
      "Val Loss: 0.7421, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 45/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.56it/s, loss=0.797]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/1000, Time: 0.03s\n",
      "Train Loss: 0.7968\n",
      "Val Loss: 0.7425, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 46/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.58it/s, loss=0.841]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/1000, Time: 0.04s\n",
      "Train Loss: 0.8408\n",
      "Val Loss: 0.7426, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 47/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.73it/s, loss=0.744]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/1000, Time: 0.03s\n",
      "Train Loss: 0.7435\n",
      "Val Loss: 0.7432, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 48/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.45it/s, loss=0.747]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000, Time: 0.03s\n",
      "Train Loss: 0.7472\n",
      "Val Loss: 0.7432, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 49/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 53.98it/s, loss=0.801]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/1000, Time: 0.03s\n",
      "Train Loss: 0.8015\n",
      "Val Loss: 0.7432, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 50/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.58it/s, loss=0.7]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000, Time: 0.03s\n",
      "Train Loss: 0.6996\n",
      "Val Loss: 0.7431, Accuracy: 0.4900, F1: 0.6016\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 51/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 50.89it/s, loss=0.729]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/1000, Time: 0.03s\n",
      "Train Loss: 0.7294\n",
      "Val Loss: 0.7428, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 52/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.26it/s, loss=0.865]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/1000, Time: 0.03s\n",
      "Train Loss: 0.8646\n",
      "Val Loss: 0.7428, Accuracy: 0.5000, F1: 0.6094\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 53/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 54.04it/s, loss=0.724]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/1000, Time: 0.03s\n",
      "Train Loss: 0.7239\n",
      "Val Loss: 0.7432, Accuracy: 0.5000, F1: 0.6094\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 54/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 45.42it/s, loss=0.713]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/1000, Time: 0.03s\n",
      "Train Loss: 0.7132\n",
      "Val Loss: 0.7431, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 55/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 46.44it/s, loss=0.786]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/1000, Time: 0.04s\n",
      "Train Loss: 0.7858\n",
      "Val Loss: 0.7432, Accuracy: 0.5000, F1: 0.6094\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 56/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 57.06it/s, loss=0.689]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/1000, Time: 0.03s\n",
      "Train Loss: 0.6892\n",
      "Val Loss: 0.7431, Accuracy: 0.5000, F1: 0.6094\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 57/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.49it/s, loss=0.723]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/1000, Time: 0.03s\n",
      "Train Loss: 0.7228\n",
      "Val Loss: 0.7434, Accuracy: 0.5000, F1: 0.6094\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 58/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 57.08it/s, loss=0.769]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/1000, Time: 0.03s\n",
      "Train Loss: 0.7686\n",
      "Val Loss: 0.7436, Accuracy: 0.5000, F1: 0.6094\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 59/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 44.39it/s, loss=0.699]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/1000, Time: 0.04s\n",
      "Train Loss: 0.6992\n",
      "Val Loss: 0.7437, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 60/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 44.37it/s, loss=0.757]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/1000, Time: 0.04s\n",
      "Train Loss: 0.7571\n",
      "Val Loss: 0.7437, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 61/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.88it/s, loss=0.745]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/1000, Time: 0.03s\n",
      "Train Loss: 0.7451\n",
      "Val Loss: 0.7438, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 62/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 43.39it/s, loss=0.818]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000, Time: 0.04s\n",
      "Train Loss: 0.8180\n",
      "Val Loss: 0.7435, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 63/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 60.55it/s, loss=0.739]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/1000, Time: 0.03s\n",
      "Train Loss: 0.7391\n",
      "Val Loss: 0.7437, Accuracy: 0.5000, F1: 0.6063\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 64/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 45.39it/s, loss=0.713]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/1000, Time: 0.03s\n",
      "Train Loss: 0.7128\n",
      "Val Loss: 0.7435, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 65/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 53.97it/s, loss=0.707]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/1000, Time: 0.03s\n",
      "Train Loss: 0.7070\n",
      "Val Loss: 0.7435, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 66/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.52it/s, loss=0.762]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/1000, Time: 0.03s\n",
      "Train Loss: 0.7622\n",
      "Val Loss: 0.7432, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 67/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 57.07it/s, loss=0.751]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/1000, Time: 0.03s\n",
      "Train Loss: 0.7511\n",
      "Val Loss: 0.7434, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 68/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.51it/s, loss=0.683]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/1000, Time: 0.03s\n",
      "Train Loss: 0.6827\n",
      "Val Loss: 0.7437, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 69/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.58it/s, loss=0.795]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/1000, Time: 0.03s\n",
      "Train Loss: 0.7949\n",
      "Val Loss: 0.7433, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 70/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.30it/s, loss=0.79]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/1000, Time: 0.03s\n",
      "Train Loss: 0.7898\n",
      "Val Loss: 0.7437, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 71/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 54.00it/s, loss=0.734]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/1000, Time: 0.03s\n",
      "Train Loss: 0.7343\n",
      "Val Loss: 0.7439, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 72/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 54.00it/s, loss=0.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/1000, Time: 0.03s\n",
      "Train Loss: 0.7001\n",
      "Val Loss: 0.7439, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 73/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.48it/s, loss=0.759]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/1000, Time: 0.03s\n",
      "Train Loss: 0.7591\n",
      "Val Loss: 0.7442, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 74/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 60.57it/s, loss=0.755]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/1000, Time: 0.03s\n",
      "Train Loss: 0.7545\n",
      "Val Loss: 0.7439, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 75/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.60it/s, loss=0.755]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/1000, Time: 0.03s\n",
      "Train Loss: 0.7546\n",
      "Val Loss: 0.7441, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 76/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.24it/s, loss=0.778]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/1000, Time: 0.03s\n",
      "Train Loss: 0.7778\n",
      "Val Loss: 0.7442, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 77/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.50it/s, loss=0.635]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/1000, Time: 0.04s\n",
      "Train Loss: 0.6346\n",
      "Val Loss: 0.7441, Accuracy: 0.5000, F1: 0.6063\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 78/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.70it/s, loss=0.822]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/1000, Time: 0.03s\n",
      "Train Loss: 0.8216\n",
      "Val Loss: 0.7441, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 79/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.57it/s, loss=0.763]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/1000, Time: 0.03s\n",
      "Train Loss: 0.7627\n",
      "Val Loss: 0.7440, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 80/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.33it/s, loss=0.755]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/1000, Time: 0.04s\n",
      "Train Loss: 0.7550\n",
      "Val Loss: 0.7442, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 81/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.74it/s, loss=0.68]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/1000, Time: 0.03s\n",
      "Train Loss: 0.6804\n",
      "Val Loss: 0.7438, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 82/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.22it/s, loss=0.67]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/1000, Time: 0.03s\n",
      "Train Loss: 0.6704\n",
      "Val Loss: 0.7439, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 83/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.60it/s, loss=0.711]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/1000, Time: 0.03s\n",
      "Train Loss: 0.7111\n",
      "Val Loss: 0.7437, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 84/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 46.45it/s, loss=0.703]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/1000, Time: 0.04s\n",
      "Train Loss: 0.7034\n",
      "Val Loss: 0.7438, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 85/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.96it/s, loss=0.752]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/1000, Time: 0.03s\n",
      "Train Loss: 0.7523\n",
      "Val Loss: 0.7432, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 86/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.53it/s, loss=0.8]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/1000, Time: 0.03s\n",
      "Train Loss: 0.7997\n",
      "Val Loss: 0.7430, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 87/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.23it/s, loss=0.688]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/1000, Time: 0.03s\n",
      "Train Loss: 0.6882\n",
      "Val Loss: 0.7434, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 88/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.47it/s, loss=0.733]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/1000, Time: 0.03s\n",
      "Train Loss: 0.7330\n",
      "Val Loss: 0.7432, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 89/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.57it/s, loss=0.776]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/1000, Time: 0.03s\n",
      "Train Loss: 0.7755\n",
      "Val Loss: 0.7430, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 90/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.59it/s, loss=0.763]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/1000, Time: 0.03s\n",
      "Train Loss: 0.7631\n",
      "Val Loss: 0.7432, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 91/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.73it/s, loss=0.666]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/1000, Time: 0.03s\n",
      "Train Loss: 0.6660\n",
      "Val Loss: 0.7431, Accuracy: 0.5000, F1: 0.6063\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 92/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 44.41it/s, loss=0.751]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/1000, Time: 0.03s\n",
      "Train Loss: 0.7509\n",
      "Val Loss: 0.7433, Accuracy: 0.5000, F1: 0.6063\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 93/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.71it/s, loss=0.702]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/1000, Time: 0.03s\n",
      "Train Loss: 0.7018\n",
      "Val Loss: 0.7434, Accuracy: 0.5000, F1: 0.6063\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 94/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.92it/s, loss=0.799]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/1000, Time: 0.03s\n",
      "Train Loss: 0.7994\n",
      "Val Loss: 0.7433, Accuracy: 0.5000, F1: 0.6063\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 95/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.79it/s, loss=0.804]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/1000, Time: 0.03s\n",
      "Train Loss: 0.8037\n",
      "Val Loss: 0.7428, Accuracy: 0.5000, F1: 0.6063\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 96/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 54.00it/s, loss=0.734]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/1000, Time: 0.03s\n",
      "Train Loss: 0.7343\n",
      "Val Loss: 0.7424, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 97/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.55it/s, loss=0.747]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/1000, Time: 0.03s\n",
      "Train Loss: 0.7470\n",
      "Val Loss: 0.7421, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 98/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 53.94it/s, loss=0.785]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/1000, Time: 0.03s\n",
      "Train Loss: 0.7853\n",
      "Val Loss: 0.7425, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 99/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 56.12it/s, loss=0.71]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/1000, Time: 0.03s\n",
      "Train Loss: 0.7095\n",
      "Val Loss: 0.7421, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 100/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 46.44it/s, loss=0.761]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/1000, Time: 0.04s\n",
      "Train Loss: 0.7611\n",
      "Val Loss: 0.7423, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 101/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 40.74it/s, loss=0.682]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/1000, Time: 0.04s\n",
      "Train Loss: 0.6815\n",
      "Val Loss: 0.7426, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 102/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 42.46it/s, loss=0.766]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/1000, Time: 0.03s\n",
      "Train Loss: 0.7655\n",
      "Val Loss: 0.7429, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 103/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 40.75it/s, loss=0.845]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000, Time: 0.04s\n",
      "Train Loss: 0.8450\n",
      "Val Loss: 0.7431, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 104/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.69it/s, loss=0.753]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000, Time: 0.03s\n",
      "Train Loss: 0.7529\n",
      "Val Loss: 0.7432, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 105/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.50it/s, loss=0.7]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/1000, Time: 0.03s\n",
      "Train Loss: 0.7003\n",
      "Val Loss: 0.7428, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 106/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 56.10it/s, loss=0.799]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/1000, Time: 0.03s\n",
      "Train Loss: 0.7991\n",
      "Val Loss: 0.7428, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 107/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.47it/s, loss=0.757]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/1000, Time: 0.03s\n",
      "Train Loss: 0.7574\n",
      "Val Loss: 0.7433, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 108/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.56it/s, loss=0.844]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/1000, Time: 0.03s\n",
      "Train Loss: 0.8445\n",
      "Val Loss: 0.7435, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 109/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 39.20it/s, loss=0.72]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/1000, Time: 0.04s\n",
      "Train Loss: 0.7197\n",
      "Val Loss: 0.7437, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 110/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 35.38it/s, loss=0.769]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/1000, Time: 0.05s\n",
      "Train Loss: 0.7685\n",
      "Val Loss: 0.7439, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 111/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 42.80it/s, loss=0.695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000, Time: 0.04s\n",
      "Train Loss: 0.6954\n",
      "Val Loss: 0.7442, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 112/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 45.41it/s, loss=0.764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/1000, Time: 0.04s\n",
      "Train Loss: 0.7640\n",
      "Val Loss: 0.7441, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 113/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.61it/s, loss=0.756]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/1000, Time: 0.03s\n",
      "Train Loss: 0.7561\n",
      "Val Loss: 0.7444, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 114/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.55it/s, loss=0.745]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/1000, Time: 0.03s\n",
      "Train Loss: 0.7451\n",
      "Val Loss: 0.7441, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 115/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 46.47it/s, loss=0.713]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/1000, Time: 0.04s\n",
      "Train Loss: 0.7132\n",
      "Val Loss: 0.7447, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 116/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 39.21it/s, loss=0.78]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/1000, Time: 0.04s\n",
      "Train Loss: 0.7799\n",
      "Val Loss: 0.7450, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 117/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.56it/s, loss=0.753]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/1000, Time: 0.04s\n",
      "Train Loss: 0.7530\n",
      "Val Loss: 0.7448, Accuracy: 0.4900, F1: 0.6016\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 118/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 44.34it/s, loss=0.851]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/1000, Time: 0.04s\n",
      "Train Loss: 0.8506\n",
      "Val Loss: 0.7447, Accuracy: 0.4900, F1: 0.6016\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 119/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 44.41it/s, loss=0.748]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128/1000, Time: 0.04s\n",
      "Train Loss: 0.7478\n",
      "Val Loss: 0.7450, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 120/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.74it/s, loss=0.739]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/1000, Time: 0.03s\n",
      "Train Loss: 0.7389\n",
      "Val Loss: 0.7447, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 121/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.74it/s, loss=0.736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/1000, Time: 0.03s\n",
      "Train Loss: 0.7362\n",
      "Val Loss: 0.7448, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 122/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.55it/s, loss=0.713]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/1000, Time: 0.03s\n",
      "Train Loss: 0.7126\n",
      "Val Loss: 0.7450, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 123/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 54.00it/s, loss=0.727]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/1000, Time: 0.03s\n",
      "Train Loss: 0.7272\n",
      "Val Loss: 0.7450, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 124/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.72it/s, loss=0.761]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/1000, Time: 0.03s\n",
      "Train Loss: 0.7609\n",
      "Val Loss: 0.7448, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 125/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.58it/s, loss=0.695]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/1000, Time: 0.03s\n",
      "Train Loss: 0.6946\n",
      "Val Loss: 0.7450, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 126/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 45.34it/s, loss=0.721]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/1000, Time: 0.04s\n",
      "Train Loss: 0.7213\n",
      "Val Loss: 0.7448, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 127/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.58it/s, loss=0.721]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/1000, Time: 0.03s\n",
      "Train Loss: 0.7208\n",
      "Val Loss: 0.7445, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 128/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.56it/s, loss=0.721]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/1000, Time: 0.03s\n",
      "Train Loss: 0.7211\n",
      "Val Loss: 0.7443, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 129/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 57.09it/s, loss=0.728]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138/1000, Time: 0.03s\n",
      "Train Loss: 0.7281\n",
      "Val Loss: 0.7447, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 130/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.54it/s, loss=0.81]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/1000, Time: 0.03s\n",
      "Train Loss: 0.8096\n",
      "Val Loss: 0.7448, Accuracy: 0.4900, F1: 0.6016\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 131/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 44.40it/s, loss=0.756]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/1000, Time: 0.04s\n",
      "Train Loss: 0.7561\n",
      "Val Loss: 0.7440, Accuracy: 0.4900, F1: 0.6016\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 132/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 46.49it/s, loss=0.8]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/1000, Time: 0.03s\n",
      "Train Loss: 0.7996\n",
      "Val Loss: 0.7442, Accuracy: 0.4900, F1: 0.6016\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 133/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 43.44it/s, loss=0.652]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/1000, Time: 0.03s\n",
      "Train Loss: 0.6525\n",
      "Val Loss: 0.7439, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 134/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 44.40it/s, loss=0.754]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/1000, Time: 0.04s\n",
      "Train Loss: 0.7539\n",
      "Val Loss: 0.7435, Accuracy: 0.4850, F1: 0.5961\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 135/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.97it/s, loss=0.723]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/1000, Time: 0.03s\n",
      "Train Loss: 0.7229\n",
      "Val Loss: 0.7432, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 136/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 46.45it/s, loss=0.714]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/1000, Time: 0.04s\n",
      "Train Loss: 0.7142\n",
      "Val Loss: 0.7436, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 137/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 43.44it/s, loss=0.748]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/1000, Time: 0.04s\n",
      "Train Loss: 0.7475\n",
      "Val Loss: 0.7434, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 138/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 44.35it/s, loss=0.724]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/1000, Time: 0.04s\n",
      "Train Loss: 0.7237\n",
      "Val Loss: 0.7434, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 139/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 43.46it/s, loss=0.721]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/1000, Time: 0.04s\n",
      "Train Loss: 0.7206\n",
      "Val Loss: 0.7433, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 140/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 44.77it/s, loss=0.678]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/1000, Time: 0.04s\n",
      "Train Loss: 0.6780\n",
      "Val Loss: 0.7433, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 141/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 45.18it/s, loss=0.697]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/1000, Time: 0.04s\n",
      "Train Loss: 0.6974\n",
      "Val Loss: 0.7434, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 142/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 40.14it/s, loss=0.725]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000, Time: 0.04s\n",
      "Train Loss: 0.7255\n",
      "Val Loss: 0.7435, Accuracy: 0.5000, F1: 0.6094\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 143/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.26it/s, loss=0.797]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152/1000, Time: 0.03s\n",
      "Train Loss: 0.7974\n",
      "Val Loss: 0.7437, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 144/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 45.43it/s, loss=0.736]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153/1000, Time: 0.03s\n",
      "Train Loss: 0.7364\n",
      "Val Loss: 0.7443, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 145/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.59it/s, loss=0.726]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154/1000, Time: 0.03s\n",
      "Train Loss: 0.7256\n",
      "Val Loss: 0.7446, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 146/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 53.97it/s, loss=0.759]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/1000, Time: 0.03s\n",
      "Train Loss: 0.7589\n",
      "Val Loss: 0.7452, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 147/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.21it/s, loss=0.757]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156/1000, Time: 0.03s\n",
      "Train Loss: 0.7570\n",
      "Val Loss: 0.7452, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 148/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.96it/s, loss=0.694]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/1000, Time: 0.03s\n",
      "Train Loss: 0.6944\n",
      "Val Loss: 0.7449, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 149/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.26it/s, loss=0.738]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158/1000, Time: 0.03s\n",
      "Train Loss: 0.7381\n",
      "Val Loss: 0.7445, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 150/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 44.49it/s, loss=0.728]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/1000, Time: 0.04s\n",
      "Train Loss: 0.7284\n",
      "Val Loss: 0.7444, Accuracy: 0.5000, F1: 0.6094\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 151/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 41.33it/s, loss=0.758]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/1000, Time: 0.04s\n",
      "Train Loss: 0.7582\n",
      "Val Loss: 0.7440, Accuracy: 0.5000, F1: 0.6094\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 152/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.58it/s, loss=0.719]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/1000, Time: 0.03s\n",
      "Train Loss: 0.7186\n",
      "Val Loss: 0.7438, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 153/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 46.83it/s, loss=0.792]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/1000, Time: 0.04s\n",
      "Train Loss: 0.7918\n",
      "Val Loss: 0.7433, Accuracy: 0.5000, F1: 0.6094\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 154/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.74it/s, loss=0.779]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/1000, Time: 0.03s\n",
      "Train Loss: 0.7791\n",
      "Val Loss: 0.7432, Accuracy: 0.5000, F1: 0.6094\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 155/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 45.39it/s, loss=0.678]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/1000, Time: 0.03s\n",
      "Train Loss: 0.6783\n",
      "Val Loss: 0.7432, Accuracy: 0.5000, F1: 0.6094\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 156/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.20it/s, loss=0.702]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/1000, Time: 0.03s\n",
      "Train Loss: 0.7024\n",
      "Val Loss: 0.7434, Accuracy: 0.5000, F1: 0.6094\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 157/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 46.46it/s, loss=0.702]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/1000, Time: 0.03s\n",
      "Train Loss: 0.7017\n",
      "Val Loss: 0.7435, Accuracy: 0.5000, F1: 0.6094\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 158/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.24it/s, loss=0.694]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/1000, Time: 0.03s\n",
      "Train Loss: 0.6939\n",
      "Val Loss: 0.7435, Accuracy: 0.4950, F1: 0.6070\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 159/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 54.00it/s, loss=0.721]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/1000, Time: 0.03s\n",
      "Train Loss: 0.7209\n",
      "Val Loss: 0.7433, Accuracy: 0.5000, F1: 0.6094\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 160/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 45.43it/s, loss=0.703]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1000, Time: 0.04s\n",
      "Train Loss: 0.7025\n",
      "Val Loss: 0.7433, Accuracy: 0.5000, F1: 0.6094\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 161/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.61it/s, loss=0.694]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/1000, Time: 0.03s\n",
      "Train Loss: 0.6943\n",
      "Val Loss: 0.7435, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 162/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.69it/s, loss=0.635]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/1000, Time: 0.03s\n",
      "Train Loss: 0.6350\n",
      "Val Loss: 0.7437, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 163/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.95it/s, loss=0.77]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000, Time: 0.03s\n",
      "Train Loss: 0.7702\n",
      "Val Loss: 0.7435, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 164/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 54.01it/s, loss=0.78]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/1000, Time: 0.03s\n",
      "Train Loss: 0.7802\n",
      "Val Loss: 0.7434, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 165/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.54it/s, loss=0.744]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/1000, Time: 0.03s\n",
      "Train Loss: 0.7443\n",
      "Val Loss: 0.7435, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 166/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.66it/s, loss=0.71]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/1000, Time: 0.03s\n",
      "Train Loss: 0.7099\n",
      "Val Loss: 0.7432, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 167/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 50.68it/s, loss=0.699]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176/1000, Time: 0.03s\n",
      "Train Loss: 0.6993\n",
      "Val Loss: 0.7433, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 168/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.86it/s, loss=0.791]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/1000, Time: 0.04s\n",
      "Train Loss: 0.7913\n",
      "Val Loss: 0.7432, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 169/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 42.32it/s, loss=0.774]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/1000, Time: 0.04s\n",
      "Train Loss: 0.7741\n",
      "Val Loss: 0.7440, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 170/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.97it/s, loss=0.81]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/1000, Time: 0.03s\n",
      "Train Loss: 0.8101\n",
      "Val Loss: 0.7435, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 171/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.25it/s, loss=0.766]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/1000, Time: 0.03s\n",
      "Train Loss: 0.7663\n",
      "Val Loss: 0.7431, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 172/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.51it/s, loss=0.825]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/1000, Time: 0.03s\n",
      "Train Loss: 0.8253\n",
      "Val Loss: 0.7434, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 173/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.75it/s, loss=0.702]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182/1000, Time: 0.03s\n",
      "Train Loss: 0.7021\n",
      "Val Loss: 0.7434, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 174/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 60.56it/s, loss=0.716]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/1000, Time: 0.03s\n",
      "Train Loss: 0.7162\n",
      "Val Loss: 0.7435, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 175/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 57.06it/s, loss=0.871]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/1000, Time: 0.03s\n",
      "Train Loss: 0.8713\n",
      "Val Loss: 0.7434, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 176/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 57.06it/s, loss=0.737]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185/1000, Time: 0.03s\n",
      "Train Loss: 0.7369\n",
      "Val Loss: 0.7435, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 177/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 53.97it/s, loss=0.654]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186/1000, Time: 0.03s\n",
      "Train Loss: 0.6537\n",
      "Val Loss: 0.7437, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 178/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 53.99it/s, loss=0.739]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187/1000, Time: 0.03s\n",
      "Train Loss: 0.7387\n",
      "Val Loss: 0.7441, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 179/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 53.98it/s, loss=0.702]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/1000, Time: 0.03s\n",
      "Train Loss: 0.7019\n",
      "Val Loss: 0.7440, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 180/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 57.09it/s, loss=0.721]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/1000, Time: 0.03s\n",
      "Train Loss: 0.7210\n",
      "Val Loss: 0.7443, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 181/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.97it/s, loss=0.719]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/1000, Time: 0.03s\n",
      "Train Loss: 0.7187\n",
      "Val Loss: 0.7438, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 182/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.57it/s, loss=0.724]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191/1000, Time: 0.03s\n",
      "Train Loss: 0.7245\n",
      "Val Loss: 0.7439, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 183/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 58.80it/s, loss=0.729]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192/1000, Time: 0.03s\n",
      "Train Loss: 0.7294\n",
      "Val Loss: 0.7437, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 184/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.50it/s, loss=0.776]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/1000, Time: 0.03s\n",
      "Train Loss: 0.7764\n",
      "Val Loss: 0.7436, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 185/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.93it/s, loss=0.787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194/1000, Time: 0.03s\n",
      "Train Loss: 0.7870\n",
      "Val Loss: 0.7438, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 186/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 53.99it/s, loss=0.664]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195/1000, Time: 0.03s\n",
      "Train Loss: 0.6642\n",
      "Val Loss: 0.7441, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 187/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 53.98it/s, loss=0.702]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196/1000, Time: 0.03s\n",
      "Train Loss: 0.7015\n",
      "Val Loss: 0.7443, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 188/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.48it/s, loss=0.874]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197/1000, Time: 0.03s\n",
      "Train Loss: 0.8736\n",
      "Val Loss: 0.7443, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 189/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.55it/s, loss=0.807]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/1000, Time: 0.03s\n",
      "Train Loss: 0.8066\n",
      "Val Loss: 0.7441, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 190/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 54.00it/s, loss=0.794]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/1000, Time: 0.03s\n",
      "Train Loss: 0.7938\n",
      "Val Loss: 0.7441, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 191/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 37.69it/s, loss=0.705]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/1000, Time: 0.04s\n",
      "Train Loss: 0.7052\n",
      "Val Loss: 0.7440, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 192/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 39.66it/s, loss=0.74]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201/1000, Time: 0.04s\n",
      "Train Loss: 0.7400\n",
      "Val Loss: 0.7439, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 193/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.50it/s, loss=0.706]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202/1000, Time: 0.03s\n",
      "Train Loss: 0.7058\n",
      "Val Loss: 0.7441, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 194/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 45.41it/s, loss=0.764]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 203/1000, Time: 0.03s\n",
      "Train Loss: 0.7638\n",
      "Val Loss: 0.7443, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 195/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 39.18it/s, loss=0.655]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 204/1000, Time: 0.04s\n",
      "Train Loss: 0.6547\n",
      "Val Loss: 0.7441, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 196/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.96it/s, loss=0.747]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 205/1000, Time: 0.03s\n",
      "Train Loss: 0.7467\n",
      "Val Loss: 0.7440, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 197/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.96it/s, loss=0.682]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 206/1000, Time: 0.03s\n",
      "Train Loss: 0.6815\n",
      "Val Loss: 0.7435, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 198/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.93it/s, loss=0.752]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 207/1000, Time: 0.03s\n",
      "Train Loss: 0.7521\n",
      "Val Loss: 0.7434, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 199/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 36.33it/s, loss=0.778]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208/1000, Time: 0.05s\n",
      "Train Loss: 0.7775\n",
      "Val Loss: 0.7436, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 200/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 45.43it/s, loss=0.742]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209/1000, Time: 0.04s\n",
      "Train Loss: 0.7423\n",
      "Val Loss: 0.7435, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 201/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.70it/s, loss=0.668]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 210/1000, Time: 0.03s\n",
      "Train Loss: 0.6675\n",
      "Val Loss: 0.7438, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 202/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.92it/s, loss=0.701]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211/1000, Time: 0.03s\n",
      "Train Loss: 0.7014\n",
      "Val Loss: 0.7436, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 203/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.97it/s, loss=0.667]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 212/1000, Time: 0.03s\n",
      "Train Loss: 0.6669\n",
      "Val Loss: 0.7437, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 204/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 45.42it/s, loss=0.712]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213/1000, Time: 0.04s\n",
      "Train Loss: 0.7117\n",
      "Val Loss: 0.7436, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 205/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 32.75it/s, loss=0.721]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 214/1000, Time: 0.05s\n",
      "Train Loss: 0.7209\n",
      "Val Loss: 0.7434, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 206/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.24it/s, loss=0.736]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215/1000, Time: 0.03s\n",
      "Train Loss: 0.7362\n",
      "Val Loss: 0.7438, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 207/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 57.11it/s, loss=0.708]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216/1000, Time: 0.03s\n",
      "Train Loss: 0.7080\n",
      "Val Loss: 0.7435, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 208/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 44.42it/s, loss=0.669]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/1000, Time: 0.03s\n",
      "Train Loss: 0.6688\n",
      "Val Loss: 0.7439, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 209/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.59it/s, loss=0.73]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218/1000, Time: 0.03s\n",
      "Train Loss: 0.7297\n",
      "Val Loss: 0.7441, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 210/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.82it/s, loss=0.748]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 219/1000, Time: 0.03s\n",
      "Train Loss: 0.7479\n",
      "Val Loss: 0.7438, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 211/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.93it/s, loss=0.743]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/1000, Time: 0.03s\n",
      "Train Loss: 0.7426\n",
      "Val Loss: 0.7441, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 212/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.74it/s, loss=0.745]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/1000, Time: 0.04s\n",
      "Train Loss: 0.7450\n",
      "Val Loss: 0.7443, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 213/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.50it/s, loss=0.706]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222/1000, Time: 0.03s\n",
      "Train Loss: 0.7063\n",
      "Val Loss: 0.7436, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 214/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.70it/s, loss=0.778]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/1000, Time: 0.03s\n",
      "Train Loss: 0.7783\n",
      "Val Loss: 0.7438, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 215/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.75it/s, loss=0.765]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/1000, Time: 0.03s\n",
      "Train Loss: 0.7648\n",
      "Val Loss: 0.7436, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 216/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.55it/s, loss=0.701]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000, Time: 0.03s\n",
      "Train Loss: 0.7012\n",
      "Val Loss: 0.7437, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 217/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.61it/s, loss=0.694]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226/1000, Time: 0.03s\n",
      "Train Loss: 0.6941\n",
      "Val Loss: 0.7438, Accuracy: 0.4900, F1: 0.5952\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 218/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 56.73it/s, loss=0.718]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 227/1000, Time: 0.03s\n",
      "Train Loss: 0.7180\n",
      "Val Loss: 0.7438, Accuracy: 0.4900, F1: 0.5952\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 219/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 53.92it/s, loss=0.695]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 228/1000, Time: 0.03s\n",
      "Train Loss: 0.6948\n",
      "Val Loss: 0.7441, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 220/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 53.99it/s, loss=0.717]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000, Time: 0.03s\n",
      "Train Loss: 0.7168\n",
      "Val Loss: 0.7442, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 221/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.14it/s, loss=0.739]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000, Time: 0.03s\n",
      "Train Loss: 0.7390\n",
      "Val Loss: 0.7444, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 222/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 44.39it/s, loss=0.782]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231/1000, Time: 0.04s\n",
      "Train Loss: 0.7822\n",
      "Val Loss: 0.7444, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 223/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 57.09it/s, loss=0.797]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232/1000, Time: 0.03s\n",
      "Train Loss: 0.7969\n",
      "Val Loss: 0.7444, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 224/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.25it/s, loss=0.738]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/1000, Time: 0.03s\n",
      "Train Loss: 0.7376\n",
      "Val Loss: 0.7444, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 225/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.60it/s, loss=0.679]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234/1000, Time: 0.03s\n",
      "Train Loss: 0.6787\n",
      "Val Loss: 0.7442, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 226/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.94it/s, loss=0.743]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/1000, Time: 0.03s\n",
      "Train Loss: 0.7427\n",
      "Val Loss: 0.7441, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 227/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 54.02it/s, loss=0.764]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236/1000, Time: 0.03s\n",
      "Train Loss: 0.7640\n",
      "Val Loss: 0.7440, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 228/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.92it/s, loss=0.755]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237/1000, Time: 0.03s\n",
      "Train Loss: 0.7553\n",
      "Val Loss: 0.7437, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 229/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 54.01it/s, loss=0.75]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/1000, Time: 0.03s\n",
      "Train Loss: 0.7502\n",
      "Val Loss: 0.7433, Accuracy: 0.4850, F1: 0.5929\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 230/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.98it/s, loss=0.702]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/1000, Time: 0.03s\n",
      "Train Loss: 0.7023\n",
      "Val Loss: 0.7433, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 231/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.59it/s, loss=0.684]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240/1000, Time: 0.03s\n",
      "Train Loss: 0.6841\n",
      "Val Loss: 0.7432, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 232/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.58it/s, loss=0.805]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/1000, Time: 0.04s\n",
      "Train Loss: 0.8054\n",
      "Val Loss: 0.7436, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 233/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.73it/s, loss=0.755]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 242/1000, Time: 0.04s\n",
      "Train Loss: 0.7549\n",
      "Val Loss: 0.7433, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 234/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 45.42it/s, loss=0.749]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 243/1000, Time: 0.04s\n",
      "Train Loss: 0.7485\n",
      "Val Loss: 0.7428, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 235/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.58it/s, loss=0.771]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 244/1000, Time: 0.03s\n",
      "Train Loss: 0.7715\n",
      "Val Loss: 0.7427, Accuracy: 0.4850, F1: 0.5929\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 236/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.73it/s, loss=0.74]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245/1000, Time: 0.03s\n",
      "Train Loss: 0.7401\n",
      "Val Loss: 0.7432, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 237/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.59it/s, loss=0.689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 246/1000, Time: 0.03s\n",
      "Train Loss: 0.6889\n",
      "Val Loss: 0.7430, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 238/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.98it/s, loss=0.767]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 247/1000, Time: 0.03s\n",
      "Train Loss: 0.7668\n",
      "Val Loss: 0.7425, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 239/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.97it/s, loss=0.74]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 248/1000, Time: 0.03s\n",
      "Train Loss: 0.7397\n",
      "Val Loss: 0.7426, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 240/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 46.55it/s, loss=0.743]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249/1000, Time: 0.04s\n",
      "Train Loss: 0.7433\n",
      "Val Loss: 0.7428, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 241/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.59it/s, loss=0.823]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250/1000, Time: 0.04s\n",
      "Train Loss: 0.8225\n",
      "Val Loss: 0.7431, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 242/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 46.49it/s, loss=0.695]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251/1000, Time: 0.03s\n",
      "Train Loss: 0.6947\n",
      "Val Loss: 0.7429, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 243/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.74it/s, loss=0.749]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 252/1000, Time: 0.03s\n",
      "Train Loss: 0.7495\n",
      "Val Loss: 0.7431, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 244/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 44.86it/s, loss=0.769]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 253/1000, Time: 0.04s\n",
      "Train Loss: 0.7689\n",
      "Val Loss: 0.7435, Accuracy: 0.4900, F1: 0.5952\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 245/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.56it/s, loss=0.782]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 254/1000, Time: 0.03s\n",
      "Train Loss: 0.7819\n",
      "Val Loss: 0.7436, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 246/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.75it/s, loss=0.738]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 255/1000, Time: 0.03s\n",
      "Train Loss: 0.7377\n",
      "Val Loss: 0.7433, Accuracy: 0.4900, F1: 0.5952\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 247/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 42.51it/s, loss=0.715]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 256/1000, Time: 0.04s\n",
      "Train Loss: 0.7146\n",
      "Val Loss: 0.7436, Accuracy: 0.4900, F1: 0.5952\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 248/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.18it/s, loss=0.726]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 257/1000, Time: 0.03s\n",
      "Train Loss: 0.7262\n",
      "Val Loss: 0.7438, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 249/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.97it/s, loss=0.664]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 258/1000, Time: 0.03s\n",
      "Train Loss: 0.6636\n",
      "Val Loss: 0.7439, Accuracy: 0.4900, F1: 0.5952\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 250/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.58it/s, loss=0.726]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259/1000, Time: 0.03s\n",
      "Train Loss: 0.7264\n",
      "Val Loss: 0.7439, Accuracy: 0.4900, F1: 0.5952\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 251/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.98it/s, loss=0.753]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 260/1000, Time: 0.03s\n",
      "Train Loss: 0.7525\n",
      "Val Loss: 0.7438, Accuracy: 0.4900, F1: 0.5952\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 252/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.95it/s, loss=0.748]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 261/1000, Time: 0.03s\n",
      "Train Loss: 0.7475\n",
      "Val Loss: 0.7438, Accuracy: 0.4900, F1: 0.5952\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 253/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.97it/s, loss=0.801]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 262/1000, Time: 0.03s\n",
      "Train Loss: 0.8006\n",
      "Val Loss: 0.7437, Accuracy: 0.4900, F1: 0.5952\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 254/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 46.46it/s, loss=0.724]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 263/1000, Time: 0.03s\n",
      "Train Loss: 0.7240\n",
      "Val Loss: 0.7435, Accuracy: 0.4900, F1: 0.5952\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 255/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.73it/s, loss=0.717]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 264/1000, Time: 0.04s\n",
      "Train Loss: 0.7166\n",
      "Val Loss: 0.7440, Accuracy: 0.4900, F1: 0.5952\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 256/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 45.40it/s, loss=0.771]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 265/1000, Time: 0.04s\n",
      "Train Loss: 0.7715\n",
      "Val Loss: 0.7440, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 257/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.25it/s, loss=0.75]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 266/1000, Time: 0.03s\n",
      "Train Loss: 0.7501\n",
      "Val Loss: 0.7438, Accuracy: 0.5000, F1: 0.6094\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 258/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.97it/s, loss=0.659]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 267/1000, Time: 0.03s\n",
      "Train Loss: 0.6592\n",
      "Val Loss: 0.7436, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 259/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 45.42it/s, loss=0.697]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 268/1000, Time: 0.04s\n",
      "Train Loss: 0.6971\n",
      "Val Loss: 0.7435, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 260/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 46.22it/s, loss=0.789]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269/1000, Time: 0.04s\n",
      "Train Loss: 0.7895\n",
      "Val Loss: 0.7436, Accuracy: 0.5000, F1: 0.6094\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 261/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 46.48it/s, loss=0.713]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270/1000, Time: 0.04s\n",
      "Train Loss: 0.7129\n",
      "Val Loss: 0.7436, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 262/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 43.45it/s, loss=0.689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271/1000, Time: 0.04s\n",
      "Train Loss: 0.6892\n",
      "Val Loss: 0.7439, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 263/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 40.78it/s, loss=0.724]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 272/1000, Time: 0.04s\n",
      "Train Loss: 0.7238\n",
      "Val Loss: 0.7434, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 264/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 42.52it/s, loss=0.85]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 273/1000, Time: 0.04s\n",
      "Train Loss: 0.8504\n",
      "Val Loss: 0.7438, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 265/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 44.42it/s, loss=0.757]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 274/1000, Time: 0.04s\n",
      "Train Loss: 0.7568\n",
      "Val Loss: 0.7436, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 266/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 43.46it/s, loss=0.674]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275/1000, Time: 0.04s\n",
      "Train Loss: 0.6742\n",
      "Val Loss: 0.7438, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 267/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 43.46it/s, loss=0.721]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276/1000, Time: 0.04s\n",
      "Train Loss: 0.7215\n",
      "Val Loss: 0.7439, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 268/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 39.97it/s, loss=0.757]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277/1000, Time: 0.04s\n",
      "Train Loss: 0.7569\n",
      "Val Loss: 0.7438, Accuracy: 0.4950, F1: 0.5976\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 269/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 43.45it/s, loss=0.688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 278/1000, Time: 0.04s\n",
      "Train Loss: 0.6880\n",
      "Val Loss: 0.7439, Accuracy: 0.4900, F1: 0.5952\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 270/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 44.39it/s, loss=0.697]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 279/1000, Time: 0.04s\n",
      "Train Loss: 0.6968\n",
      "Val Loss: 0.7440, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 271/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 40.78it/s, loss=0.817]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/1000, Time: 0.04s\n",
      "Train Loss: 0.8172\n",
      "Val Loss: 0.7438, Accuracy: 0.4900, F1: 0.5952\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 272/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 43.46it/s, loss=0.756]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/1000, Time: 0.04s\n",
      "Train Loss: 0.7563\n",
      "Val Loss: 0.7441, Accuracy: 0.4900, F1: 0.5952\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 273/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.65it/s, loss=0.684]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 282/1000, Time: 0.04s\n",
      "Train Loss: 0.6837\n",
      "Val Loss: 0.7444, Accuracy: 0.4900, F1: 0.5952\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 274/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.59it/s, loss=0.791]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283/1000, Time: 0.04s\n",
      "Train Loss: 0.7906\n",
      "Val Loss: 0.7440, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 275/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 46.47it/s, loss=0.788]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284/1000, Time: 0.03s\n",
      "Train Loss: 0.7884\n",
      "Val Loss: 0.7438, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 276/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.65it/s, loss=0.791]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 285/1000, Time: 0.04s\n",
      "Train Loss: 0.7907\n",
      "Val Loss: 0.7440, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 277/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.97it/s, loss=0.721]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000, Time: 0.03s\n",
      "Train Loss: 0.7206\n",
      "Val Loss: 0.7438, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 278/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.39it/s, loss=0.73]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 287/1000, Time: 0.03s\n",
      "Train Loss: 0.7299\n",
      "Val Loss: 0.7443, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 279/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.72it/s, loss=0.741]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 288/1000, Time: 0.04s\n",
      "Train Loss: 0.7413\n",
      "Val Loss: 0.7437, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 280/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 39.97it/s, loss=0.712]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289/1000, Time: 0.04s\n",
      "Train Loss: 0.7119\n",
      "Val Loss: 0.7434, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 281/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.73it/s, loss=0.744]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290/1000, Time: 0.04s\n",
      "Train Loss: 0.7437\n",
      "Val Loss: 0.7434, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 282/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 43.46it/s, loss=0.701]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/1000, Time: 0.04s\n",
      "Train Loss: 0.7011\n",
      "Val Loss: 0.7433, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 283/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 39.98it/s, loss=0.779]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 292/1000, Time: 0.04s\n",
      "Train Loss: 0.7790\n",
      "Val Loss: 0.7433, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 284/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.76it/s, loss=0.748]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/1000, Time: 0.03s\n",
      "Train Loss: 0.7484\n",
      "Val Loss: 0.7436, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 285/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 41.62it/s, loss=0.741]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 294/1000, Time: 0.04s\n",
      "Train Loss: 0.7407\n",
      "Val Loss: 0.7440, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 286/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 45.42it/s, loss=0.749]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295/1000, Time: 0.04s\n",
      "Train Loss: 0.7486\n",
      "Val Loss: 0.7439, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 287/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 44.39it/s, loss=0.658]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/1000, Time: 0.04s\n",
      "Train Loss: 0.6579\n",
      "Val Loss: 0.7438, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 288/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 43.99it/s, loss=0.772]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/1000, Time: 0.04s\n",
      "Train Loss: 0.7717\n",
      "Val Loss: 0.7438, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 289/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 45.42it/s, loss=0.755]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298/1000, Time: 0.03s\n",
      "Train Loss: 0.7555\n",
      "Val Loss: 0.7441, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 290/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.56it/s, loss=0.781]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/1000, Time: 0.04s\n",
      "Train Loss: 0.7807\n",
      "Val Loss: 0.7439, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 291/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 46.48it/s, loss=0.724]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/1000, Time: 0.04s\n",
      "Train Loss: 0.7241\n",
      "Val Loss: 0.7438, Accuracy: 0.5000, F1: 0.6063\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 292/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 45.42it/s, loss=0.749]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/1000, Time: 0.04s\n",
      "Train Loss: 0.7493\n",
      "Val Loss: 0.7436, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 293/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 45.42it/s, loss=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 302/1000, Time: 0.04s\n",
      "Train Loss: 0.6829\n",
      "Val Loss: 0.7433, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 294/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 41.62it/s, loss=0.744]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 303/1000, Time: 0.04s\n",
      "Train Loss: 0.7444\n",
      "Val Loss: 0.7437, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 295/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.73it/s, loss=0.771]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304/1000, Time: 0.03s\n",
      "Train Loss: 0.7713\n",
      "Val Loss: 0.7438, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 296/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.98it/s, loss=0.707]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 305/1000, Time: 0.04s\n",
      "Train Loss: 0.7072\n",
      "Val Loss: 0.7441, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 297/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.75it/s, loss=0.744]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 306/1000, Time: 0.03s\n",
      "Train Loss: 0.7439\n",
      "Val Loss: 0.7441, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 298/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.51it/s, loss=0.726]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 307/1000, Time: 0.03s\n",
      "Train Loss: 0.7259\n",
      "Val Loss: 0.7438, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 299/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 54.01it/s, loss=0.723]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 308/1000, Time: 0.03s\n",
      "Train Loss: 0.7231\n",
      "Val Loss: 0.7439, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 300/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.52it/s, loss=0.755]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/1000, Time: 0.03s\n",
      "Train Loss: 0.7551\n",
      "Val Loss: 0.7441, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 301/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 54.47it/s, loss=0.765]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 310/1000, Time: 0.03s\n",
      "Train Loss: 0.7652\n",
      "Val Loss: 0.7444, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 302/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 57.12it/s, loss=0.709]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 311/1000, Time: 0.03s\n",
      "Train Loss: 0.7092\n",
      "Val Loss: 0.7443, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 303/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 57.03it/s, loss=0.759]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 312/1000, Time: 0.03s\n",
      "Train Loss: 0.7594\n",
      "Val Loss: 0.7442, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 304/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.74it/s, loss=0.732]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 313/1000, Time: 0.03s\n",
      "Train Loss: 0.7316\n",
      "Val Loss: 0.7442, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 305/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.74it/s, loss=0.791]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 314/1000, Time: 0.03s\n",
      "Train Loss: 0.7907\n",
      "Val Loss: 0.7440, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 306/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.23it/s, loss=0.706]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 315/1000, Time: 0.03s\n",
      "Train Loss: 0.7063\n",
      "Val Loss: 0.7439, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 307/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.25it/s, loss=0.675]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 316/1000, Time: 0.03s\n",
      "Train Loss: 0.6746\n",
      "Val Loss: 0.7440, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 308/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.58it/s, loss=0.67]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317/1000, Time: 0.03s\n",
      "Train Loss: 0.6700\n",
      "Val Loss: 0.7437, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 309/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.26it/s, loss=0.694]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 318/1000, Time: 0.03s\n",
      "Train Loss: 0.6942\n",
      "Val Loss: 0.7432, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 310/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 57.12it/s, loss=0.718]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 319/1000, Time: 0.03s\n",
      "Train Loss: 0.7180\n",
      "Val Loss: 0.7432, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 311/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 53.99it/s, loss=0.708]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 320/1000, Time: 0.03s\n",
      "Train Loss: 0.7085\n",
      "Val Loss: 0.7435, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 312/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.55it/s, loss=0.732]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 321/1000, Time: 0.03s\n",
      "Train Loss: 0.7318\n",
      "Val Loss: 0.7436, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 313/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 57.10it/s, loss=0.728]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 322/1000, Time: 0.03s\n",
      "Train Loss: 0.7276\n",
      "Val Loss: 0.7435, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 314/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.60it/s, loss=0.706]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 323/1000, Time: 0.03s\n",
      "Train Loss: 0.7063\n",
      "Val Loss: 0.7436, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 315/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.52it/s, loss=0.816]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 324/1000, Time: 0.03s\n",
      "Train Loss: 0.8155\n",
      "Val Loss: 0.7434, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 316/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.46it/s, loss=0.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 325/1000, Time: 0.03s\n",
      "Train Loss: 0.8300\n",
      "Val Loss: 0.7441, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 317/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 53.43it/s, loss=0.737]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 326/1000, Time: 0.03s\n",
      "Train Loss: 0.7374\n",
      "Val Loss: 0.7441, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 318/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 53.97it/s, loss=0.667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 327/1000, Time: 0.03s\n",
      "Train Loss: 0.6669\n",
      "Val Loss: 0.7440, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 319/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.94it/s, loss=0.743]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 328/1000, Time: 0.03s\n",
      "Train Loss: 0.7431\n",
      "Val Loss: 0.7439, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 320/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 57.07it/s, loss=0.695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329/1000, Time: 0.03s\n",
      "Train Loss: 0.6950\n",
      "Val Loss: 0.7444, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 321/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.50it/s, loss=0.713]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 330/1000, Time: 0.03s\n",
      "Train Loss: 0.7133\n",
      "Val Loss: 0.7444, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 322/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 58.80it/s, loss=0.736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331/1000, Time: 0.03s\n",
      "Train Loss: 0.7362\n",
      "Val Loss: 0.7446, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 323/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 53.99it/s, loss=0.784]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 332/1000, Time: 0.03s\n",
      "Train Loss: 0.7838\n",
      "Val Loss: 0.7434, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 324/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 58.71it/s, loss=0.732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 333/1000, Time: 0.03s\n",
      "Train Loss: 0.7318\n",
      "Val Loss: 0.7435, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 325/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.50it/s, loss=0.76]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 334/1000, Time: 0.03s\n",
      "Train Loss: 0.7602\n",
      "Val Loss: 0.7436, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 326/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.58it/s, loss=0.65]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 335/1000, Time: 0.03s\n",
      "Train Loss: 0.6495\n",
      "Val Loss: 0.7432, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 327/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 56.62it/s, loss=0.733]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336/1000, Time: 0.03s\n",
      "Train Loss: 0.7326\n",
      "Val Loss: 0.7436, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 328/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 54.00it/s, loss=0.738]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/1000, Time: 0.03s\n",
      "Train Loss: 0.7376\n",
      "Val Loss: 0.7433, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 329/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 54.03it/s, loss=0.791]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 338/1000, Time: 0.03s\n",
      "Train Loss: 0.7906\n",
      "Val Loss: 0.7437, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 330/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 57.09it/s, loss=0.806]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 339/1000, Time: 0.03s\n",
      "Train Loss: 0.8061\n",
      "Val Loss: 0.7438, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 331/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.52it/s, loss=0.796]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 340/1000, Time: 0.03s\n",
      "Train Loss: 0.7964\n",
      "Val Loss: 0.7442, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 332/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 60.56it/s, loss=0.743]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 341/1000, Time: 0.03s\n",
      "Train Loss: 0.7432\n",
      "Val Loss: 0.7444, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 333/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 54.01it/s, loss=0.804]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 342/1000, Time: 0.03s\n",
      "Train Loss: 0.8039\n",
      "Val Loss: 0.7444, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 334/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.57it/s, loss=0.744]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000, Time: 0.03s\n",
      "Train Loss: 0.7443\n",
      "Val Loss: 0.7444, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 335/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.52it/s, loss=0.743]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 344/1000, Time: 0.03s\n",
      "Train Loss: 0.7434\n",
      "Val Loss: 0.7444, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 336/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 53.99it/s, loss=0.819]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 345/1000, Time: 0.03s\n",
      "Train Loss: 0.8190\n",
      "Val Loss: 0.7445, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 337/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 58.76it/s, loss=0.786]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 346/1000, Time: 0.03s\n",
      "Train Loss: 0.7859\n",
      "Val Loss: 0.7444, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 338/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 44.40it/s, loss=0.732]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 347/1000, Time: 0.04s\n",
      "Train Loss: 0.7324\n",
      "Val Loss: 0.7447, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 339/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 53.97it/s, loss=0.74]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 348/1000, Time: 0.03s\n",
      "Train Loss: 0.7402\n",
      "Val Loss: 0.7448, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 340/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 53.92it/s, loss=0.761]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/1000, Time: 0.03s\n",
      "Train Loss: 0.7615\n",
      "Val Loss: 0.7441, Accuracy: 0.5000, F1: 0.6094\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 341/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.53it/s, loss=0.723]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350/1000, Time: 0.03s\n",
      "Train Loss: 0.7233\n",
      "Val Loss: 0.7444, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 342/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.95it/s, loss=0.714]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 351/1000, Time: 0.03s\n",
      "Train Loss: 0.7139\n",
      "Val Loss: 0.7444, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 343/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.59it/s, loss=0.703]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 352/1000, Time: 0.03s\n",
      "Train Loss: 0.7033\n",
      "Val Loss: 0.7443, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 344/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 53.99it/s, loss=0.713]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 353/1000, Time: 0.03s\n",
      "Train Loss: 0.7132\n",
      "Val Loss: 0.7442, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 345/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.53it/s, loss=0.784]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354/1000, Time: 0.03s\n",
      "Train Loss: 0.7838\n",
      "Val Loss: 0.7444, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 346/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.57it/s, loss=0.718]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 355/1000, Time: 0.03s\n",
      "Train Loss: 0.7184\n",
      "Val Loss: 0.7447, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 347/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.52it/s, loss=0.689]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 356/1000, Time: 0.03s\n",
      "Train Loss: 0.6886\n",
      "Val Loss: 0.7452, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 348/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.91it/s, loss=0.824]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 357/1000, Time: 0.03s\n",
      "Train Loss: 0.8241\n",
      "Val Loss: 0.7456, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 349/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.65it/s, loss=0.718]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 358/1000, Time: 0.03s\n",
      "Train Loss: 0.7180\n",
      "Val Loss: 0.7455, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 350/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.93it/s, loss=0.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359/1000, Time: 0.03s\n",
      "Train Loss: 0.6996\n",
      "Val Loss: 0.7455, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 351/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.19it/s, loss=0.771]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360/1000, Time: 0.03s\n",
      "Train Loss: 0.7710\n",
      "Val Loss: 0.7454, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 352/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.58it/s, loss=0.711]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/1000, Time: 0.03s\n",
      "Train Loss: 0.7114\n",
      "Val Loss: 0.7453, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 353/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.49it/s, loss=0.748]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 362/1000, Time: 0.03s\n",
      "Train Loss: 0.7484\n",
      "Val Loss: 0.7454, Accuracy: 0.4850, F1: 0.5961\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 354/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 57.02it/s, loss=0.697]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 363/1000, Time: 0.03s\n",
      "Train Loss: 0.6967\n",
      "Val Loss: 0.7458, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 355/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 58.78it/s, loss=0.725]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 364/1000, Time: 0.03s\n",
      "Train Loss: 0.7250\n",
      "Val Loss: 0.7454, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 356/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 35.67it/s, loss=0.733]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 365/1000, Time: 0.04s\n",
      "Train Loss: 0.7334\n",
      "Val Loss: 0.7454, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 357/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.57it/s, loss=0.79]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 366/1000, Time: 0.04s\n",
      "Train Loss: 0.7896\n",
      "Val Loss: 0.7454, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 358/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 46.37it/s, loss=0.718]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 367/1000, Time: 0.03s\n",
      "Train Loss: 0.7184\n",
      "Val Loss: 0.7459, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 359/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 46.45it/s, loss=0.83]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 368/1000, Time: 0.04s\n",
      "Train Loss: 0.8296\n",
      "Val Loss: 0.7458, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 360/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 44.84it/s, loss=0.694]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 369/1000, Time: 0.04s\n",
      "Train Loss: 0.6940\n",
      "Val Loss: 0.7459, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 361/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.60it/s, loss=0.747]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 370/1000, Time: 0.03s\n",
      "Train Loss: 0.7466\n",
      "Val Loss: 0.7460, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 362/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.56it/s, loss=0.741]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 371/1000, Time: 0.04s\n",
      "Train Loss: 0.7411\n",
      "Val Loss: 0.7459, Accuracy: 0.4850, F1: 0.5961\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 363/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 39.44it/s, loss=0.698]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 372/1000, Time: 0.04s\n",
      "Train Loss: 0.6985\n",
      "Val Loss: 0.7463, Accuracy: 0.4900, F1: 0.6016\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 364/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 36.61it/s, loss=0.678]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 373/1000, Time: 0.04s\n",
      "Train Loss: 0.6777\n",
      "Val Loss: 0.7457, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 365/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.27it/s, loss=0.838]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 374/1000, Time: 0.03s\n",
      "Train Loss: 0.8381\n",
      "Val Loss: 0.7457, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 366/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.25it/s, loss=0.69]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 375/1000, Time: 0.03s\n",
      "Train Loss: 0.6905\n",
      "Val Loss: 0.7455, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 367/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.50it/s, loss=0.683]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 376/1000, Time: 0.03s\n",
      "Train Loss: 0.6829\n",
      "Val Loss: 0.7449, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 368/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 35.06it/s, loss=0.69]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 377/1000, Time: 0.04s\n",
      "Train Loss: 0.6904\n",
      "Val Loss: 0.7448, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 369/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 58.78it/s, loss=0.659]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 378/1000, Time: 0.03s\n",
      "Train Loss: 0.6595\n",
      "Val Loss: 0.7443, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 370/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 39.95it/s, loss=0.78]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379/1000, Time: 0.04s\n",
      "Train Loss: 0.7802\n",
      "Val Loss: 0.7440, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 371/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 53.18it/s, loss=0.697]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 380/1000, Time: 0.03s\n",
      "Train Loss: 0.6967\n",
      "Val Loss: 0.7442, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 372/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 53.48it/s, loss=0.738]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/1000, Time: 0.03s\n",
      "Train Loss: 0.7379\n",
      "Val Loss: 0.7438, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 373/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 46.47it/s, loss=0.672]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 382/1000, Time: 0.03s\n",
      "Train Loss: 0.6725\n",
      "Val Loss: 0.7436, Accuracy: 0.4900, F1: 0.5952\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 374/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 43.09it/s, loss=0.785]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 383/1000, Time: 0.04s\n",
      "Train Loss: 0.7852\n",
      "Val Loss: 0.7436, Accuracy: 0.4900, F1: 0.5952\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 375/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.61it/s, loss=0.697]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 384/1000, Time: 0.03s\n",
      "Train Loss: 0.6975\n",
      "Val Loss: 0.7434, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 376/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.16it/s, loss=0.7]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 385/1000, Time: 0.03s\n",
      "Train Loss: 0.7002\n",
      "Val Loss: 0.7431, Accuracy: 0.4900, F1: 0.5952\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 377/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 54.00it/s, loss=0.789]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386/1000, Time: 0.03s\n",
      "Train Loss: 0.7894\n",
      "Val Loss: 0.7429, Accuracy: 0.4900, F1: 0.5952\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 378/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 54.02it/s, loss=0.737]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 387/1000, Time: 0.03s\n",
      "Train Loss: 0.7370\n",
      "Val Loss: 0.7428, Accuracy: 0.4900, F1: 0.5952\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 379/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 53.54it/s, loss=0.772]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388/1000, Time: 0.03s\n",
      "Train Loss: 0.7722\n",
      "Val Loss: 0.7427, Accuracy: 0.4900, F1: 0.5952\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 380/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.57it/s, loss=0.708]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389/1000, Time: 0.03s\n",
      "Train Loss: 0.7084\n",
      "Val Loss: 0.7431, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 381/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.54it/s, loss=0.747]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 390/1000, Time: 0.03s\n",
      "Train Loss: 0.7469\n",
      "Val Loss: 0.7430, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 382/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.22it/s, loss=0.752]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/1000, Time: 0.03s\n",
      "Train Loss: 0.7520\n",
      "Val Loss: 0.7433, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 383/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 46.45it/s, loss=0.707]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 392/1000, Time: 0.03s\n",
      "Train Loss: 0.7074\n",
      "Val Loss: 0.7436, Accuracy: 0.4900, F1: 0.5952\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 384/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.59it/s, loss=0.848]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/1000, Time: 0.04s\n",
      "Train Loss: 0.8483\n",
      "Val Loss: 0.7433, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 385/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 46.38it/s, loss=0.71]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 394/1000, Time: 0.03s\n",
      "Train Loss: 0.7101\n",
      "Val Loss: 0.7436, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 386/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 56.96it/s, loss=0.717]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 395/1000, Time: 0.03s\n",
      "Train Loss: 0.7166\n",
      "Val Loss: 0.7440, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 387/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.01it/s, loss=0.778]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396/1000, Time: 0.03s\n",
      "Train Loss: 0.7776\n",
      "Val Loss: 0.7436, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 388/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.58it/s, loss=0.755]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 397/1000, Time: 0.03s\n",
      "Train Loss: 0.7546\n",
      "Val Loss: 0.7437, Accuracy: 0.5000, F1: 0.6063\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 389/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 46.46it/s, loss=0.819]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 398/1000, Time: 0.04s\n",
      "Train Loss: 0.8189\n",
      "Val Loss: 0.7438, Accuracy: 0.5000, F1: 0.6063\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 390/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.21it/s, loss=0.752]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399/1000, Time: 0.03s\n",
      "Train Loss: 0.7521\n",
      "Val Loss: 0.7437, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 391/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 58.76it/s, loss=0.779]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000, Time: 0.03s\n",
      "Train Loss: 0.7794\n",
      "Val Loss: 0.7436, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 392/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.19it/s, loss=0.671]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401/1000, Time: 0.03s\n",
      "Train Loss: 0.6706\n",
      "Val Loss: 0.7435, Accuracy: 0.5000, F1: 0.6063\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 393/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 33.29it/s, loss=0.732]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 402/1000, Time: 0.04s\n",
      "Train Loss: 0.7319\n",
      "Val Loss: 0.7434, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 394/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.58it/s, loss=0.693]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 403/1000, Time: 0.03s\n",
      "Train Loss: 0.6930\n",
      "Val Loss: 0.7435, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 395/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.52it/s, loss=0.7]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 404/1000, Time: 0.03s\n",
      "Train Loss: 0.7003\n",
      "Val Loss: 0.7439, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 396/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 44.79it/s, loss=0.759]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 405/1000, Time: 0.03s\n",
      "Train Loss: 0.7591\n",
      "Val Loss: 0.7440, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 397/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.54it/s, loss=0.732]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 406/1000, Time: 0.03s\n",
      "Train Loss: 0.7316\n",
      "Val Loss: 0.7440, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 398/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 41.60it/s, loss=0.758]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/1000, Time: 0.04s\n",
      "Train Loss: 0.7578\n",
      "Val Loss: 0.7437, Accuracy: 0.5000, F1: 0.6094\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 399/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 44.19it/s, loss=0.751]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 408/1000, Time: 0.03s\n",
      "Train Loss: 0.7508\n",
      "Val Loss: 0.7439, Accuracy: 0.5000, F1: 0.6094\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 400/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 41.49it/s, loss=0.825]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 409/1000, Time: 0.04s\n",
      "Train Loss: 0.8250\n",
      "Val Loss: 0.7443, Accuracy: 0.4950, F1: 0.6070\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 401/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 43.98it/s, loss=0.705]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 410/1000, Time: 0.04s\n",
      "Train Loss: 0.7045\n",
      "Val Loss: 0.7444, Accuracy: 0.5000, F1: 0.6094\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 402/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.59it/s, loss=0.736]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 411/1000, Time: 0.03s\n",
      "Train Loss: 0.7360\n",
      "Val Loss: 0.7443, Accuracy: 0.5000, F1: 0.6094\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 403/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 58.80it/s, loss=0.71]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 412/1000, Time: 0.03s\n",
      "Train Loss: 0.7096\n",
      "Val Loss: 0.7433, Accuracy: 0.5000, F1: 0.6094\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 404/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.96it/s, loss=0.735]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 413/1000, Time: 0.03s\n",
      "Train Loss: 0.7346\n",
      "Val Loss: 0.7434, Accuracy: 0.5000, F1: 0.6094\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 405/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.97it/s, loss=0.737]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 414/1000, Time: 0.04s\n",
      "Train Loss: 0.7368\n",
      "Val Loss: 0.7435, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 406/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 40.79it/s, loss=0.773]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 415/1000, Time: 0.04s\n",
      "Train Loss: 0.7732\n",
      "Val Loss: 0.7436, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 407/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.60it/s, loss=0.762]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 416/1000, Time: 0.03s\n",
      "Train Loss: 0.7617\n",
      "Val Loss: 0.7438, Accuracy: 0.5000, F1: 0.6063\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 408/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 50.90it/s, loss=0.689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 417/1000, Time: 0.03s\n",
      "Train Loss: 0.6891\n",
      "Val Loss: 0.7440, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 409/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 50.00it/s, loss=0.746]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 418/1000, Time: 0.03s\n",
      "Train Loss: 0.7457\n",
      "Val Loss: 0.7442, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 410/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 44.40it/s, loss=0.73]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419/1000, Time: 0.03s\n",
      "Train Loss: 0.7295\n",
      "Val Loss: 0.7441, Accuracy: 0.4900, F1: 0.5952\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 411/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 46.49it/s, loss=0.745]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 420/1000, Time: 0.03s\n",
      "Train Loss: 0.7453\n",
      "Val Loss: 0.7441, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 412/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.27it/s, loss=0.717]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/1000, Time: 0.03s\n",
      "Train Loss: 0.7167\n",
      "Val Loss: 0.7443, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 413/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 58.70it/s, loss=0.743]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 422/1000, Time: 0.03s\n",
      "Train Loss: 0.7435\n",
      "Val Loss: 0.7437, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 414/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.92it/s, loss=0.769]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 423/1000, Time: 0.03s\n",
      "Train Loss: 0.7686\n",
      "Val Loss: 0.7441, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 415/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.53it/s, loss=0.662]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 424/1000, Time: 0.03s\n",
      "Train Loss: 0.6621\n",
      "Val Loss: 0.7440, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 416/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 57.08it/s, loss=0.715]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 425/1000, Time: 0.03s\n",
      "Train Loss: 0.7146\n",
      "Val Loss: 0.7438, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 417/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 35.61it/s, loss=0.698]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 426/1000, Time: 0.04s\n",
      "Train Loss: 0.6976\n",
      "Val Loss: 0.7436, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 418/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 42.48it/s, loss=0.717]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 427/1000, Time: 0.04s\n",
      "Train Loss: 0.7172\n",
      "Val Loss: 0.7439, Accuracy: 0.4900, F1: 0.5952\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 419/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 32.22it/s, loss=0.702]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 428/1000, Time: 0.05s\n",
      "Train Loss: 0.7020\n",
      "Val Loss: 0.7439, Accuracy: 0.4900, F1: 0.5952\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 420/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.61it/s, loss=0.793]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 429/1000, Time: 0.03s\n",
      "Train Loss: 0.7929\n",
      "Val Loss: 0.7442, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 421/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.94it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 430/1000, Time: 0.03s\n",
      "Train Loss: 0.6853\n",
      "Val Loss: 0.7437, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 422/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 54.06it/s, loss=0.678]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 431/1000, Time: 0.03s\n",
      "Train Loss: 0.6779\n",
      "Val Loss: 0.7437, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 423/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.60it/s, loss=0.754]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 432/1000, Time: 0.03s\n",
      "Train Loss: 0.7537\n",
      "Val Loss: 0.7441, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 424/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.55it/s, loss=0.799]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 433/1000, Time: 0.03s\n",
      "Train Loss: 0.7987\n",
      "Val Loss: 0.7439, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 425/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.57it/s, loss=0.772]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 434/1000, Time: 0.03s\n",
      "Train Loss: 0.7721\n",
      "Val Loss: 0.7439, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 426/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 42.49it/s, loss=0.785]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 435/1000, Time: 0.04s\n",
      "Train Loss: 0.7845\n",
      "Val Loss: 0.7439, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 427/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.91it/s, loss=0.679]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 436/1000, Time: 0.03s\n",
      "Train Loss: 0.6792\n",
      "Val Loss: 0.7441, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 428/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 57.11it/s, loss=0.731]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 437/1000, Time: 0.03s\n",
      "Train Loss: 0.7311\n",
      "Val Loss: 0.7443, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 429/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.97it/s, loss=0.638]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 438/1000, Time: 0.03s\n",
      "Train Loss: 0.6375\n",
      "Val Loss: 0.7439, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 430/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 57.51it/s, loss=0.699]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 439/1000, Time: 0.03s\n",
      "Train Loss: 0.6988\n",
      "Val Loss: 0.7443, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 431/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 58.79it/s, loss=0.704]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 440/1000, Time: 0.03s\n",
      "Train Loss: 0.7045\n",
      "Val Loss: 0.7436, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 432/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.97it/s, loss=0.77]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/1000, Time: 0.03s\n",
      "Train Loss: 0.7700\n",
      "Val Loss: 0.7439, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 433/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 57.12it/s, loss=0.723]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 442/1000, Time: 0.03s\n",
      "Train Loss: 0.7235\n",
      "Val Loss: 0.7443, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 434/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 62.50it/s, loss=0.742]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 443/1000, Time: 0.03s\n",
      "Train Loss: 0.7425\n",
      "Val Loss: 0.7443, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 435/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 53.66it/s, loss=0.645]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 444/1000, Time: 0.03s\n",
      "Train Loss: 0.6455\n",
      "Val Loss: 0.7435, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 436/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.93it/s, loss=0.799]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445/1000, Time: 0.03s\n",
      "Train Loss: 0.7987\n",
      "Val Loss: 0.7433, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 437/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.48it/s, loss=0.797]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 446/1000, Time: 0.04s\n",
      "Train Loss: 0.7970\n",
      "Val Loss: 0.7429, Accuracy: 0.4900, F1: 0.5952\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 438/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 43.43it/s, loss=0.732]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 447/1000, Time: 0.03s\n",
      "Train Loss: 0.7318\n",
      "Val Loss: 0.7430, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 439/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 44.42it/s, loss=0.737]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448/1000, Time: 0.04s\n",
      "Train Loss: 0.7368\n",
      "Val Loss: 0.7428, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 440/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 38.43it/s, loss=0.72]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/1000, Time: 0.05s\n",
      "Train Loss: 0.7203\n",
      "Val Loss: 0.7427, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 441/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.59it/s, loss=0.693]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 450/1000, Time: 0.03s\n",
      "Train Loss: 0.6930\n",
      "Val Loss: 0.7430, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 442/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 58.76it/s, loss=0.812]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 451/1000, Time: 0.03s\n",
      "Train Loss: 0.8124\n",
      "Val Loss: 0.7428, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 443/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 53.97it/s, loss=0.694]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 452/1000, Time: 0.03s\n",
      "Train Loss: 0.6943\n",
      "Val Loss: 0.7433, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 444/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 57.11it/s, loss=0.691]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 453/1000, Time: 0.03s\n",
      "Train Loss: 0.6909\n",
      "Val Loss: 0.7436, Accuracy: 0.4900, F1: 0.6016\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 445/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.61it/s, loss=0.78]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 454/1000, Time: 0.03s\n",
      "Train Loss: 0.7805\n",
      "Val Loss: 0.7433, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 446/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 56.60it/s, loss=0.764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455/1000, Time: 0.03s\n",
      "Train Loss: 0.7637\n",
      "Val Loss: 0.7431, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 447/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.22it/s, loss=0.833]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 456/1000, Time: 0.03s\n",
      "Train Loss: 0.8331\n",
      "Val Loss: 0.7433, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 448/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 58.75it/s, loss=0.709]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000, Time: 0.03s\n",
      "Train Loss: 0.7092\n",
      "Val Loss: 0.7437, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 449/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 57.11it/s, loss=0.699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 458/1000, Time: 0.03s\n",
      "Train Loss: 0.6992\n",
      "Val Loss: 0.7437, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 450/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.59it/s, loss=0.741]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 459/1000, Time: 0.03s\n",
      "Train Loss: 0.7408\n",
      "Val Loss: 0.7440, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 451/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.93it/s, loss=0.763]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 460/1000, Time: 0.03s\n",
      "Train Loss: 0.7630\n",
      "Val Loss: 0.7437, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 452/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 46.53it/s, loss=0.761]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 461/1000, Time: 0.03s\n",
      "Train Loss: 0.7606\n",
      "Val Loss: 0.7442, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 453/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 52.61it/s, loss=0.863]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 462/1000, Time: 0.03s\n",
      "Train Loss: 0.8631\n",
      "Val Loss: 0.7434, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 454/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.78it/s, loss=0.694]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 463/1000, Time: 0.03s\n",
      "Train Loss: 0.6939\n",
      "Val Loss: 0.7441, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 455/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 45.96it/s, loss=0.77]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 464/1000, Time: 0.04s\n",
      "Train Loss: 0.7698\n",
      "Val Loss: 0.7442, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 456/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 44.59it/s, loss=0.748]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/1000, Time: 0.04s\n",
      "Train Loss: 0.7483\n",
      "Val Loss: 0.7439, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 457/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 42.47it/s, loss=0.793]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 466/1000, Time: 0.04s\n",
      "Train Loss: 0.7931\n",
      "Val Loss: 0.7444, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 458/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 21.18it/s, loss=0.806]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 467/1000, Time: 0.06s\n",
      "Train Loss: 0.8061\n",
      "Val Loss: 0.7441, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 459/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 31.22it/s, loss=0.779]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 468/1000, Time: 0.05s\n",
      "Train Loss: 0.7794\n",
      "Val Loss: 0.7445, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 460/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.98it/s, loss=0.767]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 469/1000, Time: 0.03s\n",
      "Train Loss: 0.7668\n",
      "Val Loss: 0.7448, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 461/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 44.43it/s, loss=0.787]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 470/1000, Time: 0.03s\n",
      "Train Loss: 0.7872\n",
      "Val Loss: 0.7448, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 462/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 54.03it/s, loss=0.841]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 471/1000, Time: 0.03s\n",
      "Train Loss: 0.8413\n",
      "Val Loss: 0.7446, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 463/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 33.30it/s, loss=0.706]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 472/1000, Time: 0.05s\n",
      "Train Loss: 0.7064\n",
      "Val Loss: 0.7444, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 464/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 40.77it/s, loss=0.735]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 473/1000, Time: 0.04s\n",
      "Train Loss: 0.7347\n",
      "Val Loss: 0.7444, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 465/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 46.46it/s, loss=0.749]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 474/1000, Time: 0.03s\n",
      "Train Loss: 0.7491\n",
      "Val Loss: 0.7447, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 466/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.67it/s, loss=0.647]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/1000, Time: 0.03s\n",
      "Train Loss: 0.6470\n",
      "Val Loss: 0.7446, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 467/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 45.42it/s, loss=0.749]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 476/1000, Time: 0.04s\n",
      "Train Loss: 0.7495\n",
      "Val Loss: 0.7446, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 468/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.49it/s, loss=0.734]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 477/1000, Time: 0.03s\n",
      "Train Loss: 0.7338\n",
      "Val Loss: 0.7440, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 469/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.76it/s, loss=0.684]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 478/1000, Time: 0.04s\n",
      "Train Loss: 0.6840\n",
      "Val Loss: 0.7443, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 470/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.70it/s, loss=0.724]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 479/1000, Time: 0.03s\n",
      "Train Loss: 0.7235\n",
      "Val Loss: 0.7440, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 471/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 42.53it/s, loss=0.693]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 480/1000, Time: 0.04s\n",
      "Train Loss: 0.6932\n",
      "Val Loss: 0.7438, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 472/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.96it/s, loss=0.704]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/1000, Time: 0.03s\n",
      "Train Loss: 0.7040\n",
      "Val Loss: 0.7444, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 473/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 42.52it/s, loss=0.782]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 482/1000, Time: 0.04s\n",
      "Train Loss: 0.7824\n",
      "Val Loss: 0.7444, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 474/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 46.47it/s, loss=0.702]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 483/1000, Time: 0.04s\n",
      "Train Loss: 0.7024\n",
      "Val Loss: 0.7444, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 475/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.95it/s, loss=0.695]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 484/1000, Time: 0.03s\n",
      "Train Loss: 0.6952\n",
      "Val Loss: 0.7442, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 476/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 43.40it/s, loss=0.732]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 485/1000, Time: 0.04s\n",
      "Train Loss: 0.7321\n",
      "Val Loss: 0.7442, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 477/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 47.82it/s, loss=0.704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 486/1000, Time: 0.04s\n",
      "Train Loss: 0.7041\n",
      "Val Loss: 0.7442, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 478/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 48.72it/s, loss=0.788]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 487/1000, Time: 0.03s\n",
      "Train Loss: 0.7883\n",
      "Val Loss: 0.7443, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 479/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 37.65it/s, loss=0.696]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 488/1000, Time: 0.04s\n",
      "Train Loss: 0.6961\n",
      "Val Loss: 0.7445, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 480/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 54.83it/s, loss=0.787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 489/1000, Time: 0.03s\n",
      "Train Loss: 0.7866\n",
      "Val Loss: 0.7447, Accuracy: 0.5000, F1: 0.6063\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 481/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.51it/s, loss=0.714]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 490/1000, Time: 0.03s\n",
      "Train Loss: 0.7141\n",
      "Val Loss: 0.7446, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 482/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.55it/s, loss=0.77]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 491/1000, Time: 0.03s\n",
      "Train Loss: 0.7702\n",
      "Val Loss: 0.7447, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 483/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 45.43it/s, loss=0.707]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 492/1000, Time: 0.03s\n",
      "Train Loss: 0.7072\n",
      "Val Loss: 0.7448, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 484/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.95it/s, loss=0.794]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 493/1000, Time: 0.03s\n",
      "Train Loss: 0.7939\n",
      "Val Loss: 0.7448, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 485/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.93it/s, loss=0.738]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 494/1000, Time: 0.03s\n",
      "Train Loss: 0.7377\n",
      "Val Loss: 0.7450, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 486/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 60.52it/s, loss=0.707]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 495/1000, Time: 0.03s\n",
      "Train Loss: 0.7067\n",
      "Val Loss: 0.7447, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 487/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.21it/s, loss=0.774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496/1000, Time: 0.03s\n",
      "Train Loss: 0.7742\n",
      "Val Loss: 0.7448, Accuracy: 0.4900, F1: 0.6016\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 488/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 55.42it/s, loss=0.752]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 497/1000, Time: 0.03s\n",
      "Train Loss: 0.7525\n",
      "Val Loss: 0.7449, Accuracy: 0.4900, F1: 0.6016\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 489/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.18it/s, loss=0.694]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 498/1000, Time: 0.03s\n",
      "Train Loss: 0.6944\n",
      "Val Loss: 0.7448, Accuracy: 0.4900, F1: 0.6016\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 490/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 54.03it/s, loss=0.777]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499/1000, Time: 0.03s\n",
      "Train Loss: 0.7772\n",
      "Val Loss: 0.7450, Accuracy: 0.4900, F1: 0.6016\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 491/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 54.02it/s, loss=0.742]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/1000, Time: 0.03s\n",
      "Train Loss: 0.7423\n",
      "Val Loss: 0.7450, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 492/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 54.01it/s, loss=0.797]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 501/1000, Time: 0.03s\n",
      "Train Loss: 0.7972\n",
      "Val Loss: 0.7449, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 493/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 49.95it/s, loss=0.66]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 502/1000, Time: 0.03s\n",
      "Train Loss: 0.6597\n",
      "Val Loss: 0.7450, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 494/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.22it/s, loss=0.674]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 503/1000, Time: 0.03s\n",
      "Train Loss: 0.6737\n",
      "Val Loss: 0.7445, Accuracy: 0.5000, F1: 0.6063\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 495/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.23it/s, loss=0.696]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 504/1000, Time: 0.04s\n",
      "Train Loss: 0.6957\n",
      "Val Loss: 0.7442, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 496/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 43.44it/s, loss=0.696]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505/1000, Time: 0.04s\n",
      "Train Loss: 0.6961\n",
      "Val Loss: 0.7442, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 497/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.21it/s, loss=0.811]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 506/1000, Time: 0.03s\n",
      "Train Loss: 0.8112\n",
      "Val Loss: 0.7443, Accuracy: 0.4950, F1: 0.6008\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 498/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 51.21it/s, loss=0.64]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 507/1000, Time: 0.03s\n",
      "Train Loss: 0.6402\n",
      "Val Loss: 0.7441, Accuracy: 0.4850, F1: 0.5961\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 499/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00, 56.74it/s, loss=0.693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 508/1000, Time: 0.03s\n",
      "Train Loss: 0.6929\n",
      "Val Loss: 0.7440, Accuracy: 0.4900, F1: 0.6016\n",
      "Best Val F1: 0.6140 (Epoch 8)\n",
      "Patience: 500/500\n",
      "--------------------------------------------------\n",
      "Early stopping after 508 epochs\n",
      "Test Results:\n",
      "Loss: 0.7771, Accuracy: 0.5000\n",
      "Precision: 0.5000, Recall: 0.8000, F1: 0.6154\n",
      "Confusion Matrix:\n",
      "[[ 4 16]\n",
      " [ 4 16]]\n",
      "Training complete for deep! Best validation F1 score: 0.6140\n"
     ]
    }
   ],
   "source": [
    "print('Deep CNN')\n",
    "deep_model = run_model(config, 'deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT\n",
      "Preparing dataloaders...\n",
      "Feature dimension: 13\n",
      "Initializing vit model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it, loss=0.703]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Time: 1.26s\n",
      "Train Loss: 0.7027\n",
      "Val Loss: 6.7067, Accuracy: 0.5000, F1: 0.0000\n",
      "Best Val F1: 0.0000 (Epoch 1)\n",
      "Patience: 1/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s, loss=6.69]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000, Time: 1.39s\n",
      "Train Loss: 6.6930\n",
      "Val Loss: 12.8519, Accuracy: 0.5000, F1: 0.6667\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 0/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s, loss=12.8]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000, Time: 1.03s\n",
      "Train Loss: 12.7735\n",
      "Val Loss: 1.5208, Accuracy: 0.5000, F1: 0.6667\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 1/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s, loss=1.53]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/1000, Time: 1.03s\n",
      "Train Loss: 1.5293\n",
      "Val Loss: 6.9568, Accuracy: 0.5000, F1: 0.0000\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 2/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s, loss=6.96]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/1000, Time: 1.06s\n",
      "Train Loss: 6.9560\n",
      "Val Loss: 4.2065, Accuracy: 0.5000, F1: 0.0000\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 3/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s, loss=4.21]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/1000, Time: 1.05s\n",
      "Train Loss: 4.2076\n",
      "Val Loss: 0.7003, Accuracy: 0.5000, F1: 0.6667\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 4/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s, loss=0.701]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/1000, Time: 1.07s\n",
      "Train Loss: 0.7014\n",
      "Val Loss: 2.0352, Accuracy: 0.5000, F1: 0.6667\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 5/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s, loss=2.03]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/1000, Time: 1.05s\n",
      "Train Loss: 2.0344\n",
      "Val Loss: 0.7275, Accuracy: 0.5000, F1: 0.6667\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 6/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s, loss=0.726]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/1000, Time: 1.02s\n",
      "Train Loss: 0.7264\n",
      "Val Loss: 0.9764, Accuracy: 0.5000, F1: 0.0000\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 7/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s, loss=0.975]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/1000, Time: 1.03s\n",
      "Train Loss: 0.9751\n",
      "Val Loss: 0.8915, Accuracy: 0.5000, F1: 0.0000\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 8/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s, loss=0.89]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/1000, Time: 1.04s\n",
      "Train Loss: 0.8897\n",
      "Val Loss: 0.6975, Accuracy: 0.5000, F1: 0.6667\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 9/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s, loss=0.695]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/1000, Time: 1.01s\n",
      "Train Loss: 0.6952\n",
      "Val Loss: 0.8698, Accuracy: 0.5000, F1: 0.6667\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 10/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s, loss=0.867]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/1000, Time: 1.04s\n",
      "Train Loss: 0.8667\n",
      "Val Loss: 0.8260, Accuracy: 0.5000, F1: 0.6667\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 11/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s, loss=0.823]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/1000, Time: 1.05s\n",
      "Train Loss: 0.8226\n",
      "Val Loss: 0.6949, Accuracy: 0.5000, F1: 0.6667\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 12/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s, loss=0.691]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/1000, Time: 1.01s\n",
      "Train Loss: 0.6914\n",
      "Val Loss: 0.7079, Accuracy: 0.5000, F1: 0.0000\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 13/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s, loss=0.704]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/1000, Time: 1.05s\n",
      "Train Loss: 0.7043\n",
      "Val Loss: 0.7372, Accuracy: 0.5000, F1: 0.0000\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 14/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.733]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/1000, Time: 1.10s\n",
      "Train Loss: 0.7334\n",
      "Val Loss: 0.7353, Accuracy: 0.5000, F1: 0.0000\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 15/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, loss=0.731]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/1000, Time: 1.12s\n",
      "Train Loss: 0.7313\n",
      "Val Loss: 0.7081, Accuracy: 0.5000, F1: 0.0000\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 16/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, loss=0.704]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/1000, Time: 1.12s\n",
      "Train Loss: 0.7038\n",
      "Val Loss: 0.6935, Accuracy: 0.4650, F1: 0.5597\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 17/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, loss=0.689]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/1000, Time: 1.15s\n",
      "Train Loss: 0.6888\n",
      "Val Loss: 0.7068, Accuracy: 0.5000, F1: 0.6667\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 18/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s, loss=0.702]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/1000, Time: 1.30s\n",
      "Train Loss: 0.7017\n",
      "Val Loss: 0.7135, Accuracy: 0.5000, F1: 0.6667\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 19/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:01<00:00,  1.00s/it, loss=0.708]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/1000, Time: 1.32s\n",
      "Train Loss: 0.7081\n",
      "Val Loss: 0.7122, Accuracy: 0.5000, F1: 0.6667\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 20/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s, loss=0.707]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/1000, Time: 1.24s\n",
      "Train Loss: 0.7066\n",
      "Val Loss: 0.7047, Accuracy: 0.5000, F1: 0.6667\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 21/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s, loss=0.699]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/1000, Time: 1.20s\n",
      "Train Loss: 0.6989\n",
      "Val Loss: 0.6968, Accuracy: 0.5000, F1: 0.6667\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 22/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s, loss=0.691]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/1000, Time: 1.18s\n",
      "Train Loss: 0.6909\n",
      "Val Loss: 0.6937, Accuracy: 0.5150, F1: 0.5727\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 23/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, loss=0.688]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/1000, Time: 1.10s\n",
      "Train Loss: 0.6876\n",
      "Val Loss: 0.6963, Accuracy: 0.5000, F1: 0.0000\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 24/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.69]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/1000, Time: 1.10s\n",
      "Train Loss: 0.6900\n",
      "Val Loss: 0.6984, Accuracy: 0.5000, F1: 0.0000\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 25/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, loss=0.692]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/1000, Time: 1.11s\n",
      "Train Loss: 0.6920\n",
      "Val Loss: 0.6997, Accuracy: 0.5000, F1: 0.0000\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 26/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s, loss=0.693]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/1000, Time: 1.24s\n",
      "Train Loss: 0.6932\n",
      "Val Loss: 0.6998, Accuracy: 0.5000, F1: 0.0000\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 27/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s, loss=0.693]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/1000, Time: 1.16s\n",
      "Train Loss: 0.6930\n",
      "Val Loss: 0.6986, Accuracy: 0.5000, F1: 0.0000\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 28/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, loss=0.692]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/1000, Time: 1.17s\n",
      "Train Loss: 0.6917\n",
      "Val Loss: 0.6968, Accuracy: 0.5000, F1: 0.0000\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 29/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.69]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/1000, Time: 1.12s\n",
      "Train Loss: 0.6897\n",
      "Val Loss: 0.6951, Accuracy: 0.5000, F1: 0.0000\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 30/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s, loss=0.688]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/1000, Time: 1.32s\n",
      "Train Loss: 0.6878\n",
      "Val Loss: 0.6945, Accuracy: 0.5000, F1: 0.0000\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 31/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s, loss=0.687]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/1000, Time: 1.22s\n",
      "Train Loss: 0.6871\n",
      "Val Loss: 0.6941, Accuracy: 0.5350, F1: 0.4973\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 32/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s, loss=0.687]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/1000, Time: 1.17s\n",
      "Train Loss: 0.6866\n",
      "Val Loss: 0.6940, Accuracy: 0.5600, F1: 0.5963\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 33/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, loss=0.686]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/1000, Time: 1.13s\n",
      "Train Loss: 0.6863\n",
      "Val Loss: 0.6941, Accuracy: 0.4900, F1: 0.5952\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 34/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, loss=0.686]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/1000, Time: 1.12s\n",
      "Train Loss: 0.6862\n",
      "Val Loss: 0.6943, Accuracy: 0.4850, F1: 0.6113\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 35/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.686]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/1000, Time: 1.11s\n",
      "Train Loss: 0.6864\n",
      "Val Loss: 0.6946, Accuracy: 0.4850, F1: 0.6113\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 36/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s, loss=0.687]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/1000, Time: 1.08s\n",
      "Train Loss: 0.6865\n",
      "Val Loss: 0.6948, Accuracy: 0.4850, F1: 0.6113\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 37/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, loss=0.687]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/1000, Time: 1.09s\n",
      "Train Loss: 0.6866\n",
      "Val Loss: 0.6949, Accuracy: 0.4700, F1: 0.6103\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 38/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, loss=0.687]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/1000, Time: 1.12s\n",
      "Train Loss: 0.6866\n",
      "Val Loss: 0.6949, Accuracy: 0.4650, F1: 0.6081\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 39/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s, loss=0.687]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/1000, Time: 1.06s\n",
      "Train Loss: 0.6866\n",
      "Val Loss: 0.6949, Accuracy: 0.4750, F1: 0.6125\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 40/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, loss=0.687]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/1000, Time: 1.08s\n",
      "Train Loss: 0.6865\n",
      "Val Loss: 0.6949, Accuracy: 0.4800, F1: 0.6090\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 41/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s, loss=0.686]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/1000, Time: 1.21s\n",
      "Train Loss: 0.6864\n",
      "Val Loss: 0.6948, Accuracy: 0.4850, F1: 0.6113\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 42/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s, loss=0.686]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/1000, Time: 1.26s\n",
      "Train Loss: 0.6862\n",
      "Val Loss: 0.6948, Accuracy: 0.4850, F1: 0.6113\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 43/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, loss=0.686]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/1000, Time: 1.11s\n",
      "Train Loss: 0.6861\n",
      "Val Loss: 0.6947, Accuracy: 0.4850, F1: 0.6113\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 44/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.686]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/1000, Time: 1.10s\n",
      "Train Loss: 0.6860\n",
      "Val Loss: 0.6946, Accuracy: 0.4850, F1: 0.6113\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 45/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, loss=0.686]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/1000, Time: 1.18s\n",
      "Train Loss: 0.6859\n",
      "Val Loss: 0.6946, Accuracy: 0.4850, F1: 0.6113\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 46/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, loss=0.686]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/1000, Time: 1.16s\n",
      "Train Loss: 0.6858\n",
      "Val Loss: 0.6945, Accuracy: 0.5000, F1: 0.6154\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 47/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, loss=0.686]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/1000, Time: 1.15s\n",
      "Train Loss: 0.6857\n",
      "Val Loss: 0.6945, Accuracy: 0.5000, F1: 0.6124\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 48/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, loss=0.686]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/1000, Time: 1.12s\n",
      "Train Loss: 0.6856\n",
      "Val Loss: 0.6944, Accuracy: 0.5000, F1: 0.6124\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 49/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s, loss=0.686]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/1000, Time: 1.08s\n",
      "Train Loss: 0.6856\n",
      "Val Loss: 0.6944, Accuracy: 0.4950, F1: 0.6070\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 50/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, loss=0.686]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/1000, Time: 1.08s\n",
      "Train Loss: 0.6855\n",
      "Val Loss: 0.6944, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 51/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/1000, Time: 1.07s\n",
      "Train Loss: 0.6855\n",
      "Val Loss: 0.6944, Accuracy: 0.4950, F1: 0.6039\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 52/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/1000, Time: 1.06s\n",
      "Train Loss: 0.6855\n",
      "Val Loss: 0.6944, Accuracy: 0.4900, F1: 0.5984\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 53/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/1000, Time: 1.04s\n",
      "Train Loss: 0.6854\n",
      "Val Loss: 0.6943, Accuracy: 0.4750, F1: 0.5783\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 54/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000, Time: 1.05s\n",
      "Train Loss: 0.6854\n",
      "Val Loss: 0.6943, Accuracy: 0.4800, F1: 0.5772\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 55/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/1000, Time: 1.06s\n",
      "Train Loss: 0.6854\n",
      "Val Loss: 0.6943, Accuracy: 0.4750, F1: 0.5679\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 56/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000, Time: 1.06s\n",
      "Train Loss: 0.6853\n",
      "Val Loss: 0.6943, Accuracy: 0.4700, F1: 0.5620\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 57/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/1000, Time: 1.08s\n",
      "Train Loss: 0.6853\n",
      "Val Loss: 0.6943, Accuracy: 0.4700, F1: 0.5620\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 58/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/1000, Time: 1.06s\n",
      "Train Loss: 0.6853\n",
      "Val Loss: 0.6943, Accuracy: 0.4750, F1: 0.5643\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 59/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/1000, Time: 1.20s\n",
      "Train Loss: 0.6853\n",
      "Val Loss: 0.6943, Accuracy: 0.4850, F1: 0.5690\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 60/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/1000, Time: 1.26s\n",
      "Train Loss: 0.6853\n",
      "Val Loss: 0.6943, Accuracy: 0.4800, F1: 0.5630\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 61/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/1000, Time: 1.29s\n",
      "Train Loss: 0.6853\n",
      "Val Loss: 0.6943, Accuracy: 0.4850, F1: 0.5654\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 62/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/1000, Time: 1.27s\n",
      "Train Loss: 0.6853\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5751\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 63/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/1000, Time: 1.30s\n",
      "Train Loss: 0.6853\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5776\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 64/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/1000, Time: 1.18s\n",
      "Train Loss: 0.6853\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5776\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 65/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/1000, Time: 1.15s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5776\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 66/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/1000, Time: 1.15s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5776\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 67/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/1000, Time: 1.11s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5776\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 68/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5776\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 69/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5776\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 70/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/1000, Time: 1.08s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5776\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 71/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/1000, Time: 1.07s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5776\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 72/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/1000, Time: 1.07s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5776\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 73/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5776\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 74/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/1000, Time: 1.11s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5776\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 75/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5776\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 76/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5776\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 77/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5776\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 78/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/1000, Time: 1.06s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5776\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 79/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/1000, Time: 1.05s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 80/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/1000, Time: 1.05s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 81/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/1000, Time: 1.04s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 82/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 83/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/1000, Time: 1.11s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 84/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 85/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/1000, Time: 1.06s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 86/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/1000, Time: 1.06s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 87/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/1000, Time: 1.11s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 88/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/1000, Time: 1.09s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 89/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/1000, Time: 1.09s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 90/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 91/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/1000, Time: 1.09s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 92/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/1000, Time: 1.06s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 93/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/1000, Time: 1.07s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 94/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/1000, Time: 1.09s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 95/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/1000, Time: 1.05s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 96/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/1000, Time: 1.06s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 97/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/1000, Time: 1.06s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 98/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/1000, Time: 1.09s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 99/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/1000, Time: 1.04s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 100/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/1000, Time: 1.05s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 101/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/1000, Time: 1.18s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 102/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/1000, Time: 1.15s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 103/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/1000, Time: 1.26s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 104/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/1000, Time: 1.19s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 105/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/1000, Time: 1.24s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 106/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:01<00:00,  1.06s/it, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/1000, Time: 1.36s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 107/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/1000, Time: 1.21s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 108/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/1000, Time: 1.19s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 109/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000, Time: 1.17s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 110/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 111/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/1000, Time: 1.06s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 112/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/1000, Time: 1.08s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 113/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 114/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/1000, Time: 1.11s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 115/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/1000, Time: 1.08s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 116/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 117/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 118/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 119/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/1000, Time: 1.09s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 120/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/1000, Time: 1.07s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 121/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 122/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/1000, Time: 1.06s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 123/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/1000, Time: 1.04s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 124/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/1000, Time: 1.11s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 125/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128/1000, Time: 1.05s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 126/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/1000, Time: 1.05s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 127/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/1000, Time: 1.04s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 128/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/1000, Time: 1.04s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 129/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/1000, Time: 1.06s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 130/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/1000, Time: 1.13s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 131/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 132/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 133/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/1000, Time: 1.15s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 134/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/1000, Time: 1.16s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 135/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 136/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/1000, Time: 1.15s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 137/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/1000, Time: 1.19s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 138/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/1000, Time: 1.14s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 139/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/1000, Time: 1.08s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 140/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/1000, Time: 1.09s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 141/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/1000, Time: 1.05s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 142/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 143/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/1000, Time: 1.15s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 144/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/1000, Time: 1.07s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 145/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 146/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 147/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/1000, Time: 1.13s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 148/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000, Time: 1.21s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 149/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152/1000, Time: 1.16s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 150/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 151/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154/1000, Time: 1.09s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 152/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/1000, Time: 1.09s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 153/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156/1000, Time: 1.09s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 154/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/1000, Time: 1.13s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 155/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158/1000, Time: 1.15s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 156/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/1000, Time: 1.18s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 157/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 158/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/1000, Time: 1.08s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 159/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 160/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/1000, Time: 1.13s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 161/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/1000, Time: 1.15s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 162/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/1000, Time: 1.15s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 163/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/1000, Time: 1.19s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 164/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 165/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/1000, Time: 1.08s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 166/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 167/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/1000, Time: 1.15s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 168/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/1000, Time: 1.15s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 169/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000, Time: 1.11s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 170/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 171/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 172/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/1000, Time: 1.14s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 173/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176/1000, Time: 1.13s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 174/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/1000, Time: 1.20s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 175/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/1000, Time: 1.15s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 176/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/1000, Time: 1.21s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 177/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/1000, Time: 1.18s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 178/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/1000, Time: 1.13s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 179/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 180/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/1000, Time: 1.11s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 181/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/1000, Time: 1.11s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 182/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185/1000, Time: 1.15s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 183/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186/1000, Time: 1.14s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 184/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187/1000, Time: 1.15s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 185/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/1000, Time: 1.11s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 186/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/1000, Time: 1.14s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 187/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/1000, Time: 1.11s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 188/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191/1000, Time: 1.15s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 189/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192/1000, Time: 1.17s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 190/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/1000, Time: 1.22s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 191/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194/1000, Time: 1.20s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 192/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195/1000, Time: 1.13s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 193/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196/1000, Time: 1.13s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 194/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197/1000, Time: 1.09s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 195/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/1000, Time: 1.11s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 196/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/1000, Time: 1.15s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 197/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/1000, Time: 1.16s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 198/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201/1000, Time: 1.19s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 199/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202/1000, Time: 1.14s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 200/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 203/1000, Time: 1.15s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 201/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 204/1000, Time: 1.21s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 202/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 205/1000, Time: 1.20s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 203/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 206/1000, Time: 1.28s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 204/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:01<00:00,  1.06s/it, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 207/1000, Time: 1.41s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 205/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:01<00:00,  1.06s/it, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208/1000, Time: 1.38s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 206/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209/1000, Time: 1.26s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 207/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 210/1000, Time: 1.14s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 208/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211/1000, Time: 1.13s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 209/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 212/1000, Time: 1.17s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 210/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213/1000, Time: 1.18s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 211/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 214/1000, Time: 1.17s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 212/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215/1000, Time: 1.17s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 213/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216/1000, Time: 1.09s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 214/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/1000, Time: 1.17s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 215/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218/1000, Time: 1.18s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 216/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 219/1000, Time: 1.13s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 217/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/1000, Time: 1.15s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 218/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/1000, Time: 1.15s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 219/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222/1000, Time: 1.13s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 220/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/1000, Time: 1.18s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 221/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 222/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000, Time: 1.11s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 223/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 224/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 227/1000, Time: 1.09s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 225/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 228/1000, Time: 1.07s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 226/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 227/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000, Time: 1.09s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 228/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231/1000, Time: 1.08s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 229/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232/1000, Time: 1.14s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 230/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/1000, Time: 1.14s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 231/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234/1000, Time: 1.15s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 232/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/1000, Time: 1.18s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 233/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236/1000, Time: 1.15s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 234/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 235/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/1000, Time: 1.07s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 236/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/1000, Time: 1.07s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 237/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240/1000, Time: 1.06s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 238/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/1000, Time: 1.09s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 239/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 242/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 240/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 243/1000, Time: 1.09s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 241/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 244/1000, Time: 1.08s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 242/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245/1000, Time: 1.08s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 243/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 246/1000, Time: 1.09s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 244/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 247/1000, Time: 1.11s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 245/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 248/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 246/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 247/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 248/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251/1000, Time: 1.11s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 249/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 252/1000, Time: 1.09s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 250/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 253/1000, Time: 1.08s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 251/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 254/1000, Time: 1.13s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 252/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 255/1000, Time: 1.09s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 253/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 256/1000, Time: 1.09s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 254/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 257/1000, Time: 1.08s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 255/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 258/1000, Time: 1.09s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 256/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259/1000, Time: 1.20s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 257/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 260/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 258/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 261/1000, Time: 1.15s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 259/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 262/1000, Time: 1.26s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 260/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 263/1000, Time: 1.14s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 261/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 264/1000, Time: 1.14s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 262/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 265/1000, Time: 1.14s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 263/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 266/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 264/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 267/1000, Time: 1.08s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 265/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 268/1000, Time: 1.08s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 266/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269/1000, Time: 1.21s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 267/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270/1000, Time: 1.30s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 268/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271/1000, Time: 1.09s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 269/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 272/1000, Time: 1.13s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 270/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 273/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 271/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 274/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 272/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 273/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276/1000, Time: 1.16s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 274/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277/1000, Time: 1.15s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 275/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 278/1000, Time: 1.19s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 276/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 279/1000, Time: 1.16s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 277/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 278/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/1000, Time: 1.11s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 279/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 282/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 280/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283/1000, Time: 1.14s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 281/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 282/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 285/1000, Time: 1.08s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 283/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000, Time: 1.11s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 284/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 287/1000, Time: 1.19s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 285/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 288/1000, Time: 1.17s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 286/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289/1000, Time: 1.18s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 287/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290/1000, Time: 1.16s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 288/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/1000, Time: 1.16s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 289/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 292/1000, Time: 1.13s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 290/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/1000, Time: 1.11s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 291/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 294/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 292/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295/1000, Time: 1.07s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 293/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/1000, Time: 1.08s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 294/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/1000, Time: 1.09s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 295/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 296/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/1000, Time: 1.07s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 297/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 298/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/1000, Time: 1.08s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 299/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 302/1000, Time: 1.09s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 300/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 303/1000, Time: 1.14s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 301/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304/1000, Time: 1.25s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 302/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 305/1000, Time: 1.20s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 303/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 306/1000, Time: 1.18s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 304/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 307/1000, Time: 1.20s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 305/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 308/1000, Time: 1.11s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 306/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 307/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 310/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 308/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 311/1000, Time: 1.06s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 309/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 312/1000, Time: 1.13s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 310/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 313/1000, Time: 1.19s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 311/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 314/1000, Time: 1.21s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 312/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 315/1000, Time: 1.25s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 313/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 316/1000, Time: 1.18s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 314/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317/1000, Time: 1.21s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 315/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 318/1000, Time: 1.16s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 316/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 319/1000, Time: 1.19s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 317/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 320/1000, Time: 1.13s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 318/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 321/1000, Time: 1.08s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 319/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 322/1000, Time: 1.06s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 320/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 323/1000, Time: 1.03s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 321/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 324/1000, Time: 1.05s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 322/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 325/1000, Time: 1.03s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 323/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 326/1000, Time: 1.03s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 324/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 327/1000, Time: 1.05s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 325/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 328/1000, Time: 1.05s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 326/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329/1000, Time: 1.04s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 327/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 330/1000, Time: 1.09s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 328/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331/1000, Time: 1.05s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 329/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 332/1000, Time: 1.08s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 330/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 333/1000, Time: 1.07s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 331/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 334/1000, Time: 1.07s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 332/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 335/1000, Time: 1.08s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 333/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336/1000, Time: 1.05s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 334/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/1000, Time: 1.07s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 335/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 338/1000, Time: 1.07s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 336/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 339/1000, Time: 1.04s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 337/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 340/1000, Time: 1.05s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 338/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 341/1000, Time: 1.05s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 339/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 342/1000, Time: 1.05s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 340/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000, Time: 1.05s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 341/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 344/1000, Time: 1.06s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 342/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 345/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 343/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 346/1000, Time: 1.08s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 344/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 347/1000, Time: 1.13s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 345/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 348/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 346/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/1000, Time: 1.11s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 347/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 348/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 351/1000, Time: 1.09s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 349/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 352/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 350/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 353/1000, Time: 1.07s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 351/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354/1000, Time: 1.05s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 352/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 355/1000, Time: 1.07s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 353/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 356/1000, Time: 1.07s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 354/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 357/1000, Time: 1.11s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 355/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 358/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 356/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359/1000, Time: 1.08s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 357/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360/1000, Time: 1.05s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 358/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/1000, Time: 1.17s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 359/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 362/1000, Time: 1.15s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 360/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 363/1000, Time: 1.21s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 361/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 364/1000, Time: 1.20s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 362/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:01<00:00,  1.03s/it, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 365/1000, Time: 1.35s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 363/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.00it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 366/1000, Time: 1.28s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 364/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 367/1000, Time: 1.21s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 365/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 368/1000, Time: 1.18s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 366/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 369/1000, Time: 1.18s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 367/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:01<00:00,  1.13s/it, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 370/1000, Time: 1.45s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 368/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 371/1000, Time: 1.17s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 369/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 372/1000, Time: 1.19s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 370/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 373/1000, Time: 1.17s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 371/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 374/1000, Time: 1.20s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 372/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 375/1000, Time: 1.19s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 373/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 376/1000, Time: 1.17s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 374/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 377/1000, Time: 1.16s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 375/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 378/1000, Time: 1.26s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 376/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 377/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 380/1000, Time: 1.08s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 378/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 379/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 382/1000, Time: 1.16s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 380/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 383/1000, Time: 1.16s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 381/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 384/1000, Time: 1.17s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 382/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 385/1000, Time: 1.16s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 383/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386/1000, Time: 1.17s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 384/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 387/1000, Time: 1.09s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 385/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 386/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389/1000, Time: 1.11s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 387/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 390/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 388/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/1000, Time: 1.11s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 389/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 392/1000, Time: 1.08s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 390/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/1000, Time: 1.07s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 391/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 394/1000, Time: 1.08s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 392/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 395/1000, Time: 1.06s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 393/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396/1000, Time: 1.04s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 394/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 397/1000, Time: 1.05s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 395/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 398/1000, Time: 1.05s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 396/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399/1000, Time: 1.04s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 397/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000, Time: 1.11s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 398/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401/1000, Time: 1.04s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 399/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 402/1000, Time: 1.06s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 400/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 403/1000, Time: 1.08s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 401/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 404/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 402/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 405/1000, Time: 1.06s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 403/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 406/1000, Time: 1.07s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 404/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/1000, Time: 1.06s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 405/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 408/1000, Time: 1.04s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 406/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 409/1000, Time: 1.05s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 407/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 410/1000, Time: 1.04s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 408/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 411/1000, Time: 1.05s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 409/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 412/1000, Time: 1.05s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 410/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 413/1000, Time: 1.06s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 411/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 414/1000, Time: 1.03s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 412/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 415/1000, Time: 1.03s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 413/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 416/1000, Time: 1.02s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 414/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 417/1000, Time: 1.06s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 415/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 418/1000, Time: 1.09s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 416/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 417/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 420/1000, Time: 1.11s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 418/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/1000, Time: 1.13s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 419/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 422/1000, Time: 1.13s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 420/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 423/1000, Time: 1.09s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 421/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 424/1000, Time: 1.08s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 422/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 425/1000, Time: 1.09s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 423/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 426/1000, Time: 1.09s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 424/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 427/1000, Time: 1.09s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 425/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 428/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 426/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 429/1000, Time: 1.13s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 427/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 430/1000, Time: 1.11s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 428/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 431/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 429/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 432/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 430/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 433/1000, Time: 1.15s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 431/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 434/1000, Time: 1.15s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 432/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 435/1000, Time: 1.14s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 433/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 436/1000, Time: 1.15s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 434/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 437/1000, Time: 1.15s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 435/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 438/1000, Time: 1.14s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 436/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 439/1000, Time: 1.11s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 437/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 440/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 438/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/1000, Time: 1.11s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 439/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 442/1000, Time: 1.10s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 440/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 443/1000, Time: 1.11s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 441/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 444/1000, Time: 1.11s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 442/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445/1000, Time: 1.11s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 443/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 446/1000, Time: 1.13s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 444/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 447/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5050, F1: 0.5714\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 445/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448/1000, Time: 1.14s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 446/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/1000, Time: 1.15s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 447/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 450/1000, Time: 1.15s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 448/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 451/1000, Time: 1.13s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 449/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 452/1000, Time: 1.13s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 450/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 453/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 451/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 454/1000, Time: 1.14s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 452/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455/1000, Time: 1.13s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 453/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 456/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 454/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 455/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 458/1000, Time: 1.12s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 456/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 459/1000, Time: 1.13s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 457/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 460/1000, Time: 1.11s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 458/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 461/1000, Time: 1.13s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 459/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 462/1000, Time: 1.17s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 460/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 463/1000, Time: 1.17s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 461/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 464/1000, Time: 1.15s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 462/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/1000, Time: 1.16s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 463/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 466/1000, Time: 1.15s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 464/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 467/1000, Time: 1.19s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 465/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 468/1000, Time: 1.16s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 466/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 469/1000, Time: 1.18s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 467/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 470/1000, Time: 1.20s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 468/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 471/1000, Time: 1.19s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 469/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 472/1000, Time: 1.17s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 470/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 473/1000, Time: 1.16s\n",
      "Train Loss: 0.6852\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 471/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 474/1000, Time: 1.14s\n",
      "Train Loss: 0.6851\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 472/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/1000, Time: 1.18s\n",
      "Train Loss: 0.6851\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 473/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 476/1000, Time: 1.20s\n",
      "Train Loss: 0.6851\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 474/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 477/1000, Time: 1.23s\n",
      "Train Loss: 0.6851\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 475/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 478/1000, Time: 1.17s\n",
      "Train Loss: 0.6851\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 476/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 479/1000, Time: 1.21s\n",
      "Train Loss: 0.6851\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 477/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 480/1000, Time: 1.19s\n",
      "Train Loss: 0.6851\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 478/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/1000, Time: 1.15s\n",
      "Train Loss: 0.6851\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 479/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 482/1000, Time: 1.19s\n",
      "Train Loss: 0.6851\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 480/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 483/1000, Time: 1.22s\n",
      "Train Loss: 0.6851\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 481/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 484/1000, Time: 1.17s\n",
      "Train Loss: 0.6851\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 482/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 485/1000, Time: 1.16s\n",
      "Train Loss: 0.6851\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 483/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 486/1000, Time: 1.16s\n",
      "Train Loss: 0.6851\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 484/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 487/1000, Time: 1.16s\n",
      "Train Loss: 0.6851\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 485/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 488/1000, Time: 1.18s\n",
      "Train Loss: 0.6851\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 486/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 489/1000, Time: 1.22s\n",
      "Train Loss: 0.6851\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 487/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:01<00:00,  1.00s/it, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 490/1000, Time: 1.31s\n",
      "Train Loss: 0.6851\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 488/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 491/1000, Time: 1.23s\n",
      "Train Loss: 0.6851\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 489/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 492/1000, Time: 1.25s\n",
      "Train Loss: 0.6851\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 490/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 493/1000, Time: 1.38s\n",
      "Train Loss: 0.6851\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 491/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 494/1000, Time: 1.27s\n",
      "Train Loss: 0.6851\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 492/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 495/1000, Time: 1.20s\n",
      "Train Loss: 0.6851\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 493/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496/1000, Time: 1.19s\n",
      "Train Loss: 0.6851\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 494/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 497/1000, Time: 1.28s\n",
      "Train Loss: 0.6851\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 495/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 498/1000, Time: 1.23s\n",
      "Train Loss: 0.6851\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 496/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499/1000, Time: 1.29s\n",
      "Train Loss: 0.6851\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 497/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/1000, Time: 1.27s\n",
      "Train Loss: 0.6851\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 498/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it, loss=0.685]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 501/1000, Time: 1.33s\n",
      "Train Loss: 0.6851\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 499/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.00it/s, loss=0.685]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 502/1000, Time: 1.30s\n",
      "Train Loss: 0.6851\n",
      "Val Loss: 0.6943, Accuracy: 0.5100, F1: 0.5739\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 500/500\n",
      "--------------------------------------------------\n",
      "Early stopping after 502 epochs\n",
      "Test Results:\n",
      "Loss: 0.6959, Accuracy: 0.5500\n",
      "Precision: 0.5385, Recall: 0.7000, F1: 0.6087\n",
      "Confusion Matrix:\n",
      "[[ 8 12]\n",
      " [ 6 14]]\n",
      "Training complete for vit! Best validation F1 score: 0.6667\n"
     ]
    }
   ],
   "source": [
    "print('ViT')\n",
    "vit_model = run_model(config, 'vit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine Tuned ViT\n",
      "Preparing dataloaders...\n",
      "Feature dimension: 13\n",
      "Initializing fine_tuned_vit model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s, loss=0.734]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Time: 1.00s\n",
      "Train Loss: 0.7335\n",
      "Val Loss: 1.7135, Accuracy: 0.5000, F1: 0.0000\n",
      "Best Val F1: 0.0000 (Epoch 1)\n",
      "Patience: 1/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s, loss=1.72]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000, Time: 1.46s\n",
      "Train Loss: 1.7213\n",
      "Val Loss: 1.1087, Accuracy: 0.5000, F1: 0.6667\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 0/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, loss=1.11]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000, Time: 0.91s\n",
      "Train Loss: 1.1069\n",
      "Val Loss: 0.7813, Accuracy: 0.5000, F1: 0.0000\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 1/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s, loss=0.793]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/1000, Time: 0.98s\n",
      "Train Loss: 0.7935\n",
      "Val Loss: 0.7058, Accuracy: 0.5000, F1: 0.6667\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 2/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s, loss=0.705]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/1000, Time: 0.96s\n",
      "Train Loss: 0.7055\n",
      "Val Loss: 0.7019, Accuracy: 0.5000, F1: 0.6667\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 3/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.705]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/1000, Time: 0.91s\n",
      "Train Loss: 0.7053\n",
      "Val Loss: 0.7010, Accuracy: 0.5000, F1: 0.0000\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 4/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.724]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/1000, Time: 0.88s\n",
      "Train Loss: 0.7242\n",
      "Val Loss: 0.6933, Accuracy: 0.5000, F1: 0.0000\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 5/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s, loss=0.689]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/1000, Time: 0.87s\n",
      "Train Loss: 0.6886\n",
      "Val Loss: 0.6960, Accuracy: 0.5000, F1: 0.6667\n",
      "Best Val F1: 0.6667 (Epoch 2)\n",
      "Patience: 6/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.712]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/1000, Time: 1.28s\n",
      "Train Loss: 0.7122\n",
      "Val Loss: 0.6941, Accuracy: 0.5050, F1: 0.6689\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 0/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.679]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/1000, Time: 0.89s\n",
      "Train Loss: 0.6787\n",
      "Val Loss: 0.6922, Accuracy: 0.5250, F1: 0.4099\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 1/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.71it/s, loss=0.687]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/1000, Time: 0.86s\n",
      "Train Loss: 0.6875\n",
      "Val Loss: 0.6938, Accuracy: 0.5000, F1: 0.0000\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 2/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s, loss=0.703]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/1000, Time: 0.87s\n",
      "Train Loss: 0.7028\n",
      "Val Loss: 0.6929, Accuracy: 0.4950, F1: 0.5976\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 3/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.677]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/1000, Time: 0.89s\n",
      "Train Loss: 0.6769\n",
      "Val Loss: 0.6965, Accuracy: 0.5000, F1: 0.6183\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 4/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.668]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/1000, Time: 0.92s\n",
      "Train Loss: 0.6684\n",
      "Val Loss: 0.7037, Accuracy: 0.5000, F1: 0.6094\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 5/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.66]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/1000, Time: 0.92s\n",
      "Train Loss: 0.6597\n",
      "Val Loss: 0.7174, Accuracy: 0.5000, F1: 0.6183\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 6/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s, loss=0.642]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/1000, Time: 0.94s\n",
      "Train Loss: 0.6422\n",
      "Val Loss: 0.7241, Accuracy: 0.4950, F1: 0.6189\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 7/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.644]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/1000, Time: 0.93s\n",
      "Train Loss: 0.6436\n",
      "Val Loss: 0.7329, Accuracy: 0.5050, F1: 0.6207\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 8/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.625]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/1000, Time: 0.89s\n",
      "Train Loss: 0.6254\n",
      "Val Loss: 0.7774, Accuracy: 0.5100, F1: 0.6142\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 9/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.616]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/1000, Time: 0.89s\n",
      "Train Loss: 0.6161\n",
      "Val Loss: 0.7718, Accuracy: 0.5100, F1: 0.6231\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 10/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s, loss=0.607]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/1000, Time: 0.88s\n",
      "Train Loss: 0.6066\n",
      "Val Loss: 0.9080, Accuracy: 0.4950, F1: 0.5976\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 11/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s, loss=0.586]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/1000, Time: 0.88s\n",
      "Train Loss: 0.5859\n",
      "Val Loss: 0.9581, Accuracy: 0.4950, F1: 0.5844\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 12/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.588]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/1000, Time: 0.91s\n",
      "Train Loss: 0.5880\n",
      "Val Loss: 0.9737, Accuracy: 0.5250, F1: 0.6025\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 13/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.587]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/1000, Time: 0.91s\n",
      "Train Loss: 0.5865\n",
      "Val Loss: 1.0200, Accuracy: 0.4950, F1: 0.5073\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 14/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s, loss=0.573]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/1000, Time: 0.92s\n",
      "Train Loss: 0.5734\n",
      "Val Loss: 0.9477, Accuracy: 0.5250, F1: 0.6058\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 15/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, loss=0.572]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/1000, Time: 0.89s\n",
      "Train Loss: 0.5722\n",
      "Val Loss: 0.9683, Accuracy: 0.5150, F1: 0.5764\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 16/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.571]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/1000, Time: 0.90s\n",
      "Train Loss: 0.5706\n",
      "Val Loss: 1.1028, Accuracy: 0.5000, F1: 0.4949\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 17/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.581]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/1000, Time: 0.90s\n",
      "Train Loss: 0.5807\n",
      "Val Loss: 0.8472, Accuracy: 0.5150, F1: 0.6166\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 18/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s, loss=0.598]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/1000, Time: 0.88s\n",
      "Train Loss: 0.5979\n",
      "Val Loss: 0.8414, Accuracy: 0.4950, F1: 0.6100\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 19/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, loss=0.603]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/1000, Time: 0.90s\n",
      "Train Loss: 0.6035\n",
      "Val Loss: 0.8983, Accuracy: 0.5000, F1: 0.6000\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 20/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.585]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/1000, Time: 0.92s\n",
      "Train Loss: 0.5850\n",
      "Val Loss: 1.0158, Accuracy: 0.5100, F1: 0.5776\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 21/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.554]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/1000, Time: 0.92s\n",
      "Train Loss: 0.5537\n",
      "Val Loss: 1.0411, Accuracy: 0.5300, F1: 0.5566\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 22/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.555]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/1000, Time: 0.91s\n",
      "Train Loss: 0.5547\n",
      "Val Loss: 1.0676, Accuracy: 0.5250, F1: 0.4751\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 23/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s, loss=0.562]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/1000, Time: 0.94s\n",
      "Train Loss: 0.5622\n",
      "Val Loss: 1.0997, Accuracy: 0.5450, F1: 0.5027\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 24/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, loss=0.555]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/1000, Time: 0.92s\n",
      "Train Loss: 0.5550\n",
      "Val Loss: 1.0946, Accuracy: 0.5150, F1: 0.5359\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 25/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s, loss=0.541]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/1000, Time: 0.94s\n",
      "Train Loss: 0.5413\n",
      "Val Loss: 1.0915, Accuracy: 0.4800, F1: 0.5357\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 26/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.541]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/1000, Time: 0.91s\n",
      "Train Loss: 0.5410\n",
      "Val Loss: 1.0933, Accuracy: 0.5050, F1: 0.5787\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 27/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s, loss=0.536]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/1000, Time: 0.94s\n",
      "Train Loss: 0.5363\n",
      "Val Loss: 1.1010, Accuracy: 0.5100, F1: 0.5847\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 28/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s, loss=0.545]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/1000, Time: 0.93s\n",
      "Train Loss: 0.5453\n",
      "Val Loss: 1.1123, Accuracy: 0.5000, F1: 0.5763\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 29/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s, loss=0.538]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/1000, Time: 0.94s\n",
      "Train Loss: 0.5385\n",
      "Val Loss: 1.1175, Accuracy: 0.4950, F1: 0.5702\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 30/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.537]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/1000, Time: 0.89s\n",
      "Train Loss: 0.5372\n",
      "Val Loss: 1.1157, Accuracy: 0.4950, F1: 0.5702\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 31/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.535]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/1000, Time: 0.89s\n",
      "Train Loss: 0.5352\n",
      "Val Loss: 1.1139, Accuracy: 0.5000, F1: 0.5726\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 32/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.529]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/1000, Time: 0.89s\n",
      "Train Loss: 0.5287\n",
      "Val Loss: 1.1124, Accuracy: 0.5000, F1: 0.5690\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 33/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.534]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/1000, Time: 0.90s\n",
      "Train Loss: 0.5343\n",
      "Val Loss: 1.1126, Accuracy: 0.5050, F1: 0.5639\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 34/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s, loss=0.527]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/1000, Time: 0.94s\n",
      "Train Loss: 0.5267\n",
      "Val Loss: 1.1160, Accuracy: 0.5150, F1: 0.5571\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 35/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s, loss=0.528]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/1000, Time: 0.94s\n",
      "Train Loss: 0.5276\n",
      "Val Loss: 1.1234, Accuracy: 0.5300, F1: 0.5607\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 36/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s, loss=0.519]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/1000, Time: 0.97s\n",
      "Train Loss: 0.5189\n",
      "Val Loss: 1.1283, Accuracy: 0.5200, F1: 0.5340\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 37/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, loss=0.523]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/1000, Time: 0.92s\n",
      "Train Loss: 0.5228\n",
      "Val Loss: 1.1328, Accuracy: 0.5200, F1: 0.5340\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 38/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.524]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/1000, Time: 0.91s\n",
      "Train Loss: 0.5242\n",
      "Val Loss: 1.1365, Accuracy: 0.5250, F1: 0.5366\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 39/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s, loss=0.517]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/1000, Time: 0.95s\n",
      "Train Loss: 0.5175\n",
      "Val Loss: 1.1383, Accuracy: 0.5250, F1: 0.5366\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 40/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.511]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/1000, Time: 0.92s\n",
      "Train Loss: 0.5107\n",
      "Val Loss: 1.1393, Accuracy: 0.5250, F1: 0.5455\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 41/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s, loss=0.503]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/1000, Time: 0.94s\n",
      "Train Loss: 0.5032\n",
      "Val Loss: 1.1401, Accuracy: 0.5350, F1: 0.5592\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 42/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s, loss=0.511]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/1000, Time: 0.93s\n",
      "Train Loss: 0.5107\n",
      "Val Loss: 1.1404, Accuracy: 0.5300, F1: 0.5566\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 43/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, loss=0.504]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/1000, Time: 0.92s\n",
      "Train Loss: 0.5040\n",
      "Val Loss: 1.1409, Accuracy: 0.5300, F1: 0.5607\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 44/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s, loss=0.506]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/1000, Time: 0.93s\n",
      "Train Loss: 0.5057\n",
      "Val Loss: 1.1415, Accuracy: 0.5200, F1: 0.5556\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 45/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.504]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/1000, Time: 0.91s\n",
      "Train Loss: 0.5038\n",
      "Val Loss: 1.1427, Accuracy: 0.5150, F1: 0.5530\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 46/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.501]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/1000, Time: 0.90s\n",
      "Train Loss: 0.5005\n",
      "Val Loss: 1.1441, Accuracy: 0.5150, F1: 0.5530\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 47/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s, loss=0.506]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000, Time: 0.87s\n",
      "Train Loss: 0.5058\n",
      "Val Loss: 1.1457, Accuracy: 0.5200, F1: 0.5596\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 48/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s, loss=0.506]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/1000, Time: 0.87s\n",
      "Train Loss: 0.5064\n",
      "Val Loss: 1.1467, Accuracy: 0.5200, F1: 0.5596\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 49/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000, Time: 0.88s\n",
      "Train Loss: 0.4973\n",
      "Val Loss: 1.1478, Accuracy: 0.5200, F1: 0.5596\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 50/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/1000, Time: 0.90s\n",
      "Train Loss: 0.5016\n",
      "Val Loss: 1.1489, Accuracy: 0.5200, F1: 0.5596\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 51/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s, loss=0.509]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/1000, Time: 0.87s\n",
      "Train Loss: 0.5093\n",
      "Val Loss: 1.1500, Accuracy: 0.5200, F1: 0.5596\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 52/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s, loss=0.493]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/1000, Time: 0.88s\n",
      "Train Loss: 0.4930\n",
      "Val Loss: 1.1513, Accuracy: 0.5200, F1: 0.5596\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 53/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/1000, Time: 0.89s\n",
      "Train Loss: 0.4966\n",
      "Val Loss: 1.1525, Accuracy: 0.5200, F1: 0.5596\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 54/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s, loss=0.49]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/1000, Time: 0.87s\n",
      "Train Loss: 0.4896\n",
      "Val Loss: 1.1531, Accuracy: 0.5200, F1: 0.5596\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 55/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, loss=0.511]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/1000, Time: 0.93s\n",
      "Train Loss: 0.5107\n",
      "Val Loss: 1.1538, Accuracy: 0.5200, F1: 0.5596\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 56/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s, loss=0.501]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/1000, Time: 0.93s\n",
      "Train Loss: 0.5010\n",
      "Val Loss: 1.1544, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 57/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s, loss=0.493]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/1000, Time: 0.92s\n",
      "Train Loss: 0.4931\n",
      "Val Loss: 1.1548, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 58/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.504]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/1000, Time: 0.90s\n",
      "Train Loss: 0.5037\n",
      "Val Loss: 1.1552, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 59/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.5]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/1000, Time: 0.90s\n",
      "Train Loss: 0.4999\n",
      "Val Loss: 1.1555, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 60/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, loss=0.51]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/1000, Time: 0.89s\n",
      "Train Loss: 0.5098\n",
      "Val Loss: 1.1556, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 61/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s, loss=0.499]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/1000, Time: 0.87s\n",
      "Train Loss: 0.4992\n",
      "Val Loss: 1.1557, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 62/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, loss=0.506]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/1000, Time: 0.89s\n",
      "Train Loss: 0.5062\n",
      "Val Loss: 1.1558, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 63/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/1000, Time: 0.90s\n",
      "Train Loss: 0.5018\n",
      "Val Loss: 1.1558, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 64/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s, loss=0.503]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/1000, Time: 0.87s\n",
      "Train Loss: 0.5028\n",
      "Val Loss: 1.1557, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 65/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/1000, Time: 0.88s\n",
      "Train Loss: 0.5015\n",
      "Val Loss: 1.1557, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 66/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/1000, Time: 0.88s\n",
      "Train Loss: 0.4965\n",
      "Val Loss: 1.1557, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 67/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.5]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/1000, Time: 0.91s\n",
      "Train Loss: 0.5001\n",
      "Val Loss: 1.1557, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 68/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s, loss=0.506]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/1000, Time: 0.95s\n",
      "Train Loss: 0.5061\n",
      "Val Loss: 1.1556, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 69/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s, loss=0.505]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/1000, Time: 0.97s\n",
      "Train Loss: 0.5047\n",
      "Val Loss: 1.1556, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 70/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/1000, Time: 0.95s\n",
      "Train Loss: 0.4967\n",
      "Val Loss: 1.1555, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 71/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, loss=0.505]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/1000, Time: 0.91s\n",
      "Train Loss: 0.5054\n",
      "Val Loss: 1.1555, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 72/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/1000, Time: 0.89s\n",
      "Train Loss: 0.4956\n",
      "Val Loss: 1.1555, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 73/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s, loss=0.49]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/1000, Time: 0.97s\n",
      "Train Loss: 0.4897\n",
      "Val Loss: 1.1555, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 74/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/1000, Time: 0.93s\n",
      "Train Loss: 0.5023\n",
      "Val Loss: 1.1555, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 75/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.505]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/1000, Time: 0.92s\n",
      "Train Loss: 0.5052\n",
      "Val Loss: 1.1554, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 76/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s, loss=0.495]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/1000, Time: 0.96s\n",
      "Train Loss: 0.4950\n",
      "Val Loss: 1.1554, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 77/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s, loss=0.499]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/1000, Time: 0.96s\n",
      "Train Loss: 0.4986\n",
      "Val Loss: 1.1555, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 78/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s, loss=0.501]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/1000, Time: 0.97s\n",
      "Train Loss: 0.5008\n",
      "Val Loss: 1.1555, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 79/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.491]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/1000, Time: 0.91s\n",
      "Train Loss: 0.4914\n",
      "Val Loss: 1.1555, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 80/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, loss=0.504]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/1000, Time: 0.92s\n",
      "Train Loss: 0.5044\n",
      "Val Loss: 1.1555, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 81/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s, loss=0.501]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/1000, Time: 0.92s\n",
      "Train Loss: 0.5012\n",
      "Val Loss: 1.1555, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 82/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s, loss=0.499]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/1000, Time: 0.92s\n",
      "Train Loss: 0.4993\n",
      "Val Loss: 1.1555, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 83/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/1000, Time: 0.91s\n",
      "Train Loss: 0.5021\n",
      "Val Loss: 1.1556, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 84/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/1000, Time: 0.91s\n",
      "Train Loss: 0.4969\n",
      "Val Loss: 1.1556, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 85/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s, loss=0.501]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/1000, Time: 0.93s\n",
      "Train Loss: 0.5008\n",
      "Val Loss: 1.1556, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 86/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/1000, Time: 0.90s\n",
      "Train Loss: 0.5024\n",
      "Val Loss: 1.1556, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 87/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/1000, Time: 0.94s\n",
      "Train Loss: 0.4968\n",
      "Val Loss: 1.1556, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 88/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.72it/s, loss=0.503]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/1000, Time: 0.87s\n",
      "Train Loss: 0.5032\n",
      "Val Loss: 1.1556, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 89/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, loss=0.501]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/1000, Time: 0.88s\n",
      "Train Loss: 0.5012\n",
      "Val Loss: 1.1556, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 90/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/1000, Time: 0.89s\n",
      "Train Loss: 0.5019\n",
      "Val Loss: 1.1556, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 91/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/1000, Time: 0.92s\n",
      "Train Loss: 0.4961\n",
      "Val Loss: 1.1556, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 92/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.492]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/1000, Time: 0.90s\n",
      "Train Loss: 0.4924\n",
      "Val Loss: 1.1557, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 93/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, loss=0.494]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/1000, Time: 0.88s\n",
      "Train Loss: 0.4942\n",
      "Val Loss: 1.1557, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 94/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.501]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/1000, Time: 0.90s\n",
      "Train Loss: 0.5014\n",
      "Val Loss: 1.1557, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 95/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/1000, Time: 0.94s\n",
      "Train Loss: 0.5021\n",
      "Val Loss: 1.1557, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 96/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/1000, Time: 0.92s\n",
      "Train Loss: 0.4964\n",
      "Val Loss: 1.1557, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 97/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.486]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/1000, Time: 0.90s\n",
      "Train Loss: 0.4857\n",
      "Val Loss: 1.1557, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 98/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.505]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/1000, Time: 0.91s\n",
      "Train Loss: 0.5053\n",
      "Val Loss: 1.1557, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 99/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/1000, Time: 0.88s\n",
      "Train Loss: 0.4959\n",
      "Val Loss: 1.1557, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 100/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.489]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/1000, Time: 0.91s\n",
      "Train Loss: 0.4895\n",
      "Val Loss: 1.1557, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 101/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, loss=0.493]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/1000, Time: 0.92s\n",
      "Train Loss: 0.4927\n",
      "Val Loss: 1.1557, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 102/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000, Time: 0.87s\n",
      "Train Loss: 0.5022\n",
      "Val Loss: 1.1557, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 103/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, loss=0.494]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000, Time: 0.91s\n",
      "Train Loss: 0.4937\n",
      "Val Loss: 1.1557, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 104/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.72it/s, loss=0.491]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/1000, Time: 0.87s\n",
      "Train Loss: 0.4910\n",
      "Val Loss: 1.1557, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 105/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, loss=0.504]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/1000, Time: 0.88s\n",
      "Train Loss: 0.5036\n",
      "Val Loss: 1.1558, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 106/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, loss=0.494]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/1000, Time: 0.88s\n",
      "Train Loss: 0.4942\n",
      "Val Loss: 1.1558, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 107/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s, loss=0.492]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/1000, Time: 0.87s\n",
      "Train Loss: 0.4917\n",
      "Val Loss: 1.1558, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 108/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, loss=0.494]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/1000, Time: 0.89s\n",
      "Train Loss: 0.4941\n",
      "Val Loss: 1.1558, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 109/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s, loss=0.493]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/1000, Time: 0.94s\n",
      "Train Loss: 0.4934\n",
      "Val Loss: 1.1558, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 110/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000, Time: 0.91s\n",
      "Train Loss: 0.4959\n",
      "Val Loss: 1.1558, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 111/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s, loss=0.504]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/1000, Time: 0.87s\n",
      "Train Loss: 0.5043\n",
      "Val Loss: 1.1558, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 112/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.493]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/1000, Time: 0.92s\n",
      "Train Loss: 0.4935\n",
      "Val Loss: 1.1558, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 113/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s, loss=0.5]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/1000, Time: 0.99s\n",
      "Train Loss: 0.5004\n",
      "Val Loss: 1.1558, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 114/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/1000, Time: 0.92s\n",
      "Train Loss: 0.5024\n",
      "Val Loss: 1.1558, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 115/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/1000, Time: 0.87s\n",
      "Train Loss: 0.4981\n",
      "Val Loss: 1.1558, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 116/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s, loss=0.499]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/1000, Time: 0.87s\n",
      "Train Loss: 0.4991\n",
      "Val Loss: 1.1558, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 117/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/1000, Time: 0.89s\n",
      "Train Loss: 0.4980\n",
      "Val Loss: 1.1558, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 118/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, loss=0.495]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128/1000, Time: 0.89s\n",
      "Train Loss: 0.4952\n",
      "Val Loss: 1.1559, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 119/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s, loss=0.495]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/1000, Time: 0.87s\n",
      "Train Loss: 0.4946\n",
      "Val Loss: 1.1559, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 120/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.501]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/1000, Time: 0.89s\n",
      "Train Loss: 0.5011\n",
      "Val Loss: 1.1559, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 121/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.74it/s, loss=0.492]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/1000, Time: 0.86s\n",
      "Train Loss: 0.4919\n",
      "Val Loss: 1.1559, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 122/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.71it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/1000, Time: 0.86s\n",
      "Train Loss: 0.4981\n",
      "Val Loss: 1.1559, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 123/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, loss=0.509]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/1000, Time: 0.88s\n",
      "Train Loss: 0.5095\n",
      "Val Loss: 1.1559, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 124/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s, loss=0.505]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/1000, Time: 0.88s\n",
      "Train Loss: 0.5055\n",
      "Val Loss: 1.1559, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 125/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s, loss=0.494]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/1000, Time: 0.94s\n",
      "Train Loss: 0.4938\n",
      "Val Loss: 1.1559, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 126/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/1000, Time: 0.89s\n",
      "Train Loss: 0.4984\n",
      "Val Loss: 1.1559, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 127/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, loss=0.491]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/1000, Time: 0.92s\n",
      "Train Loss: 0.4912\n",
      "Val Loss: 1.1559, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 128/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.501]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138/1000, Time: 0.90s\n",
      "Train Loss: 0.5009\n",
      "Val Loss: 1.1559, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 129/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.493]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/1000, Time: 0.91s\n",
      "Train Loss: 0.4931\n",
      "Val Loss: 1.1559, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 130/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, loss=0.503]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/1000, Time: 0.90s\n",
      "Train Loss: 0.5029\n",
      "Val Loss: 1.1559, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 131/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/1000, Time: 0.93s\n",
      "Train Loss: 0.4962\n",
      "Val Loss: 1.1559, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 132/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.495]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/1000, Time: 0.90s\n",
      "Train Loss: 0.4953\n",
      "Val Loss: 1.1560, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 133/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, loss=0.504]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/1000, Time: 0.88s\n",
      "Train Loss: 0.5044\n",
      "Val Loss: 1.1560, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 134/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, loss=0.51]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/1000, Time: 0.89s\n",
      "Train Loss: 0.5104\n",
      "Val Loss: 1.1560, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 135/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.73it/s, loss=0.503]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/1000, Time: 0.86s\n",
      "Train Loss: 0.5033\n",
      "Val Loss: 1.1560, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 136/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.71it/s, loss=0.493]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/1000, Time: 0.88s\n",
      "Train Loss: 0.4932\n",
      "Val Loss: 1.1560, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 137/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/1000, Time: 0.89s\n",
      "Train Loss: 0.4975\n",
      "Val Loss: 1.1560, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 138/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.71it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/1000, Time: 0.86s\n",
      "Train Loss: 0.4973\n",
      "Val Loss: 1.1560, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 139/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.71it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/1000, Time: 0.89s\n",
      "Train Loss: 0.4970\n",
      "Val Loss: 1.1560, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 140/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/1000, Time: 0.91s\n",
      "Train Loss: 0.4974\n",
      "Val Loss: 1.1560, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 141/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s, loss=0.494]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000, Time: 0.88s\n",
      "Train Loss: 0.4935\n",
      "Val Loss: 1.1560, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 142/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152/1000, Time: 0.90s\n",
      "Train Loss: 0.5016\n",
      "Val Loss: 1.1561, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 143/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153/1000, Time: 0.92s\n",
      "Train Loss: 0.4980\n",
      "Val Loss: 1.1561, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 144/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s, loss=0.503]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154/1000, Time: 0.93s\n",
      "Train Loss: 0.5033\n",
      "Val Loss: 1.1561, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 145/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s, loss=0.491]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/1000, Time: 0.93s\n",
      "Train Loss: 0.4908\n",
      "Val Loss: 1.1561, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 146/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156/1000, Time: 0.92s\n",
      "Train Loss: 0.4981\n",
      "Val Loss: 1.1561, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 147/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s, loss=0.505]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/1000, Time: 0.94s\n",
      "Train Loss: 0.5049\n",
      "Val Loss: 1.1561, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 148/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.501]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158/1000, Time: 0.92s\n",
      "Train Loss: 0.5010\n",
      "Val Loss: 1.1561, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 149/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.49]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/1000, Time: 0.91s\n",
      "Train Loss: 0.4900\n",
      "Val Loss: 1.1561, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 150/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, loss=0.5]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/1000, Time: 0.93s\n",
      "Train Loss: 0.4998\n",
      "Val Loss: 1.1561, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 151/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/1000, Time: 0.91s\n",
      "Train Loss: 0.4980\n",
      "Val Loss: 1.1561, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 152/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.5]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/1000, Time: 0.90s\n",
      "Train Loss: 0.4997\n",
      "Val Loss: 1.1562, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 153/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s, loss=0.501]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/1000, Time: 0.88s\n",
      "Train Loss: 0.5011\n",
      "Val Loss: 1.1562, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 154/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.493]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/1000, Time: 0.90s\n",
      "Train Loss: 0.4934\n",
      "Val Loss: 1.1562, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 155/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s, loss=0.503]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/1000, Time: 0.87s\n",
      "Train Loss: 0.5032\n",
      "Val Loss: 1.1562, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 156/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, loss=0.494]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/1000, Time: 0.89s\n",
      "Train Loss: 0.4944\n",
      "Val Loss: 1.1562, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 157/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.5]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/1000, Time: 0.90s\n",
      "Train Loss: 0.4996\n",
      "Val Loss: 1.1562, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 158/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, loss=0.491]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/1000, Time: 0.88s\n",
      "Train Loss: 0.4911\n",
      "Val Loss: 1.1562, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 159/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s, loss=0.506]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1000, Time: 0.88s\n",
      "Train Loss: 0.5063\n",
      "Val Loss: 1.1562, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 160/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s, loss=0.503]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/1000, Time: 0.88s\n",
      "Train Loss: 0.5028\n",
      "Val Loss: 1.1562, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 161/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/1000, Time: 0.90s\n",
      "Train Loss: 0.4963\n",
      "Val Loss: 1.1562, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 162/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.507]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000, Time: 0.92s\n",
      "Train Loss: 0.5072\n",
      "Val Loss: 1.1562, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 163/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, loss=0.499]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/1000, Time: 0.93s\n",
      "Train Loss: 0.4989\n",
      "Val Loss: 1.1562, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 164/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s, loss=0.505]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/1000, Time: 0.94s\n",
      "Train Loss: 0.5049\n",
      "Val Loss: 1.1562, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 165/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/1000, Time: 0.95s\n",
      "Train Loss: 0.4976\n",
      "Val Loss: 1.1563, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 166/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s, loss=0.503]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176/1000, Time: 0.96s\n",
      "Train Loss: 0.5034\n",
      "Val Loss: 1.1563, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 167/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s, loss=0.493]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/1000, Time: 0.95s\n",
      "Train Loss: 0.4931\n",
      "Val Loss: 1.1563, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 168/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/1000, Time: 0.92s\n",
      "Train Loss: 0.5016\n",
      "Val Loss: 1.1563, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 169/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/1000, Time: 1.03s\n",
      "Train Loss: 0.4979\n",
      "Val Loss: 1.1563, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 170/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.491]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/1000, Time: 0.91s\n",
      "Train Loss: 0.4911\n",
      "Val Loss: 1.1563, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 171/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.493]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/1000, Time: 0.90s\n",
      "Train Loss: 0.4932\n",
      "Val Loss: 1.1563, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 172/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182/1000, Time: 0.89s\n",
      "Train Loss: 0.4969\n",
      "Val Loss: 1.1563, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 173/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s, loss=0.495]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/1000, Time: 0.88s\n",
      "Train Loss: 0.4952\n",
      "Val Loss: 1.1563, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 174/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s, loss=0.499]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/1000, Time: 0.93s\n",
      "Train Loss: 0.4986\n",
      "Val Loss: 1.1563, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 175/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185/1000, Time: 0.93s\n",
      "Train Loss: 0.4974\n",
      "Val Loss: 1.1563, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 176/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.49]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186/1000, Time: 0.90s\n",
      "Train Loss: 0.4903\n",
      "Val Loss: 1.1563, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 177/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, loss=0.499]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187/1000, Time: 0.89s\n",
      "Train Loss: 0.4986\n",
      "Val Loss: 1.1563, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 178/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s, loss=0.507]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/1000, Time: 0.90s\n",
      "Train Loss: 0.5067\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 179/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/1000, Time: 0.91s\n",
      "Train Loss: 0.4981\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 180/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.494]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/1000, Time: 0.95s\n",
      "Train Loss: 0.4943\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 181/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, loss=0.503]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191/1000, Time: 0.91s\n",
      "Train Loss: 0.5026\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 182/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s, loss=0.494]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192/1000, Time: 0.93s\n",
      "Train Loss: 0.4937\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 183/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.499]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/1000, Time: 0.90s\n",
      "Train Loss: 0.4987\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 184/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194/1000, Time: 0.92s\n",
      "Train Loss: 0.4977\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 185/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195/1000, Time: 0.91s\n",
      "Train Loss: 0.4983\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 186/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, loss=0.501]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196/1000, Time: 0.92s\n",
      "Train Loss: 0.5013\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 187/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.72it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197/1000, Time: 0.86s\n",
      "Train Loss: 0.4984\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 188/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.494]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/1000, Time: 0.92s\n",
      "Train Loss: 0.4936\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 189/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.499]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/1000, Time: 0.90s\n",
      "Train Loss: 0.4991\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 190/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/1000, Time: 0.92s\n",
      "Train Loss: 0.4973\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 191/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s, loss=0.509]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201/1000, Time: 0.87s\n",
      "Train Loss: 0.5087\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 192/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.506]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202/1000, Time: 0.89s\n",
      "Train Loss: 0.5063\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 193/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s, loss=0.505]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 203/1000, Time: 0.99s\n",
      "Train Loss: 0.5054\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 194/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 204/1000, Time: 0.91s\n",
      "Train Loss: 0.4976\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 195/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 205/1000, Time: 0.90s\n",
      "Train Loss: 0.4983\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 196/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, loss=0.504]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 206/1000, Time: 0.88s\n",
      "Train Loss: 0.5037\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 197/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 207/1000, Time: 0.96s\n",
      "Train Loss: 0.4983\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 198/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s, loss=0.505]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208/1000, Time: 0.95s\n",
      "Train Loss: 0.5049\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 199/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s, loss=0.504]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209/1000, Time: 0.94s\n",
      "Train Loss: 0.5045\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 200/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s, loss=0.5]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 210/1000, Time: 0.94s\n",
      "Train Loss: 0.4998\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 201/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s, loss=0.494]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211/1000, Time: 0.92s\n",
      "Train Loss: 0.4940\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 202/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, loss=0.5]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 212/1000, Time: 0.93s\n",
      "Train Loss: 0.4996\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 203/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.503]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213/1000, Time: 0.90s\n",
      "Train Loss: 0.5031\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 204/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.493]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 214/1000, Time: 0.91s\n",
      "Train Loss: 0.4930\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 205/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s, loss=0.489]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215/1000, Time: 0.87s\n",
      "Train Loss: 0.4888\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 206/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s, loss=0.494]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216/1000, Time: 0.87s\n",
      "Train Loss: 0.4938\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 207/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.71it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/1000, Time: 0.86s\n",
      "Train Loss: 0.4978\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 208/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.72it/s, loss=0.5]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218/1000, Time: 0.85s\n",
      "Train Loss: 0.5000\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 209/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.72it/s, loss=0.5]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 219/1000, Time: 0.86s\n",
      "Train Loss: 0.5000\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 210/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/1000, Time: 0.90s\n",
      "Train Loss: 0.4966\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 211/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s, loss=0.499]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/1000, Time: 0.87s\n",
      "Train Loss: 0.4994\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 212/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s, loss=0.503]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222/1000, Time: 0.88s\n",
      "Train Loss: 0.5032\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 213/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.494]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/1000, Time: 0.89s\n",
      "Train Loss: 0.4943\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 214/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.509]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/1000, Time: 0.89s\n",
      "Train Loss: 0.5088\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 215/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000, Time: 0.92s\n",
      "Train Loss: 0.4967\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 216/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.5]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226/1000, Time: 0.91s\n",
      "Train Loss: 0.5003\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 217/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, loss=0.507]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 227/1000, Time: 0.89s\n",
      "Train Loss: 0.5072\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 218/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.506]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 228/1000, Time: 0.93s\n",
      "Train Loss: 0.5061\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 219/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000, Time: 0.98s\n",
      "Train Loss: 0.4957\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 220/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.501]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000, Time: 0.90s\n",
      "Train Loss: 0.5006\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 221/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231/1000, Time: 0.87s\n",
      "Train Loss: 0.4955\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 222/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, loss=0.486]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232/1000, Time: 0.87s\n",
      "Train Loss: 0.4865\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 223/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.71it/s, loss=0.494]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/1000, Time: 0.88s\n",
      "Train Loss: 0.4943\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 224/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s, loss=0.488]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234/1000, Time: 0.96s\n",
      "Train Loss: 0.4882\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 225/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.485]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/1000, Time: 0.91s\n",
      "Train Loss: 0.4852\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 226/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.501]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236/1000, Time: 0.89s\n",
      "Train Loss: 0.5006\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 227/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, loss=0.495]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237/1000, Time: 0.88s\n",
      "Train Loss: 0.4950\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 228/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, loss=0.505]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/1000, Time: 0.89s\n",
      "Train Loss: 0.5045\n",
      "Val Loss: 1.1564, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 229/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/1000, Time: 0.90s\n",
      "Train Loss: 0.4974\n",
      "Val Loss: 1.1565, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 230/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.506]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240/1000, Time: 0.88s\n",
      "Train Loss: 0.5057\n",
      "Val Loss: 1.1565, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 231/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/1000, Time: 0.91s\n",
      "Train Loss: 0.4978\n",
      "Val Loss: 1.1565, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 232/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.492]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 242/1000, Time: 0.93s\n",
      "Train Loss: 0.4919\n",
      "Val Loss: 1.1565, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 233/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 243/1000, Time: 0.91s\n",
      "Train Loss: 0.4971\n",
      "Val Loss: 1.1565, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 234/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s, loss=0.499]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 244/1000, Time: 0.96s\n",
      "Train Loss: 0.4987\n",
      "Val Loss: 1.1565, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 235/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245/1000, Time: 0.98s\n",
      "Train Loss: 0.4975\n",
      "Val Loss: 1.1565, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 236/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s, loss=0.504]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 246/1000, Time: 0.94s\n",
      "Train Loss: 0.5036\n",
      "Val Loss: 1.1565, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 237/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 247/1000, Time: 0.91s\n",
      "Train Loss: 0.4974\n",
      "Val Loss: 1.1565, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 238/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 248/1000, Time: 0.87s\n",
      "Train Loss: 0.4980\n",
      "Val Loss: 1.1565, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 239/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.503]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249/1000, Time: 0.90s\n",
      "Train Loss: 0.5028\n",
      "Val Loss: 1.1565, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 240/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, loss=0.501]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250/1000, Time: 0.89s\n",
      "Train Loss: 0.5013\n",
      "Val Loss: 1.1565, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 241/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s, loss=0.506]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251/1000, Time: 0.87s\n",
      "Train Loss: 0.5061\n",
      "Val Loss: 1.1565, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 242/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.72it/s, loss=0.504]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 252/1000, Time: 0.86s\n",
      "Train Loss: 0.5038\n",
      "Val Loss: 1.1565, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 243/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 253/1000, Time: 0.90s\n",
      "Train Loss: 0.5018\n",
      "Val Loss: 1.1565, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 244/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, loss=0.495]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 254/1000, Time: 0.89s\n",
      "Train Loss: 0.4946\n",
      "Val Loss: 1.1565, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 245/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 255/1000, Time: 0.89s\n",
      "Train Loss: 0.5021\n",
      "Val Loss: 1.1566, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 246/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 256/1000, Time: 0.88s\n",
      "Train Loss: 0.4966\n",
      "Val Loss: 1.1566, Accuracy: 0.5250, F1: 0.5622\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 247/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.505]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 257/1000, Time: 0.90s\n",
      "Train Loss: 0.5050\n",
      "Val Loss: 1.1566, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 248/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 258/1000, Time: 0.90s\n",
      "Train Loss: 0.5017\n",
      "Val Loss: 1.1566, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 249/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259/1000, Time: 0.93s\n",
      "Train Loss: 0.4966\n",
      "Val Loss: 1.1566, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 250/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.503]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 260/1000, Time: 0.91s\n",
      "Train Loss: 0.5033\n",
      "Val Loss: 1.1566, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 251/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.505]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 261/1000, Time: 0.93s\n",
      "Train Loss: 0.5046\n",
      "Val Loss: 1.1566, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 252/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, loss=0.486]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 262/1000, Time: 0.92s\n",
      "Train Loss: 0.4856\n",
      "Val Loss: 1.1566, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 253/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.492]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 263/1000, Time: 0.91s\n",
      "Train Loss: 0.4925\n",
      "Val Loss: 1.1566, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 254/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s, loss=0.493]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 264/1000, Time: 0.93s\n",
      "Train Loss: 0.4929\n",
      "Val Loss: 1.1566, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 255/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.501]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 265/1000, Time: 0.91s\n",
      "Train Loss: 0.5014\n",
      "Val Loss: 1.1566, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 256/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 266/1000, Time: 0.89s\n",
      "Train Loss: 0.4959\n",
      "Val Loss: 1.1567, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 257/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s, loss=0.507]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 267/1000, Time: 0.93s\n",
      "Train Loss: 0.5070\n",
      "Val Loss: 1.1567, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 258/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.491]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 268/1000, Time: 0.93s\n",
      "Train Loss: 0.4915\n",
      "Val Loss: 1.1567, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 259/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.5]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269/1000, Time: 0.91s\n",
      "Train Loss: 0.5001\n",
      "Val Loss: 1.1567, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 260/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, loss=0.494]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270/1000, Time: 0.88s\n",
      "Train Loss: 0.4943\n",
      "Val Loss: 1.1567, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 261/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s, loss=0.489]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271/1000, Time: 0.88s\n",
      "Train Loss: 0.4892\n",
      "Val Loss: 1.1567, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 262/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.71it/s, loss=0.504]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 272/1000, Time: 0.87s\n",
      "Train Loss: 0.5044\n",
      "Val Loss: 1.1567, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 263/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.73it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 273/1000, Time: 0.86s\n",
      "Train Loss: 0.4962\n",
      "Val Loss: 1.1568, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 264/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 274/1000, Time: 0.88s\n",
      "Train Loss: 0.5022\n",
      "Val Loss: 1.1568, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 265/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.492]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275/1000, Time: 0.90s\n",
      "Train Loss: 0.4923\n",
      "Val Loss: 1.1568, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 266/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276/1000, Time: 0.93s\n",
      "Train Loss: 0.4962\n",
      "Val Loss: 1.1568, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 267/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277/1000, Time: 0.94s\n",
      "Train Loss: 0.4966\n",
      "Val Loss: 1.1568, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 268/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 278/1000, Time: 0.92s\n",
      "Train Loss: 0.4971\n",
      "Val Loss: 1.1568, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 269/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s, loss=0.5]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 279/1000, Time: 0.96s\n",
      "Train Loss: 0.5005\n",
      "Val Loss: 1.1568, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 270/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s, loss=0.493]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/1000, Time: 1.06s\n",
      "Train Loss: 0.4933\n",
      "Val Loss: 1.1568, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 271/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s, loss=0.501]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/1000, Time: 0.95s\n",
      "Train Loss: 0.5014\n",
      "Val Loss: 1.1569, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 272/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s, loss=0.489]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 282/1000, Time: 1.01s\n",
      "Train Loss: 0.4889\n",
      "Val Loss: 1.1569, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 273/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s, loss=0.494]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283/1000, Time: 0.98s\n",
      "Train Loss: 0.4935\n",
      "Val Loss: 1.1569, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 274/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, loss=0.495]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284/1000, Time: 0.89s\n",
      "Train Loss: 0.4953\n",
      "Val Loss: 1.1569, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 275/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 285/1000, Time: 0.90s\n",
      "Train Loss: 0.5016\n",
      "Val Loss: 1.1569, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 276/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000, Time: 0.90s\n",
      "Train Loss: 0.4974\n",
      "Val Loss: 1.1569, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 277/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.499]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 287/1000, Time: 0.89s\n",
      "Train Loss: 0.4989\n",
      "Val Loss: 1.1569, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 278/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.494]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 288/1000, Time: 0.88s\n",
      "Train Loss: 0.4937\n",
      "Val Loss: 1.1569, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 279/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s, loss=0.491]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289/1000, Time: 0.87s\n",
      "Train Loss: 0.4910\n",
      "Val Loss: 1.1569, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 280/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s, loss=0.503]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290/1000, Time: 0.87s\n",
      "Train Loss: 0.5027\n",
      "Val Loss: 1.1570, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 281/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.508]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/1000, Time: 0.91s\n",
      "Train Loss: 0.5083\n",
      "Val Loss: 1.1570, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 282/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.501]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 292/1000, Time: 0.91s\n",
      "Train Loss: 0.5014\n",
      "Val Loss: 1.1570, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 283/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, loss=0.501]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/1000, Time: 0.90s\n",
      "Train Loss: 0.5005\n",
      "Val Loss: 1.1570, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 284/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s, loss=0.509]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 294/1000, Time: 0.93s\n",
      "Train Loss: 0.5093\n",
      "Val Loss: 1.1570, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 285/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295/1000, Time: 0.93s\n",
      "Train Loss: 0.5016\n",
      "Val Loss: 1.1570, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 286/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, loss=0.503]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/1000, Time: 0.92s\n",
      "Train Loss: 0.5028\n",
      "Val Loss: 1.1570, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 287/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/1000, Time: 0.91s\n",
      "Train Loss: 0.4967\n",
      "Val Loss: 1.1570, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 288/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.491]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298/1000, Time: 0.91s\n",
      "Train Loss: 0.4905\n",
      "Val Loss: 1.1570, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 289/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/1000, Time: 0.92s\n",
      "Train Loss: 0.4982\n",
      "Val Loss: 1.1570, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 290/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.495]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/1000, Time: 0.90s\n",
      "Train Loss: 0.4953\n",
      "Val Loss: 1.1570, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 291/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.492]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/1000, Time: 0.88s\n",
      "Train Loss: 0.4920\n",
      "Val Loss: 1.1571, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 292/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.5]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 302/1000, Time: 0.93s\n",
      "Train Loss: 0.4998\n",
      "Val Loss: 1.1571, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 293/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 303/1000, Time: 0.90s\n",
      "Train Loss: 0.4976\n",
      "Val Loss: 1.1571, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 294/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s, loss=0.5]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304/1000, Time: 0.90s\n",
      "Train Loss: 0.4998\n",
      "Val Loss: 1.1571, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 295/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.495]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 305/1000, Time: 0.90s\n",
      "Train Loss: 0.4950\n",
      "Val Loss: 1.1571, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 296/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.503]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 306/1000, Time: 0.90s\n",
      "Train Loss: 0.5027\n",
      "Val Loss: 1.1571, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 297/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.503]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 307/1000, Time: 0.89s\n",
      "Train Loss: 0.5032\n",
      "Val Loss: 1.1571, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 298/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 308/1000, Time: 0.89s\n",
      "Train Loss: 0.4975\n",
      "Val Loss: 1.1571, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 299/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.505]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/1000, Time: 0.88s\n",
      "Train Loss: 0.5048\n",
      "Val Loss: 1.1571, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 300/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.499]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 310/1000, Time: 0.90s\n",
      "Train Loss: 0.4987\n",
      "Val Loss: 1.1571, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 301/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s, loss=0.492]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 311/1000, Time: 0.87s\n",
      "Train Loss: 0.4925\n",
      "Val Loss: 1.1571, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 302/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.495]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 312/1000, Time: 0.90s\n",
      "Train Loss: 0.4947\n",
      "Val Loss: 1.1571, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 303/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s, loss=0.499]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 313/1000, Time: 0.97s\n",
      "Train Loss: 0.4986\n",
      "Val Loss: 1.1571, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 304/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 314/1000, Time: 0.96s\n",
      "Train Loss: 0.4977\n",
      "Val Loss: 1.1571, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 305/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.492]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 315/1000, Time: 0.91s\n",
      "Train Loss: 0.4918\n",
      "Val Loss: 1.1571, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 306/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 316/1000, Time: 0.93s\n",
      "Train Loss: 0.4979\n",
      "Val Loss: 1.1571, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 307/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s, loss=0.509]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317/1000, Time: 0.94s\n",
      "Train Loss: 0.5085\n",
      "Val Loss: 1.1571, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 308/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s, loss=0.493]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 318/1000, Time: 0.93s\n",
      "Train Loss: 0.4933\n",
      "Val Loss: 1.1571, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 309/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s, loss=0.499]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 319/1000, Time: 0.93s\n",
      "Train Loss: 0.4989\n",
      "Val Loss: 1.1571, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 310/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.504]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 320/1000, Time: 0.92s\n",
      "Train Loss: 0.5035\n",
      "Val Loss: 1.1571, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 311/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 321/1000, Time: 0.92s\n",
      "Train Loss: 0.4965\n",
      "Val Loss: 1.1571, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 312/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, loss=0.511]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 322/1000, Time: 0.92s\n",
      "Train Loss: 0.5108\n",
      "Val Loss: 1.1571, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 313/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s, loss=0.499]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 323/1000, Time: 0.93s\n",
      "Train Loss: 0.4992\n",
      "Val Loss: 1.1571, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 314/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, loss=0.504]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 324/1000, Time: 0.89s\n",
      "Train Loss: 0.5045\n",
      "Val Loss: 1.1571, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 315/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.489]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 325/1000, Time: 0.90s\n",
      "Train Loss: 0.4889\n",
      "Val Loss: 1.1572, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 316/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.492]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 326/1000, Time: 0.91s\n",
      "Train Loss: 0.4921\n",
      "Val Loss: 1.1572, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 317/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 327/1000, Time: 0.90s\n",
      "Train Loss: 0.4958\n",
      "Val Loss: 1.1572, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 318/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 328/1000, Time: 0.91s\n",
      "Train Loss: 0.4984\n",
      "Val Loss: 1.1572, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 319/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s, loss=0.5]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329/1000, Time: 0.93s\n",
      "Train Loss: 0.4999\n",
      "Val Loss: 1.1572, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 320/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.504]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 330/1000, Time: 0.92s\n",
      "Train Loss: 0.5041\n",
      "Val Loss: 1.1572, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 321/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s, loss=0.5]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331/1000, Time: 0.97s\n",
      "Train Loss: 0.5004\n",
      "Val Loss: 1.1572, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 322/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, loss=0.493]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 332/1000, Time: 0.94s\n",
      "Train Loss: 0.4930\n",
      "Val Loss: 1.1572, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 323/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.507]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 333/1000, Time: 0.91s\n",
      "Train Loss: 0.5072\n",
      "Val Loss: 1.1572, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 324/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.504]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 334/1000, Time: 0.90s\n",
      "Train Loss: 0.5038\n",
      "Val Loss: 1.1572, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 325/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s, loss=0.5]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 335/1000, Time: 0.93s\n",
      "Train Loss: 0.4995\n",
      "Val Loss: 1.1572, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 326/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s, loss=0.509]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336/1000, Time: 0.88s\n",
      "Train Loss: 0.5087\n",
      "Val Loss: 1.1572, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 327/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, loss=0.495]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/1000, Time: 0.89s\n",
      "Train Loss: 0.4950\n",
      "Val Loss: 1.1572, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 328/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s, loss=0.501]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 338/1000, Time: 0.88s\n",
      "Train Loss: 0.5006\n",
      "Val Loss: 1.1572, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 329/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 339/1000, Time: 0.89s\n",
      "Train Loss: 0.4969\n",
      "Val Loss: 1.1573, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 330/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 340/1000, Time: 0.89s\n",
      "Train Loss: 0.4966\n",
      "Val Loss: 1.1573, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 331/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 341/1000, Time: 0.89s\n",
      "Train Loss: 0.4983\n",
      "Val Loss: 1.1573, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 332/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.491]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 342/1000, Time: 0.89s\n",
      "Train Loss: 0.4907\n",
      "Val Loss: 1.1573, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 333/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.494]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000, Time: 0.89s\n",
      "Train Loss: 0.4941\n",
      "Val Loss: 1.1573, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 334/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.504]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 344/1000, Time: 0.90s\n",
      "Train Loss: 0.5043\n",
      "Val Loss: 1.1573, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 335/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.492]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 345/1000, Time: 0.91s\n",
      "Train Loss: 0.4922\n",
      "Val Loss: 1.1573, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 336/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.501]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 346/1000, Time: 0.90s\n",
      "Train Loss: 0.5010\n",
      "Val Loss: 1.1573, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 337/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 347/1000, Time: 0.95s\n",
      "Train Loss: 0.4968\n",
      "Val Loss: 1.1573, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 338/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s, loss=0.509]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 348/1000, Time: 0.95s\n",
      "Train Loss: 0.5091\n",
      "Val Loss: 1.1573, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 339/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.509]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/1000, Time: 0.91s\n",
      "Train Loss: 0.5086\n",
      "Val Loss: 1.1573, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 340/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350/1000, Time: 0.94s\n",
      "Train Loss: 0.5018\n",
      "Val Loss: 1.1573, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 341/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s, loss=0.501]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 351/1000, Time: 0.94s\n",
      "Train Loss: 0.5009\n",
      "Val Loss: 1.1573, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 342/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s, loss=0.495]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 352/1000, Time: 0.93s\n",
      "Train Loss: 0.4950\n",
      "Val Loss: 1.1573, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 343/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, loss=0.499]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 353/1000, Time: 0.90s\n",
      "Train Loss: 0.4989\n",
      "Val Loss: 1.1573, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 344/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.486]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354/1000, Time: 0.89s\n",
      "Train Loss: 0.4857\n",
      "Val Loss: 1.1574, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 345/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.499]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 355/1000, Time: 0.88s\n",
      "Train Loss: 0.4986\n",
      "Val Loss: 1.1574, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 346/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 356/1000, Time: 0.88s\n",
      "Train Loss: 0.4980\n",
      "Val Loss: 1.1574, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 347/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 357/1000, Time: 0.87s\n",
      "Train Loss: 0.4956\n",
      "Val Loss: 1.1574, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 348/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 358/1000, Time: 0.88s\n",
      "Train Loss: 0.4969\n",
      "Val Loss: 1.1574, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 349/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.495]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359/1000, Time: 0.94s\n",
      "Train Loss: 0.4951\n",
      "Val Loss: 1.1574, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 350/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360/1000, Time: 0.91s\n",
      "Train Loss: 0.4959\n",
      "Val Loss: 1.1574, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 351/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/1000, Time: 0.90s\n",
      "Train Loss: 0.4958\n",
      "Val Loss: 1.1574, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 352/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s, loss=0.495]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 362/1000, Time: 0.98s\n",
      "Train Loss: 0.4953\n",
      "Val Loss: 1.1574, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 353/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s, loss=0.49]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 363/1000, Time: 0.92s\n",
      "Train Loss: 0.4900\n",
      "Val Loss: 1.1574, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 354/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 364/1000, Time: 0.94s\n",
      "Train Loss: 0.5022\n",
      "Val Loss: 1.1574, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 355/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 365/1000, Time: 0.97s\n",
      "Train Loss: 0.4968\n",
      "Val Loss: 1.1574, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 356/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 366/1000, Time: 0.96s\n",
      "Train Loss: 0.5018\n",
      "Val Loss: 1.1574, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 357/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s, loss=0.51]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 367/1000, Time: 0.95s\n",
      "Train Loss: 0.5099\n",
      "Val Loss: 1.1574, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 358/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.501]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 368/1000, Time: 0.90s\n",
      "Train Loss: 0.5012\n",
      "Val Loss: 1.1575, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 359/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.494]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 369/1000, Time: 0.91s\n",
      "Train Loss: 0.4944\n",
      "Val Loss: 1.1575, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 360/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s, loss=0.501]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 370/1000, Time: 0.96s\n",
      "Train Loss: 0.5013\n",
      "Val Loss: 1.1575, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 361/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 371/1000, Time: 0.88s\n",
      "Train Loss: 0.4985\n",
      "Val Loss: 1.1575, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 362/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s, loss=0.5]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 372/1000, Time: 0.88s\n",
      "Train Loss: 0.5001\n",
      "Val Loss: 1.1575, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 363/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 373/1000, Time: 0.93s\n",
      "Train Loss: 0.4964\n",
      "Val Loss: 1.1575, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 364/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.499]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 374/1000, Time: 0.91s\n",
      "Train Loss: 0.4991\n",
      "Val Loss: 1.1575, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 365/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.491]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 375/1000, Time: 0.91s\n",
      "Train Loss: 0.4913\n",
      "Val Loss: 1.1576, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 366/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s, loss=0.495]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 376/1000, Time: 0.88s\n",
      "Train Loss: 0.4954\n",
      "Val Loss: 1.1576, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 367/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s, loss=0.504]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 377/1000, Time: 0.92s\n",
      "Train Loss: 0.5037\n",
      "Val Loss: 1.1576, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 368/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.5]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 378/1000, Time: 0.90s\n",
      "Train Loss: 0.5001\n",
      "Val Loss: 1.1576, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 369/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379/1000, Time: 0.88s\n",
      "Train Loss: 0.4968\n",
      "Val Loss: 1.1576, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 370/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.71it/s, loss=0.494]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 380/1000, Time: 0.87s\n",
      "Train Loss: 0.4939\n",
      "Val Loss: 1.1576, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 371/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/1000, Time: 0.94s\n",
      "Train Loss: 0.4973\n",
      "Val Loss: 1.1577, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 372/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 382/1000, Time: 0.95s\n",
      "Train Loss: 0.4971\n",
      "Val Loss: 1.1577, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 373/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.501]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 383/1000, Time: 0.92s\n",
      "Train Loss: 0.5007\n",
      "Val Loss: 1.1577, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 374/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, loss=0.494]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 384/1000, Time: 0.93s\n",
      "Train Loss: 0.4943\n",
      "Val Loss: 1.1577, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 375/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 385/1000, Time: 0.93s\n",
      "Train Loss: 0.5022\n",
      "Val Loss: 1.1577, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 376/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386/1000, Time: 0.93s\n",
      "Train Loss: 0.5024\n",
      "Val Loss: 1.1577, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 377/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 387/1000, Time: 0.93s\n",
      "Train Loss: 0.5023\n",
      "Val Loss: 1.1577, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 378/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.488]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388/1000, Time: 0.91s\n",
      "Train Loss: 0.4884\n",
      "Val Loss: 1.1577, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 379/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389/1000, Time: 0.90s\n",
      "Train Loss: 0.4965\n",
      "Val Loss: 1.1577, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 380/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 390/1000, Time: 0.90s\n",
      "Train Loss: 0.4976\n",
      "Val Loss: 1.1577, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 381/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.503]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/1000, Time: 0.88s\n",
      "Train Loss: 0.5026\n",
      "Val Loss: 1.1577, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 382/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, loss=0.493]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 392/1000, Time: 0.91s\n",
      "Train Loss: 0.4926\n",
      "Val Loss: 1.1577, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 383/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.484]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/1000, Time: 0.91s\n",
      "Train Loss: 0.4842\n",
      "Val Loss: 1.1577, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 384/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.495]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 394/1000, Time: 0.90s\n",
      "Train Loss: 0.4954\n",
      "Val Loss: 1.1577, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 385/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.505]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 395/1000, Time: 0.90s\n",
      "Train Loss: 0.5047\n",
      "Val Loss: 1.1577, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 386/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.485]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396/1000, Time: 0.90s\n",
      "Train Loss: 0.4852\n",
      "Val Loss: 1.1578, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 387/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.494]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 397/1000, Time: 0.89s\n",
      "Train Loss: 0.4937\n",
      "Val Loss: 1.1578, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 388/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 398/1000, Time: 0.89s\n",
      "Train Loss: 0.4956\n",
      "Val Loss: 1.1578, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 389/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.71it/s, loss=0.495]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399/1000, Time: 0.87s\n",
      "Train Loss: 0.4947\n",
      "Val Loss: 1.1578, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 390/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.491]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000, Time: 0.89s\n",
      "Train Loss: 0.4905\n",
      "Val Loss: 1.1578, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 391/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s, loss=0.488]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401/1000, Time: 0.94s\n",
      "Train Loss: 0.4883\n",
      "Val Loss: 1.1578, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 392/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.5]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 402/1000, Time: 0.91s\n",
      "Train Loss: 0.5003\n",
      "Val Loss: 1.1578, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 393/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 403/1000, Time: 0.92s\n",
      "Train Loss: 0.4961\n",
      "Val Loss: 1.1578, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 394/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.499]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 404/1000, Time: 0.93s\n",
      "Train Loss: 0.4989\n",
      "Val Loss: 1.1578, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 395/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, loss=0.489]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 405/1000, Time: 0.91s\n",
      "Train Loss: 0.4891\n",
      "Val Loss: 1.1578, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 396/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, loss=0.499]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 406/1000, Time: 0.89s\n",
      "Train Loss: 0.4988\n",
      "Val Loss: 1.1578, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 397/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/1000, Time: 0.87s\n",
      "Train Loss: 0.4956\n",
      "Val Loss: 1.1578, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 398/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.495]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 408/1000, Time: 0.90s\n",
      "Train Loss: 0.4954\n",
      "Val Loss: 1.1579, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 399/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 409/1000, Time: 0.90s\n",
      "Train Loss: 0.4982\n",
      "Val Loss: 1.1579, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 400/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 410/1000, Time: 0.91s\n",
      "Train Loss: 0.4964\n",
      "Val Loss: 1.1579, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 401/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s, loss=0.495]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 411/1000, Time: 0.94s\n",
      "Train Loss: 0.4954\n",
      "Val Loss: 1.1579, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 402/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.505]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 412/1000, Time: 0.90s\n",
      "Train Loss: 0.5048\n",
      "Val Loss: 1.1579, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 403/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.507]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 413/1000, Time: 0.91s\n",
      "Train Loss: 0.5069\n",
      "Val Loss: 1.1579, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 404/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 414/1000, Time: 0.92s\n",
      "Train Loss: 0.4959\n",
      "Val Loss: 1.1579, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 405/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 415/1000, Time: 0.90s\n",
      "Train Loss: 0.4966\n",
      "Val Loss: 1.1579, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 406/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 416/1000, Time: 0.93s\n",
      "Train Loss: 0.4962\n",
      "Val Loss: 1.1579, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 407/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s, loss=0.503]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 417/1000, Time: 0.95s\n",
      "Train Loss: 0.5030\n",
      "Val Loss: 1.1580, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 408/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s, loss=0.494]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 418/1000, Time: 0.95s\n",
      "Train Loss: 0.4942\n",
      "Val Loss: 1.1580, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 409/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s, loss=0.495]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419/1000, Time: 0.93s\n",
      "Train Loss: 0.4955\n",
      "Val Loss: 1.1580, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 410/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s, loss=0.494]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 420/1000, Time: 0.97s\n",
      "Train Loss: 0.4941\n",
      "Val Loss: 1.1580, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 411/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s, loss=0.495]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/1000, Time: 0.95s\n",
      "Train Loss: 0.4949\n",
      "Val Loss: 1.1580, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 412/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 422/1000, Time: 0.95s\n",
      "Train Loss: 0.4974\n",
      "Val Loss: 1.1580, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 413/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s, loss=0.5]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 423/1000, Time: 0.93s\n",
      "Train Loss: 0.5002\n",
      "Val Loss: 1.1580, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 414/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.505]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 424/1000, Time: 0.90s\n",
      "Train Loss: 0.5050\n",
      "Val Loss: 1.1580, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 415/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 425/1000, Time: 0.92s\n",
      "Train Loss: 0.4963\n",
      "Val Loss: 1.1581, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 416/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s, loss=0.491]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 426/1000, Time: 0.87s\n",
      "Train Loss: 0.4911\n",
      "Val Loss: 1.1581, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 417/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, loss=0.503]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 427/1000, Time: 0.88s\n",
      "Train Loss: 0.5030\n",
      "Val Loss: 1.1581, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 418/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s, loss=0.485]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 428/1000, Time: 0.86s\n",
      "Train Loss: 0.4850\n",
      "Val Loss: 1.1581, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 419/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.73it/s, loss=0.493]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 429/1000, Time: 0.85s\n",
      "Train Loss: 0.4926\n",
      "Val Loss: 1.1581, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 420/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.72it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 430/1000, Time: 0.86s\n",
      "Train Loss: 0.4975\n",
      "Val Loss: 1.1581, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 421/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, loss=0.493]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 431/1000, Time: 0.87s\n",
      "Train Loss: 0.4935\n",
      "Val Loss: 1.1581, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 422/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.72it/s, loss=0.495]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 432/1000, Time: 0.86s\n",
      "Train Loss: 0.4952\n",
      "Val Loss: 1.1581, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 423/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.72it/s, loss=0.495]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 433/1000, Time: 0.86s\n",
      "Train Loss: 0.4953\n",
      "Val Loss: 1.1581, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 424/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s, loss=0.499]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 434/1000, Time: 0.87s\n",
      "Train Loss: 0.4988\n",
      "Val Loss: 1.1581, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 425/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.5]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 435/1000, Time: 0.89s\n",
      "Train Loss: 0.5001\n",
      "Val Loss: 1.1581, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 426/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.503]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 436/1000, Time: 0.91s\n",
      "Train Loss: 0.5033\n",
      "Val Loss: 1.1582, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 427/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s, loss=0.488]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 437/1000, Time: 0.93s\n",
      "Train Loss: 0.4875\n",
      "Val Loss: 1.1582, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 428/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.5]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 438/1000, Time: 0.90s\n",
      "Train Loss: 0.5001\n",
      "Val Loss: 1.1582, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 429/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s, loss=0.499]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 439/1000, Time: 0.92s\n",
      "Train Loss: 0.4988\n",
      "Val Loss: 1.1582, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 430/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s, loss=0.494]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 440/1000, Time: 0.91s\n",
      "Train Loss: 0.4940\n",
      "Val Loss: 1.1582, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 431/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, loss=0.501]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/1000, Time: 0.88s\n",
      "Train Loss: 0.5015\n",
      "Val Loss: 1.1582, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 432/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.71it/s, loss=0.501]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 442/1000, Time: 0.86s\n",
      "Train Loss: 0.5009\n",
      "Val Loss: 1.1582, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 433/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.72it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 443/1000, Time: 0.86s\n",
      "Train Loss: 0.4982\n",
      "Val Loss: 1.1582, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 434/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.504]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 444/1000, Time: 0.90s\n",
      "Train Loss: 0.5043\n",
      "Val Loss: 1.1582, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 435/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, loss=0.495]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445/1000, Time: 0.89s\n",
      "Train Loss: 0.4946\n",
      "Val Loss: 1.1582, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 436/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.509]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 446/1000, Time: 0.89s\n",
      "Train Loss: 0.5087\n",
      "Val Loss: 1.1582, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 437/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.493]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 447/1000, Time: 0.89s\n",
      "Train Loss: 0.4928\n",
      "Val Loss: 1.1582, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 438/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448/1000, Time: 0.87s\n",
      "Train Loss: 0.4972\n",
      "Val Loss: 1.1582, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 439/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s, loss=0.498]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/1000, Time: 0.88s\n",
      "Train Loss: 0.4978\n",
      "Val Loss: 1.1582, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 440/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.499]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 450/1000, Time: 0.92s\n",
      "Train Loss: 0.4993\n",
      "Val Loss: 1.1582, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 441/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 451/1000, Time: 0.91s\n",
      "Train Loss: 0.4962\n",
      "Val Loss: 1.1582, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 442/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s, loss=0.494]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 452/1000, Time: 0.87s\n",
      "Train Loss: 0.4941\n",
      "Val Loss: 1.1582, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 443/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.505]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 453/1000, Time: 0.90s\n",
      "Train Loss: 0.5049\n",
      "Val Loss: 1.1582, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 444/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 454/1000, Time: 0.89s\n",
      "Train Loss: 0.5020\n",
      "Val Loss: 1.1583, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 445/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455/1000, Time: 0.91s\n",
      "Train Loss: 0.5021\n",
      "Val Loss: 1.1583, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 446/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s, loss=0.494]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 456/1000, Time: 0.95s\n",
      "Train Loss: 0.4943\n",
      "Val Loss: 1.1583, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 447/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s, loss=0.507]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000, Time: 0.94s\n",
      "Train Loss: 0.5066\n",
      "Val Loss: 1.1583, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 448/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s, loss=0.494]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 458/1000, Time: 0.95s\n",
      "Train Loss: 0.4938\n",
      "Val Loss: 1.1583, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 449/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 459/1000, Time: 0.91s\n",
      "Train Loss: 0.5022\n",
      "Val Loss: 1.1583, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 450/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s, loss=0.499]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 460/1000, Time: 0.93s\n",
      "Train Loss: 0.4994\n",
      "Val Loss: 1.1583, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 451/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, loss=0.504]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 461/1000, Time: 0.89s\n",
      "Train Loss: 0.5041\n",
      "Val Loss: 1.1583, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 452/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 462/1000, Time: 0.89s\n",
      "Train Loss: 0.4963\n",
      "Val Loss: 1.1583, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 453/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 463/1000, Time: 0.89s\n",
      "Train Loss: 0.4956\n",
      "Val Loss: 1.1583, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 454/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, loss=0.501]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 464/1000, Time: 0.88s\n",
      "Train Loss: 0.5008\n",
      "Val Loss: 1.1583, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 455/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s, loss=0.505]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/1000, Time: 0.87s\n",
      "Train Loss: 0.5053\n",
      "Val Loss: 1.1583, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 456/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s, loss=0.495]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 466/1000, Time: 0.92s\n",
      "Train Loss: 0.4953\n",
      "Val Loss: 1.1583, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 457/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 467/1000, Time: 0.90s\n",
      "Train Loss: 0.5023\n",
      "Val Loss: 1.1583, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 458/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.489]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 468/1000, Time: 0.89s\n",
      "Train Loss: 0.4890\n",
      "Val Loss: 1.1583, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 459/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.71it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 469/1000, Time: 0.86s\n",
      "Train Loss: 0.4974\n",
      "Val Loss: 1.1583, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 460/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.72it/s, loss=0.491]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 470/1000, Time: 0.88s\n",
      "Train Loss: 0.4911\n",
      "Val Loss: 1.1583, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 461/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s, loss=0.499]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 471/1000, Time: 0.93s\n",
      "Train Loss: 0.4987\n",
      "Val Loss: 1.1583, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 462/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s, loss=0.507]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 472/1000, Time: 0.93s\n",
      "Train Loss: 0.5069\n",
      "Val Loss: 1.1583, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 463/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s, loss=0.494]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 473/1000, Time: 0.95s\n",
      "Train Loss: 0.4942\n",
      "Val Loss: 1.1583, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 464/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s, loss=0.499]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 474/1000, Time: 0.94s\n",
      "Train Loss: 0.4990\n",
      "Val Loss: 1.1583, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 465/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s, loss=0.5]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/1000, Time: 0.93s\n",
      "Train Loss: 0.5004\n",
      "Val Loss: 1.1583, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 466/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s, loss=0.499]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 476/1000, Time: 0.93s\n",
      "Train Loss: 0.4991\n",
      "Val Loss: 1.1583, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 467/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.504]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 477/1000, Time: 0.90s\n",
      "Train Loss: 0.5035\n",
      "Val Loss: 1.1583, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 468/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 478/1000, Time: 0.89s\n",
      "Train Loss: 0.4958\n",
      "Val Loss: 1.1584, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 469/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, loss=0.488]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 479/1000, Time: 0.90s\n",
      "Train Loss: 0.4884\n",
      "Val Loss: 1.1584, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 470/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 480/1000, Time: 0.88s\n",
      "Train Loss: 0.4971\n",
      "Val Loss: 1.1584, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 471/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/1000, Time: 0.89s\n",
      "Train Loss: 0.4967\n",
      "Val Loss: 1.1584, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 472/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, loss=0.501]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 482/1000, Time: 0.89s\n",
      "Train Loss: 0.5007\n",
      "Val Loss: 1.1584, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 473/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, loss=0.504]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 483/1000, Time: 0.88s\n",
      "Train Loss: 0.5039\n",
      "Val Loss: 1.1584, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 474/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.492]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 484/1000, Time: 0.91s\n",
      "Train Loss: 0.4917\n",
      "Val Loss: 1.1584, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 475/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s, loss=0.499]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 485/1000, Time: 0.92s\n",
      "Train Loss: 0.4992\n",
      "Val Loss: 1.1584, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 476/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.71it/s, loss=0.5]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 486/1000, Time: 0.86s\n",
      "Train Loss: 0.4999\n",
      "Val Loss: 1.1584, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 477/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.73it/s, loss=0.503]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 487/1000, Time: 0.86s\n",
      "Train Loss: 0.5028\n",
      "Val Loss: 1.1584, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 478/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s, loss=0.501]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 488/1000, Time: 0.92s\n",
      "Train Loss: 0.5010\n",
      "Val Loss: 1.1584, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 479/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 489/1000, Time: 0.91s\n",
      "Train Loss: 0.4966\n",
      "Val Loss: 1.1584, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 480/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s, loss=0.501]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 490/1000, Time: 0.95s\n",
      "Train Loss: 0.5011\n",
      "Val Loss: 1.1584, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 481/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 491/1000, Time: 0.91s\n",
      "Train Loss: 0.5021\n",
      "Val Loss: 1.1584, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 482/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 492/1000, Time: 0.91s\n",
      "Train Loss: 0.4957\n",
      "Val Loss: 1.1584, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 483/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.489]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 493/1000, Time: 0.90s\n",
      "Train Loss: 0.4887\n",
      "Val Loss: 1.1584, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 484/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, loss=0.488]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 494/1000, Time: 0.89s\n",
      "Train Loss: 0.4882\n",
      "Val Loss: 1.1584, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 485/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 495/1000, Time: 0.88s\n",
      "Train Loss: 0.4970\n",
      "Val Loss: 1.1585, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 486/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496/1000, Time: 0.89s\n",
      "Train Loss: 0.5023\n",
      "Val Loss: 1.1585, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 487/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, loss=0.495]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 497/1000, Time: 0.89s\n",
      "Train Loss: 0.4954\n",
      "Val Loss: 1.1585, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 488/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s, loss=0.492]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 498/1000, Time: 0.87s\n",
      "Train Loss: 0.4917\n",
      "Val Loss: 1.1585, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 489/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s, loss=0.491]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499/1000, Time: 0.88s\n",
      "Train Loss: 0.4911\n",
      "Val Loss: 1.1585, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 490/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s, loss=0.503]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/1000, Time: 0.87s\n",
      "Train Loss: 0.5034\n",
      "Val Loss: 1.1585, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 491/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.496]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 501/1000, Time: 0.89s\n",
      "Train Loss: 0.4957\n",
      "Val Loss: 1.1585, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 492/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.72it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 502/1000, Time: 0.86s\n",
      "Train Loss: 0.5018\n",
      "Val Loss: 1.1585, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 493/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, loss=0.491]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 503/1000, Time: 0.88s\n",
      "Train Loss: 0.4914\n",
      "Val Loss: 1.1585, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 494/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, loss=0.497]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 504/1000, Time: 0.90s\n",
      "Train Loss: 0.4970\n",
      "Val Loss: 1.1585, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 495/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, loss=0.492]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505/1000, Time: 0.89s\n",
      "Train Loss: 0.4922\n",
      "Val Loss: 1.1585, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 496/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 506/1000, Time: 0.92s\n",
      "Train Loss: 0.5016\n",
      "Val Loss: 1.1585, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 497/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s, loss=0.493]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 507/1000, Time: 0.94s\n",
      "Train Loss: 0.4931\n",
      "Val Loss: 1.1585, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 498/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s, loss=0.502]\n",
      "C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 508/1000, Time: 0.91s\n",
      "Train Loss: 0.5022\n",
      "Val Loss: 1.1585, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 499/500\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\ishan\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, loss=0.488]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 509/1000, Time: 0.89s\n",
      "Train Loss: 0.4881\n",
      "Val Loss: 1.1585, Accuracy: 0.5300, F1: 0.5648\n",
      "Best Val F1: 0.6689 (Epoch 9)\n",
      "Patience: 500/500\n",
      "--------------------------------------------------\n",
      "Early stopping after 509 epochs\n",
      "Test Results:\n",
      "Loss: 1.4471, Accuracy: 0.4000\n",
      "Precision: 0.4000, Recall: 0.4000, F1: 0.4000\n",
      "Confusion Matrix:\n",
      "[[ 8 12]\n",
      " [12  8]]\n",
      "Training complete for fine_tuned_vit! Best validation F1 score: 0.6689\n"
     ]
    }
   ],
   "source": [
    "print('Fine Tuned ViT')\n",
    "fine_tuned_vit_model = run_model(config, 'fine_tuned_vit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 40 videos from FF++/real to FF++/eval_videos/\n",
      "Copied 40 videos from FF++/fake to FF++/eval_videos/\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "def split_and_copy_eval_videos(source_dir, dest_dir, label_prefix, eval_ratio=0.1, seed=42):\n",
    "    video_paths = list(Path(source_dir).rglob(\"*.mp4\")) + \\\n",
    "                  list(Path(source_dir).rglob(\"*.avi\")) + \\\n",
    "                  list(Path(source_dir).rglob(\"*.mov\"))\n",
    "\n",
    "    eval_paths, _ = train_test_split(\n",
    "        video_paths, test_size=(1 - eval_ratio), random_state=seed\n",
    "    )\n",
    "\n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "\n",
    "    for i, src in enumerate(eval_paths):\n",
    "        new_name = f\"{label_prefix}_{i+1:03d}{src.suffix}\"\n",
    "        dest_path = os.path.join(dest_dir, new_name)\n",
    "        shutil.copy2(src, dest_path)\n",
    "\n",
    "    print(f\"Copied {len(eval_paths)} videos from {source_dir} to {dest_dir}\")\n",
    "\n",
    "split_and_copy_eval_videos(config['real_dir'], config['eval_dir'], 'real', eval_ratio=0.2)\n",
    "split_and_copy_eval_videos(config['fake_dir'], config['eval_dir'], 'fake', eval_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation_pipeline(config, model, model_type, device=None):\n",
    "    \n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "\n",
    "    if 'eval_dir' not in config or not os.path.exists(config['eval_dir']):\n",
    "        print(\"Evaluation directory not specified or does not exist.\")\n",
    "        return\n",
    "\n",
    "    eval_output_dir = os.path.join(config['output_dir'], 'evaluations', model_type)\n",
    "    os.makedirs(eval_output_dir, exist_ok=True)\n",
    "\n",
    "    print(\"Running prediction on evaluation videos...\")\n",
    "    results_df = predict_videos(\n",
    "        video_dir=config['eval_dir'],\n",
    "        model=model,\n",
    "        device=device,\n",
    "        output_csv=os.path.join(eval_output_dir, 'predictions.csv'),\n",
    "        sample_rate=config['sample_rate'],\n",
    "        max_frames=config['max_frames'],\n",
    "        resize_width=config['resize_width'],\n",
    "        resize_height=config['resize_height']\n",
    "    )\n",
    "\n",
    "    print(\"Generating result visualizations...\")\n",
    "    visualize_results(results_df, output_dir=config['output_dir'])\n",
    "    print(\"Evaluation pipeline complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running prediction on evaluation videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 80/80 [22:19<00:00, 16.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to output/evaluations\\deep_model\\predictions.csv\n",
      "Summary: 80 videos processed\n",
      "Real: 21 (26.2%)\n",
      "Fake: 59 (73.8%)\n",
      "Generating result visualizations...\n",
      "Evaluation pipeline complete.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAJOCAYAAACqS2TfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAACIE0lEQVR4nOzdd3zU9eHH8fft7L0hIew9ZDhwAC4c4K51r1b9uS3WWrVatSpqh7hbbRVaV60TraAWQRyADNlhCiSQhAyyx93l7vv740IgQiBALt9L8no+eo/73ve+d/dOSIV3Pp/v52sxDMMQAAAAAABoc1azAwAAAAAA0FlRugEAAAAACBJKNwAAAAAAQULpBgAAAAAgSCjdAAAAAAAECaUbAAAAAIAgoXQDAAAAABAklG4AAAAAAIKE0g0AAAAAQJBQugEAIWflypW69tpr1bNnT4WFhSkqKkojR47UU089pV27dgX1s3/44QeNGzdOsbGxslgsmjZtmubNmyeLxaJ58+Yd9PXXXHONsrOzg5qxPVxzzTWyWCxNt8jISGVnZ+ucc87Ra6+9Jrfbvc9rxo8fr/Hjxx/S56xdu1YPPfSQtm7dekiv++lnbd26VRaLRX/6058O6X0O5vHHH9eHH364z/5D+ZkAAHRtdrMDAACwt1deeUU333yz+vfvr7vvvluDBg2S1+vVkiVL9Ne//lULFizQBx98ELTPv+6661RTU6O3335b8fHxys7OVkREhBYsWKBBgwYF7XNDUXh4uL788ktJUl1dnfLy8jRr1ixdf/31+vOf/6zZs2ere/fuTce/+OKLh/wZa9eu1cMPP6zx48cf0i8rDuezDsfjjz+uiy66SOedd16z/SNHjuySPxMAgENH6QYAhIwFCxbopptu0mmnnaYPP/xQLper6bnTTjtNd911l2bPnh3UDKtXr9b111+vM888s9n+Y489NqifG4qsVus+X/dVV12la6+9VpMmTdJFF12khQsXNj3XHgW0trZWERERppfdmJiYLvkzAQA4dEwvBwCEjMcff1wWi0Uvv/xys8K9m9Pp1DnnnNP02O/366mnntKAAQPkcrmUkpKiq666Stu3b2/2uvHjx2vIkCFavHixTjzxREVERKhXr1564okn5Pf7JUnTp0+XxWJRQ0ODXnrppaZp1VLLU4mnT5+u/v37y+VyaeDAgfrnP/+536/L4/Ho0UcfbcqZnJysa6+9VsXFxc2Oy87O1qRJkzR79myNHDlS4eHhGjBggF599dV93nPHjh264YYblJmZKafTqYyMDF100UXauXNn0zGVlZX69a9/rZ49e8rpdKpbt2668847VVNTc4A/hYM7/fTTdf3112vRokWaP39+0/79TS9/6aWXNHz4cEVFRSk6OloDBgzQfffdJynw/fvZz34mSZowYULT93z69OlN7zdkyBDNnz9fY8eOVUREhK677roWP0sK/Ew89thjysrKUlhYmEaPHq05c+Y0O6alUwAeeuihpj9zSbJYLKqpqdGMGTOasu3+zJZ+JmbOnKnjjjtOERERio6O1mmnnaYFCxbs93PWrFmjSy+9VLGxsUpNTdV1112nioqK/X7PAQAdF6UbABASfD6fvvzyS40aNUqZmZmtes1NN92ke+65R6eddppmzpypP/zhD5o9e7bGjh2rkpKSZscWFhbq8ssv1xVXXKGZM2fqzDPP1L333qvXX39dknT22Wc3laOLLrpICxYs2Kcs7W369Om69tprNXDgQL333nv63e9+pz/84Q9N07F38/v9Ovfcc/XEE0/osssu03//+1898cQT+uKLLzR+/HjV1dU1O37FihW666679Ktf/UofffSRhg0bpl/84hfNyu2OHTs0ZswYffDBB5oyZYpmzZqladOmKTY2VmVlZZICI8Ljxo3TjBkzdPvtt2vWrFm65557NH36dJ1zzjkyDKNV3+OW7P7lx965furtt9/WzTffrHHjxumDDz7Qhx9+qF/96ldNpf/ss8/W448/Lkl64YUXmr7nZ599dtN7FBQU6IorrtBll12mTz/9VDfffPMBcz3//POaPXu2pk2bptdff11Wq1VnnnnmAf8sW7JgwQKFh4frrLPOasp2oGntb775ps4991zFxMTorbfe0j/+8Q+VlZVp/Pjx+uabb/Y5/sILL1S/fv303nvv6be//a3efPNN/epXvzrknACAEGcAABACCgsLDUnGJZdc0qrjc3JyDEnGzTff3Gz/okWLDEnGfffd17Rv3LhxhiRj0aJFzY4dNGiQMXHixGb7JBm33HJLs31z5841JBlz5841DMMwfD6fkZGRYYwcOdLw+/1Nx23dutVwOBxGjx49mva99dZbhiTjvffea/aeixcvNiQZL774YtO+Hj16GGFhYca2bdua9tXV1RkJCQnGjTfe2LTvuuuuMxwOh7F27doWvz9Tp041rFarsXjx4mb73333XUOS8emnn7b4WsMwjKuvvtqIjIxs8fnd3/+bbrqpad+4ceOMcePGNT2+9dZbjbi4uAN+zn/+859m39u97f5zmzNnzn6f2/uztmzZYkgyMjIyjLq6uqb9lZWVRkJCgnHqqac2+9r2/jPa7fe//73x038aRUZGGldfffU+x7b0MzF06FDD5/M1HVdVVWWkpKQYY8eO3edznnrqqWbvefPNNxthYWHNfqYAAB0fI90AgA5p7ty5kgJThfd29NFHa+DAgftMKU5LS9PRRx/dbN+wYcO0bdu2Q/7s9evXKz8/X5dddlmz6cg9evTQ2LFjmx37ySefKC4uTpMnT1ZDQ0PTbcSIEUpLS9tnevKIESOUlZXV9DgsLEz9+vVrlnPWrFmaMGGCBg4c2GLGTz75REOGDNGIESOafe7EiRPbZNVtoxUj5UcffbTKy8t16aWX6qOPPtpn9kFrxMfH6+STT2718RdccIHCwsKaHkdHR2vy5MmaP3++fD7fIX9+a+3+mbjyyitlte7551VUVJQuvPBCLVy4ULW1tc1es/epElLg57G+vl5FRUVBywkAaH+UbgBASEhKSlJERIS2bNnSquNLS0slSenp6fs8l5GR0fT8bomJifsc53K59pnefSifnZaWts9zP923c+dOlZeXy+l0yuFwNLsVFhbuU0Rbk7O4uLjZquH7s3PnTq1cuXKfz4yOjpZhGIdVgPe2+5cAGRkZLR5z5ZVX6tVXX9W2bdt04YUXKiUlRcccc4y++OKLVn/O/v58D6SlPxOPx6Pq6upDeq9DcbCfR7/f3zT1f7ef/lnvXsfgcH4mAQChi9XLAQAhwWaz6ZRTTtGsWbO0ffv2g5bK3YWloKBgn2Pz8/OVlJQUtKy7P7uwsHCf5366LykpSYmJiS2uuh4dHX3In5+cnLzPYnE/lZSUpPDw8P0uwrb7+SMxc+ZMSTrodbmvvfZaXXvttaqpqdH8+fP1+9//XpMmTdKGDRvUo0ePg37O3jMJWqOlPxOn06moqChJgdkD+7vO+JH8ImLvn8efys/Pl9VqVXx8/GG/PwCg42KkGwAQMu69914ZhqHrr79eHo9nn+e9Xq8+/vhjSWqacrx7IbTdFi9erJycHJ1yyilBy9m/f3+lp6frrbfeajbNetu2bfruu++aHTtp0iSVlpbK5/Np9OjR+9z69+9/yJ9/5plnau7cuVq/fn2Lx0yaNEmbN29WYmLifj/3UK6J/VNffPGF/v73v2vs2LE64YQTWvWayMhInXnmmbr//vvl8Xi0Zs0aSW0/uvv++++rvr6+6XFVVZU+/vhjnXjiibLZbJICq8QXFRU1W+nd4/Hos88+2+f9Wjsbon///urWrZvefPPNZj8TNTU1eu+995pWNAcAdD2MdAMAQsZxxx2nl156STfffLNGjRqlm266SYMHD5bX69UPP/ygl19+WUOGDNHkyZPVv39/3XDDDXruueeaVqjeunWrHnjgAWVmZgZ1FWir1ao//OEP+uUvf6nzzz9f119/vcrLy/XQQw/tM735kksu0RtvvKGzzjpLd9xxh44++mg5HA5t375dc+fO1bnnnqvzzz//kD7/kUce0axZs3TSSSfpvvvu09ChQ1VeXq7Zs2drypQpGjBggO6880699957Oumkk/SrX/1Kw4YNk9/vV25urj7//HPdddddOuaYYw74OX6/v+k63G63W7m5uZo1a5beeecdDRw4UO+8884BX3/99dcrPDxcxx9/vNLT01VYWKipU6cqNjZWY8aMkSQNGTJEkvTyyy8rOjpaYWFh6tmz536n2beGzWbTaaedpilTpsjv9+vJJ59UZWWlHn744aZjfv7zn+vBBx/UJZdcorvvvlv19fV69tln93vO99ChQzVv3jx9/PHHSk9PV3R09H5/UWK1WvXUU0/p8ssv16RJk3TjjTfK7Xbrj3/8o8rLy/XEE08c1tcDAOj4KN0AgJBy/fXX6+ijj9bTTz+tJ598UoWFhXI4HOrXr58uu+wy3XrrrU3HvvTSS+rdu7f+8Y9/6IUXXlBsbKzOOOMMTZ069bBLW2v94he/kCQ9+eSTuuCCC5Sdna377rtPX331VbNFymw2m2bOnKlnnnlG//rXvzR16lTZ7XZ1795d48aN09ChQw/5s7t166bvv/9ev//97/XEE0+otLRUycnJOuGEE5SQkCApMLL89ddf64knntDLL7+sLVu2KDw8XFlZWTr11FNbNdJdV1en4447TpIUHh6u5ORkDR8+XK+88oouv/xyOZ3OA77+xBNP1PTp0/XOO++orKxMSUlJOuGEE/TPf/5TycnJkqSePXtq2rRpeuaZZzR+/Hj5fD699tpr+yyQ11q33nqr6uvrdfvtt6uoqEiDBw/Wf//7Xx1//PFNx/Ts2VMfffSR7rvvPl100UVKT0/XlClTVFxc3KycS9IzzzyjW265RZdccknTZdhaWoTusssuU2RkpKZOnaqf//znstlsOvbYYzV37tx9FtgDAHQdFqM1y48CAAAAAIBDxjndAAAAAAAECaUbAAAAAIAgoXQDAAAAABAklG4AAAAAAIKE0g0AAAAAQJBQugEAAAAACJJOf51uv9+v/Px8RUdHy2KxmB0HAAAAANAJGIahqqoqZWRkyGpteTy705fu/Px8ZWZmmh0DAAAAANAJ5eXlqXv37i0+3+lLd3R0tKTANyImJsbkNAAAAACAzqCyslKZmZlNnbMlnb50755SHhMTQ+kGAAAAALSpg53GzEJqAAAAAAAECaUbAAAAAIAgoXQDAAAAABAknf6c7tby+Xzyer1mx+hQHA6HbDab2TEAAAAAIGR1+dJtGIYKCwtVXl5udpQOKS4uTmlpaVwDHQAAAAD2o8uX7t2FOyUlRREREZTHVjIMQ7W1tSoqKpIkpaenm5wIAAAAAEJPly7dPp+vqXAnJiaaHafDCQ8PlyQVFRUpJSWFqeYAAAAA8BNdeiG13edwR0REmJyk49r9veN8eAAAAADYV5cu3bsxpfzw8b0DAAAAgJZRugEAAAAACBJKd4jIzs7WtGnTmh5bLBZ9+OGHR/SebfEeAAAAAIDD16UXUgtlBQUFio+Pb9WxDz30kD788EMtX778sN8DAAAAAND2KN1tyOPxyOl0tsl7paWlhcR7AAAAAAAOH9PLD2D8+PG69dZbdeuttyouLk6JiYn63e9+J8MwJAWmhD/66KO65pprFBsbq+uvv16S9N133+mkk05SeHi4MjMzdfvtt6umpqbpfYuKijR58mSFh4erZ8+eeuONN/b57J9ODd++fbsuueQSJSQkKDIyUqNHj9aiRYs0ffp0Pfzww1qxYoUsFossFoumT5++3/dYtWqVTj75ZIWHhysxMVE33HCDqqurm56/5pprdN555+lPf/qT0tPTlZiYqFtuuYWVyQEAAADgMFG6D2LGjBmy2+1atGiRnn32WT399NP6+9//3vT8H//4Rw0ZMkRLly7VAw88oFWrVmnixIm64IILtHLlSv373//WN998o1tvvbXpNddcc422bt2qL7/8Uu+++65efPFFFRUVtZihurpa48aNU35+vmbOnKkVK1boN7/5jfx+v37+85/rrrvu0uDBg1VQUKCCggL9/Oc/3+c9amtrdcYZZyg+Pl6LFy/Wf/7zH/3vf/9rlkuS5s6dq82bN2vu3LmaMWOGpk+f3lTiAQAAAACHhunlB5GZmamnn35aFotF/fv316pVq/T00083jWqffPLJ+vWvf910/FVXXaXLLrtMd955pySpb9++evbZZzVu3Di99NJLys3N1axZs7Rw4UIdc8wxkqR//OMfGjhwYIsZ3nzzTRUXF2vx4sVKSEiQJPXp06fp+aioKNnt9gNOJ3/jjTdUV1enf/7zn4qMjJQkPf/885o8ebKefPJJpaamSpLi4+P1/PPPy2azacCAATr77LM1Z86cpq8XAAAAANB6jHQfxLHHHtvsWtTHHXecNm7cKJ/PJ0kaPXp0s+OXLl2q6dOnKyoqquk2ceJE+f1+bdmyRTk5ObLb7c1eN2DAAMXFxbWYYfny5TrqqKOaCvfhyMnJ0fDhw5sKtyQdf/zx8vv9Wr9+fdO+wYMHy2azNT1OT08/4Cg8AAAAAKBlppbu+fPna/LkycrIyDjo5a1uvPFGWSyWZpfVCgV7l1hJ8vv9uvHGG7V8+fKm24oVK7Rx40b17t276XzwvYv8wYSHhx9xTsMwWvzMvfc7HI59nvP7/Uf8+QAAAADQFZlaumtqajR8+HA9//zzBzzuww8/1KJFi5SRkdFOyfZYuHDhPo/79u3bbDR4byNHjtSaNWvUp0+ffW5Op1MDBw5UQ0ODlixZ0vSa9evXq7y8vMUMw4YN0/Lly7Vr1679Pu90OptG3lsyaNAgLV++vNmCbt9++62sVqv69et3wNcCAAAAAA6PqaX7zDPP1KOPPqoLLrigxWN27NihW2+9VW+88cY+o7DtIS8vT1OmTNH69ev11ltv6bnnntMdd9zR4vH33HOPFixYoFtuuUXLly/Xxo0bNXPmTN12222SpP79++uMM87Q9ddfr0WLFmnp0qX65S9/ecDR7EsvvVRpaWk677zz9O233+rHH3/Ue++9pwULFkgKrKK+ZcsWLV++XCUlJXK73fu8x+WXX66wsDBdffXVWr16tebOnavbbrtNV155ZdP53AAAAACAthXSC6n5/X5deeWVuvvuuzV48OBWvcbtdjcrnZWVlUeU4aqrrlJdXZ2OPvpo2Ww23XbbbbrhhhtaPH7YsGH66quvdP/99+vEE0+UYRjq3bt3sxXFX3vtNf3yl7/UuHHjlJqaqkcffVQPPPBAi+/pdDr1+eef66677tJZZ52lhoYGDRo0SC+88IIk6cILL9T777+vCRMmqLy8XK+99pquueaaZu8RERGhzz77THfccYfGjBmjiIgIXXjhhfrLX/5yRN8fAAAAAB1Hbm6uSkpKzI5xUElJScrKyjI7RpuwGLtPMjaZxWLRBx98oPPOO69p39SpUzV37lx99tlnslgsys7O1p133tm0Mvj+PPTQQ3r44Yf32V9RUaGYmJhm++rr67Vlyxb17NlTYWFh+7xm/PjxGjFiRMidRx5KDvY9BAAAABAacnNzNWDgQNXV1pod5aDCIyK0LicnpIt3ZWWlYmNj99s19xayI91Lly7VM888o2XLlh3SomP33nuvpkyZ0vS4srJSmZmZwYgIAAAAAB1GSUmJ6mprdfk9f1RqVm+z47RoZ+5mvfHk3SopKQnp0t1aIVu6v/76axUVFTX7Jvt8Pt11112aNm2atm7dut/XuVwuuVyudkoJAAAAAB1LalZvde/butN3ceRCtnRfeeWVOvXUU5vtmzhxoq688kpde+217ZJh3rx57fI5AAAAAIDOydTSXV1drU2bNjU93r0Cd0JCgrKyspSYmNjseIfDobS0NPXv37+9owIAAAAAcMhMLd1LlizRhAkTmh7vPhf76quv1vTp001KBQAAAABA2zC1dI8fP16Hsnh6S+dxAwAAAAAQiqxmBwAAAAAAoLOidAMAAAAAECSUbgAAAAAAgiRkLxlmttzcXJWUlLTb5yUlJR3Shd8Nw9CNN96od999V2VlZfrhhx80YsSIFo/funWrevbsedDjAAAAAABth9K9H7m5uRowcKDqamvb7TPDIyK0Lien1cV79uzZmj59uubNm6devXopKSkpyAkBAAAAAIeK0r0fJSUlqqut1eX3/FGpWb2D/nk7czfrjSfvVklJSatL9+bNm5Wenq6xY8cGOR0AAAAA4HBRug8gNau3uvcdbHaMfVxzzTWaMWOGJMlisahHjx7661//qkcffVSrV6+WzWbTcccdp2eeeUa9e+//lwZ+v1833nijvvrqK33xxRfq0aOHPv74Yz300ENas2aNMjIydPXVV+v++++X3c6PCQAAAAAcDhZS64CeeeYZPfLII+revbsKCgq0ePFi1dTUaMqUKVq8eLHmzJkjq9Wq888/X36/f5/XezweXXzxxVqyZIm++eYb9ejRQ5999pmuuOIK3X777Vq7dq3+9re/afr06XrsscdM+AoBAAAAoHNgCLMDio2NVXR0tGw2m9LS0iRJF154YbNj/vGPfyglJUVr167VkCFDmvZXV1fr7LPPVl1dnebNm6fY2FhJ0mOPPabf/va3uvrqqyVJvXr10h/+8Af95je/0e9///t2+soAAAAAoHOhdHcSmzdv1gMPPKCFCxeqpKSkaYQ7Nze3Wem+9NJL1b17d82ZM0cRERFN+5cuXarFixc3G9n2+Xyqr69XbW1ts2MBAAAAAK1D6e4kJk+erMzMTL3yyivKyMiQ3+/XkCFD5PF4mh131lln6fXXX9fChQt18sknN+33+/16+OGHdcEFF+zz3mFhYUHPDwAAAACdEaW7EygtLVVOTo7+9re/6cQTT5QkffPNN/s99qabbtKQIUN0zjnn6L///a/GjRsnSRo5cqTWr1+vPn36tFtuAAAAAOjsKN2dQHx8vBITE/Xyyy8rPT1dubm5+u1vf9vi8bfddpt8Pp8mTZqkWbNm6YQTTtCDDz6oSZMmKTMzUz/72c9ktVq1cuVKrVq1So8++mg7fjUAAAAA0HlQug9gZ+7mDvE5VqtVb7/9tm6//XYNGTJE/fv317PPPqvx48e3+Jo777xTfr9fZ511lmbPnq2JEyfqk08+0SOPPKKnnnpKDodDAwYM0C9/+csjygYAAAAAXRmlez+SkpIUHhGhN568u90+MzwiQklJSa0+/s4779Sdd97Z9PjUU0/V2rVrmx1jGEbTdnZ2drPHkjRlyhRNmTKl6fHEiRM1ceLEQ0wOAAAAAGgJpXs/srKytC4nRyUlJe32mUlJScrKymq3zwMAAAAABB+luwVZWVmUYAAAAADAEbGaHQAAAAAAgM6K0g0AAAAAQJBQugEAAAAACBJKNwAAAAAAQULpBgAAAAAgSCjdAAAAAAAECaUbAAAAAIAg4TrdLcjNzVVJSUm7fV5SUpLp1wXfunWrevbsqR9++EEjRowwNQsAAAAAdAaU7v3Izc3VwIEDVFtb126fGRERrpycdaYXbwAAAABA26F070dJSYlqa+v0+n0Xa2BWctA/Lye3WFc8/o5KSkoOu3R7PB45nc42TgYAAAAAOBKU7gMYmJWskf26mR1jv8aPH68hQ4bI6XTqn//8pwYPHqyXXnpJv/71rzV//nxFRkbq9NNP19NPP62kpCRJ0uzZs/Xoo49q9erVstlsOu644/TMM8+od+/eJn81AAAAANA5sZBaBzZjxgzZ7XZ9++23euKJJzRu3DiNGDFCS5Ys0ezZs7Vz505dfPHFTcfX1NRoypQpWrx4sebMmSOr1arzzz9ffr/fxK8CAAAAADovRro7sD59+uipp56SJD344IMaOXKkHn/88abnX331VWVmZmrDhg3q16+fLrzwwmav/8c//qGUlBStXbtWQ4YMadfsAAAAANAVMNLdgY0ePbppe+nSpZo7d66ioqKabgMGDJAkbd68uen+sssuU69evRQTE6OePXtKCiwcBwAAAABoe4x0d2CRkZFN236/X5MnT9aTTz65z3Hp6emSpMmTJyszM1OvvPKKMjIy5Pf7NWTIEHk8nnbLDAAAAABdCaW7kxg5cqTee+89ZWdny27f94+1tLRUOTk5+tvf/qYTTzxRkvTNN9+0d0wAAAAA6FKYXt5J3HLLLdq1a5cuvfRSff/99/rxxx/1+eef67rrrpPP51N8fLwSExP18ssva9OmTfryyy81ZcoUs2MDAAAAQKfGSPcB5OQWd5jPycjI0Lfffqt77rlHEydOlNvtVo8ePXTGGWfIarXKYrHo7bff1u23364hQ4aof//+evbZZzV+/Pgj/wIAAAAAAPtF6d6PpKQkRUSE64rH32m3z4yICG+6nnZrzJs3b599ffv21fvvv9/ia0499VStXbu22T7DMJq2s7Ozmz0GAAAAABwZSvd+ZGVlKSdnnUpKStrtM5OSkpSVldVunwcAAAAACD5KdwuysrIowQAAAACAI8JCagAAAAAABAmlGwAAAACAIKF0AwAAAAAQJJRuSX6/3+wIHRbfOwAAAABoWZdeSM3pdMpqtSo/P1/JyclyOp2yWCxmx+oQDMOQx+NRcXGxrFarnE6n2ZEAAAAAIOR06dJttVrVs2dPFRQUKD8/3+w4HVJERISysrJktTJpAgAAAAB+qkuXbikw2p2VlaWGhgb5fD6z43QoNptNdrud2QEAAAAA0IIuX7olyWKxyOFwyOFwmB0FAAAAANCJMCcYAAAAAIAgoXQDAAAAABAklG4AAAAAAIKE0g0AAAAAQJBQugEAAAAACBJKNwAAAAAAQULpBgAAAAAgSCjdAAAAAAAECaUbAAAAAIAgoXQDAAAAABAklG4AAAAAAIKE0g0AAAAAQJCYWrrnz5+vyZMnKyMjQxaLRR9++GHTc16vV/fcc4+GDh2qyMhIZWRk6KqrrlJ+fr55gQEAAAAAOASmlu6amhoNHz5czz///D7P1dbWatmyZXrggQe0bNkyvf/++9qwYYPOOeccE5ICAAAAAHDo7GZ++Jlnnqkzzzxzv8/Fxsbqiy++aLbvueee09FHH63c3FxlZWW1R0QAAAAAAA6bqaX7UFVUVMhisSguLq7FY9xut9xud9PjysrKdkgGAAAAAMC+OsxCavX19frtb3+ryy67TDExMS0eN3XqVMXGxjbdMjMz2zElAAAAAAB7dIjS7fV6dckll8jv9+vFF1884LH33nuvKioqmm55eXntlBIAAAAAgOZCfnq51+vVxRdfrC1btujLL7884Ci3JLlcLrlcrnZKBwAAAABAy0K6dO8u3Bs3btTcuXOVmJhodiQAAAAAAFrN1NJdXV2tTZs2NT3esmWLli9froSEBGVkZOiiiy7SsmXL9Mknn8jn86mwsFCSlJCQIKfTaVZsAAAAAABaxdTSvWTJEk2YMKHp8ZQpUyRJV199tR566CHNnDlTkjRixIhmr5s7d67Gjx/fXjEBAAAAADgsppbu8ePHyzCMFp8/0HMAAAAAAIS6DrF6OQAAAAAAHRGlGwAAAACAIKF0AwAAAAAQJJRuAAAAAACChNINAAAAAECQULoBAAAAAAgSSjcAAAAAAEFC6QYAAAAAIEgo3QAAAAAABAmlGwAAAACAIKF0AwAAAAAQJJRuAAAAAACChNINAAAAAECQULoBAAAAAAgSSjcAAAAAAEFC6QYAAAAAIEgo3QAAAAAABAmlGwAAAACAIKF0AwAAAAAQJJRuAAAAAACChNINAAAAAECQULoBAAAAAAgSSjcAAAAAAEFC6QYAAAAAIEgo3QAAAAAABAmlGwAAAACAIKF0AwAAAAAQJJRuAAAAAACChNINAAAAAECQULoBAAAAAAgSSjcAAAAAAEFC6QYAAAAAIEgo3QAAAAAABAmlGwAAAACAIKF0AwAAAAAQJJRuAAAAAACChNINAAAAAECQULoBAAAAAAgSSjcAAAAAAEFC6QYAAAAAIEgo3QAAAAAABAmlGwAAAACAIKF0AwAAAAAQJJRuAAAAAACChNINAAAAAECQULoBAAAAAAgSSjcAAAAAAEFC6QYAAAAAIEgo3QAAAAAABAmlGwAAAACAIKF0AwAAAAAQJJRuAAAAAACChNINAAAAAECQULoBAAAAAAgSSjcAAAAAAEFC6QYAAAAAIEgo3QAAAAAABAmlGwAAAACAIDG1dM+fP1+TJ09WRkaGLBaLPvzww2bPG4ahhx56SBkZGQoPD9f48eO1Zs0ac8ICAAAAAHCITC3dNTU1Gj58uJ5//vn9Pv/UU0/pL3/5i55//nktXrxYaWlpOu2001RVVdXOSQEAAAAAOHR2Mz/8zDPP1Jlnnrnf5wzD0LRp03T//ffrggsukCTNmDFDqampevPNN3XjjTe2Z1QAAAAAAA5ZyJ7TvWXLFhUWFur0009v2udyuTRu3Dh99913Lb7O7XarsrKy2Q0AAAAAADOEbOkuLCyUJKWmpjbbn5qa2vTc/kydOlWxsbFNt8zMzKDmBAAAAACgJSFbunezWCzNHhuGsc++vd17772qqKhouuXl5QU7IgAAAAAA+2XqOd0HkpaWJikw4p2ent60v6ioaJ/R7725XC65XK6g5wMAAAAA4GBCdqS7Z8+eSktL0xdffNG0z+Px6KuvvtLYsWNNTAYAAAAAQOuYOtJdXV2tTZs2NT3esmWLli9froSEBGVlZenOO+/U448/rr59+6pv3756/PHHFRERocsuu8zE1AAAAAAAtI6ppXvJkiWaMGFC0+MpU6ZIkq6++mpNnz5dv/nNb1RXV6ebb75ZZWVlOuaYY/T5558rOjrarMgAAAAAALSaqaV7/PjxMgyjxectFoseeughPfTQQ+0XCgAAAACANhKy53QDAAAAANDRUboBAAAAAAgSSjcAAAAAAEFC6QYAAAAAIEgo3QAAAAAABAmlGwAAAACAIKF0AwAAAAAQJJRuAAAAAACChNINAAAAAECQULoBAAAAAAgSSjcAAAAAAEFC6QYAAAAAIEgo3QAAAAAABAmlGwAAAACAIKF0AwAAAAAQJJRuAAAAAACChNINAAAAAECQULoBAAAAAAgSSjcAAAAAAEFC6QYAAAAAIEgo3QAAAAAABAmlGwAAAACAIKF0AwAAAAAQJJRuAAAAAACChNINAAAAAECQULoBAAAAAAgSSjcAAAAAAEFC6QYAAAAAIEgo3QAAAAAABAmlGwAAAACAIKF0AwAAAAAQJJRuAAAAAACChNINAAAAAECQULoBAAAAAAgSSjcAAAAAAEFC6QYAAAAAIEgo3QAAAAAABAmlGwAAAACAIKF0AwAAAAAQJJRuAAAAAACChNINAAAAAECQULoBAAAAAAgSSjcAAAAAAEFC6QYAAAAAIEgo3QAAAAAABAmlGwAAAACAIKF0AwAAAAAQJJRuAAAAAACChNINAAAAAECQULoBAAAAAAgSSjcAAAAAAEFC6QYAAAAAIEgo3QAAAAAABAmlGwAAAACAIKF0AwAAAAAQJJRuAAAAAACChNINAAAAAECQULoBAAAAAAiSkC7dDQ0N+t3vfqeePXsqPDxcvXr10iOPPCK/3292NAAAAAAADspudoADefLJJ/XXv/5VM2bM0ODBg7VkyRJde+21io2N1R133GF2PAAAAAAADiikS/eCBQt07rnn6uyzz5YkZWdn66233tKSJUtMTgYAAAAAwMGF9PTyE044QXPmzNGGDRskSStWrNA333yjs846q8XXuN1uVVZWNrsBAAAAAGCGkB7pvueee1RRUaEBAwbIZrPJ5/Ppscce06WXXtria6ZOnaqHH364HVMCAAAAALB/IT3S/e9//1uvv/663nzzTS1btkwzZszQn/70J82YMaPF19x7772qqKhouuXl5bVjYgAAAAAA9gjpke67775bv/3tb3XJJZdIkoYOHapt27Zp6tSpuvrqq/f7GpfLJZfL1Z4xAQAAAADYr5Ae6a6trZXV2jyizWbjkmEAAAAAgA7hsEp3r169VFpaus/+8vJy9erV64hD7TZ58mQ99thj+u9//6utW7fqgw8+0F/+8hedf/75bfYZAAAAAAAEy2FNL9+6dat8Pt8++91ut3bs2HHEoXZ77rnn9MADD+jmm29WUVGRMjIydOONN+rBBx9ss88AAAAAACBYDql0z5w5s2n7s88+U2xsbNNjn8+nOXPmKDs7u83CRUdHa9q0aZo2bVqbvScAAAAAAO3lkEr3eeedJ0myWCz7LGTmcDiUnZ2tP//5z20WDgAAAACAjuyQSvfuBcx69uypxYsXKykpKSihAAAAAADoDA7rnO4tW7a0dQ4AAAAAADqdw75O95w5czRnzhwVFRXtcwmvV1999YiDAQAAAADQ0R1W6X744Yf1yCOPaPTo0UpPT5fFYmnrXAAAAAAAdHiHVbr/+te/avr06bryyivbOg8AAAAAAJ2G9XBe5PF4NHbs2LbOAgAAAABAp3JYpfuXv/yl3nzzzbbOAgAAAABAp3JY08vr6+v18ssv63//+5+GDRsmh8PR7Pm//OUvbRIOAAAAAICO7LBK98qVKzVixAhJ0urVq5s9x6JqAAAAAAAEHFbpnjt3blvnAAAAAACg0zmsc7oBAAAAAMDBHdZI94QJEw44jfzLL7887EAAAAAAAHQWh1W6d5/PvZvX69Xy5cu1evVqXX311W2RCwAAAACADu+wSvfTTz+93/0PPfSQqqurjygQAAAAAACdRZue033FFVfo1Vdfbcu3BAAAAACgw2rT0r1gwQKFhYW15VsCAAAAANBhHdb08gsuuKDZY8MwVFBQoCVLluiBBx5ok2AAAAAAAHR0h1W6Y2Njmz22Wq3q37+/HnnkEZ1++ultEgwAAAAAgI7usEr3a6+91tY5AAAAAADodA6rdO+2dOlS5eTkyGKxaNCgQTrqqKPaKhcAAAAAAB3eYZXuoqIiXXLJJZo3b57i4uJkGIYqKio0YcIEvf3220pOTm7rnAAAAAAAdDiHtXr5bbfdpsrKSq1Zs0a7du1SWVmZVq9ercrKSt1+++1tnREAAAAAgA7psEa6Z8+erf/9738aOHBg075BgwbphRdeYCE1AAAAAAAaHdZIt9/vl8Ph2Ge/w+GQ3+8/4lAAAAAAAHQGh1W6Tz75ZN1xxx3Kz89v2rdjxw796le/0imnnNJm4QAAAAAA6MgOq3Q///zzqqqqUnZ2tnr37q0+ffqoZ8+eqqqq0nPPPdfWGQEAAAAA6JAO65zuzMxMLVu2TF988YXWrVsnwzA0aNAgnXrqqW2dDwAAAACADuuQRrq//PJLDRo0SJWVlZKk0047Tbfddptuv/12jRkzRoMHD9bXX38dlKAAAAAAAHQ0h1S6p02bpuuvv14xMTH7PBcbG6sbb7xRf/nLX9osHAAAAAAAHdkhle4VK1bojDPOaPH5008/XUuXLj3iUAAAAAAAdAaHVLp37ty530uF7Wa321VcXHzEoQAAAAAA6AwOqXR369ZNq1atavH5lStXKj09/YhDAQAAAADQGRxS6T7rrLP04IMPqr6+fp/n6urq9Pvf/16TJk1qs3AAAAAAAHRkh3TJsN/97nd6//331a9fP916663q37+/LBaLcnJy9MILL8jn8+n+++8PVlYAAAAAADqUQyrdqamp+u6773TTTTfp3nvvlWEYkiSLxaKJEyfqxRdfVGpqalCCAgAAAADQ0RxS6ZakHj166NNPP1VZWZk2bdokwzDUt29fxcfHByMfAAAAAAAd1iGX7t3i4+M1ZsyYtswCAAAAAECnckgLqQEAAAAAgNajdAMAAAAAECSUbgAAAAAAgoTSDQAAAABAkFC6AQAAAAAIEko3AAAAAABBQukGAAAAACBIKN0AAAAAAAQJpRsAAAAAgCChdAMAAAAAECSUbgAAAAAAgoTSDQAAAABAkFC6AQAAAAAIEko3AAAAAABBQukGAAAAACBIKN0AAAAAAAQJpRsAAAAAgCChdAMAAAAAECSUbgAAAAAAgoTSDQAAAABAkIR86d6xY4euuOIKJSYmKiIiQiNGjNDSpUvNjgUAAAAAwEHZzQ5wIGVlZTr++OM1YcIEzZo1SykpKdq8ebPi4uLMjgYAAAAAwEGFdOl+8sknlZmZqddee61pX3Z2tnmBAAAAAAA4BCFdumfOnKmJEyfqZz/7mb766it169ZNN998s66//voWX+N2u+V2u5seV1ZWtkdUhKDc3FyVlJSYHeOgkpKSlJWVZXaMg+L7CQAwG38XdU38uaOjC+nS/eOPP+qll17SlClTdN999+n777/X7bffLpfLpauuumq/r5k6daoefvjhdk6KUJObm6uBAweotrbO7CgHFRERrpycdSH9H2m+nwAAs+Xm5mrAwIGqq601O8pBhUdEaF1ODn8XtQH+3NEZhHTp9vv9Gj16tB5//HFJ0lFHHaU1a9bopZdearF033vvvZoyZUrT48rKSmVmZrZLXoSOkpIS1dbW6fX7LtbArGSz47QoJ7dYVzz+jkpKSkL6P9B8PwEAZispKVFdba0uv+ePSs3qbXacFu3M3aw3nrybv4vaCH/u6AxCunSnp6dr0KBBzfYNHDhQ7733XouvcblccrlcwY6GDmJgVrJG9utmdoxOg+8nAMBsqVm91b3vYLNjoJ3x546OLKQvGXb88cdr/fr1zfZt2LBBPXr0MCkRAAAAAACtF9Ij3b/61a80duxYPf7447r44ov1/fff6+WXX9bLL79sdjSgczEMqXaXVFMkVTfePNVSykApbajZ6QAAAIAOK6RL95gxY/TBBx/o3nvv1SOPPKKePXtq2rRpuvzyy82OBnQOReuk1e9Kq96Vyrbs/xiLVQOjeujVc8IU5d4pienlAAAAQGuFdOmWpEmTJmnSpElmxwA6jwa3tOQ16YfXpZ2rmj8XHi9FpkhRKZI9TNq5WqoqUHjVFl17lFPa9bm0cqPU8yQpOt2c/AAAAEAHEvKlG0AbMQxp7YfSF7+XyrcF9lntUp9TpSEXSf3PkFzR+76uskCbv3lXX7z4G90wOkzWsi2BUfGkflLPcVJEYrt+GQAAAEBHQukGuoLtS6TP7pPyFgUeR6VJJ/1aGnKhFJFw4NfGpKsi7Xjd9N96nXDmxRpi3RQYAS/ZIJVtlQaeKyWG7iU8AAAAADNRuoHOrMEjzX1M+vYZSYbkiJDG3i4df7vkjDzkt/PYo6V+k6TMY6SNn0sVeYFzwvucKnUb1fb5AQAAgA6O0g10VqWbpfd+IeX/EHg8/FLplAelmIwjf+/IZGnYJdLGz6TCldKmL6S6XVLvUyRLSF+JEAAAAGhXlG6gszEMacVb0n9/LXlrAoujnfOcNHBy236O1Sb1O1MKT5C2zJN2LJXqK6RB5weeAwAAACCGpIDOpMEjfXy79OFNgcLd4wTp/75t+8K9m8UiZR0rDTovsChb6abA6LdhBOfzAAAAgA6GkW6gs6gpld65Str2TWCK9/j7pBOntM+oc/IAyeaUVv0nMN08PCFQxgEAAIAujpFuoDMoWif9/eRA4XZGS5f+Wxp3d/tO807oFVhQTQpMNy9e336fDQAAAIQoRrqBjm7THOk/10juSimuh3TZv6WUgeZk6TZKqi2V8pdJ6z6WXDFSTLo5WQAAAIAQwEg30JGtfEd68+JA4c4aK10/17zCvVufUwOj3v4Gac27krvK3DwAAACAiSjdQEe14AXp/esD5Xboz6SrPpIiE81OFTiffOC5gcuKeWqkDbNZWA0AAABdFqUb6GgMQ/riQemz+wKPj71ZOv9lye40N9fe7K5A8bbYpF2bA4urAQAAAF0QpRvoSHwN0ke3St8+E3h86kPSxMclawj+XzkySep5UmB785zANbwBAACALiYE/6UOYL8aPNJ7v5CWvx4YQT73BemEXwWulR2quo+RYrpLPo+0/lOmmQMAAKDLoXQDHYG3XnrnSmnth4HrYV/8T+moK8xOdXAWq9T/LMlql8q3Sfk/mJ0IAAAAaFeUbiDUeWoCK5RvmC3Zw6RL35IGTjI7VetFJEi9xge2f5wr1ZWZGgcAAABoT5RuIJTVV0r/ukDa8pXkjJKueC9wSa6OJmOUFJcl+b3Spi/MTgMAAAC0G0o3EKrqK6TXL5DyFkphsYFLgmWfYHaqw2OxSH3PCEw33/WjVLrZ7EQAAABAu6B0A6GoviIwwr19sRQWJ101U+o+2uxURyYiQerW+DX8+KXk95mbBwAAAGgHlG4g1Owu3DuWSOHx0tUzpYwRZqdqGz3GSo4IqbZUyl9mdhoAAAAg6CjdQCipr5D+df6ewn3VTCl9uNmp2o49TMpuvHb3tm8kb525eQAAAIAgo3QDocJdLb1+kbRjqRSeIF39sZQ+zOxUbS99mBSZIjW4pa1fm50GAAAACCpKNxACLA310luXSNu/D5zDffVMKW2o2bGCw2KVep8S2M7/QaopNjcPAAAAEESUbsBkTpvUe/EDgVFfZ7R05fudt3DvFt9DSuonyZA2zzU7DQAAABA0lG7ATIZf71wUrpjiJYEFxi7/j9RtlNmp2kevCYFR77IfpYrtZqcBAAAAgoLSDZjFMJRd/q3OHeCQ3+qQLn1b6nGc2anaT3i8lNo4or/1G3OzAAAAAEFiNzsA0CUZhrR5jhLqt8rrM/RNxvWKLY+WloXmZbRycnKC88Y9jpN2rpLKt0rluVJcVnA+BwAAADAJpRswQ96iwGXBJF33Ub1eX/WEpCfMzdQKVdXVbfuGYXFS2nCp4IfAaPeIy9r2/QEAAACTUbqB9la4UtoyT5K01Ndfr69arOdvPl3HDetrbq4D+PT7DXrg1S9UX1/f9m+edVzge1KRK5VtCyyyBgAAAHQSlG6gPZVuktbPCmxnHqN1P8ZLWqw+GfEa2a+bqdEOJCc3iJf1CouR0odL+csCK7jHZUkWS/A+DwAAAGhHLKQGtJfqImntR5IMKXWI1HO8yYFCSNZxktUuVW6XyraanQYAAABoM5RuoD14aqTV70p+rxTXQ+p3JqO5e3NFS+lHBba3fh1YaA4AAADoBCjdQLD5G6Q170vuSik8QRp0vmS1mZ0q9GQdGxjtrsoPrGQOAAAAdAKUbiCYDCNwDnflDsnukoZcJDnCzE4VmpyRUtqwwHbeQnOzAAAAAG2E0g0EU95CqWiNJEtghDsiwexEoa370ZIsUtkWqarQ7DQAAADAEaN0A8Gya4u05avAdt/TpfhsU+N0COFxUsrAwHbeIlOjAAAAAG2B0g0Eg7tKWvdxYDt9uJRxlLl5OpLMYwP3xeukujJzswAAAABHiNINtDXDL+V8JHlrpcgUqfepZifqWKJSpIRekgwp73uz0wAAAABHhNINtLUt86WK7ZLNKQ06T7I5zE7U8ewe7S5cKXmqzc0CAAAAHAFKN9CWSjftWXm7/1ksnHa4YjOl6AzJ8Enbl5qdBgAAADhslG6grbirpHWfBLYzRkrJA8zN05FZLIHrdktS/jKpwW1uHgAAAOAwUbqBtmAY0vpPpYZ6KSpN6n2y2Yk6vsS+UkSi5HMHppkDAAAAHRClG2gLhSsC15a22KQBkySr3exEHZ/FInUbHdjesSSwQB0AAADQwVC6gSNVXy5t/jKw3fMkKTLJ1DidSuoQyR4m1VdIJRvNTgMAAAAcMko3cCQMQ1r3qeTzSDHdpe5jzE7Uudgce65xvn2xuVkAAACAw0DpBo5E/lKpIleyOqQBZ0sW/i/V5jJGBr6vldulqgKz0wAAAACHhIYAHK66MunHeYHtXhOk8HhT43RarmgpeWBge/sSc7MAAAAAh4jSDRwOw5A2fCb5G6S4HnumQCM4dk/bL84JXJoNAAAA6CAo3cDhKF4nlW8NrFbe74zAStsInug0KTYzsIL5jmVmpwEAAABajdINHKoGt7R5TmA76zimlbeX7o2XDyv4QfJ5zc0CAAAAtBKlGzhU276RPNVSWJyUdazZabqOxL6B73lDvbRzjdlpAAAAgFahdAOHorpoz2JefU6TrHZz83QlFqvUbVRgO39p4Lx6AAAAIMRRuoHWMgxp4+eSDCmpn5TY2+xEXU/a0MDl2WqKpYo8s9MAAAAAB0XpBlpr5+rAtaKtDqn3qWan6ZrsYVLq4MB2PguqAQAAIPRRuoHW8HmkLV8FtnscL4XFmJunK8sYGbgvXs/lwwAAABDyKN1Aa2xf3Lh4WuyeVbRhjqiUwOXDZEj5P5idBgAAADggSjdwMJ4aKW9RYLvnOBZPCwW7F1QrWC75G0yNAgAAABxIhyrdU6dOlcVi0Z133ml2FHQl274NTC+PTpOSB5qdBlLg8mHOaMlbG5hmDgAAAISoDlO6Fy9erJdfflnDhg0zOwq6ktrSPVOYe02QLBZz8yDAapMyRgS2dyw1NQoAAABwIB2idFdXV+vyyy/XK6+8ovj4eLPjoCvZ8pUkQ0roLcX1MDsN9pY+InDt7qp8qarA7DQAAKCTMgxDXp9fdV6fquq9Kq/1qLTarV01HpXVelRR51Vtg2SLSlB5vU/ltR5V1Xvl9fnNjo4Q0SFOTr3lllt09tln69RTT9Wjjz5qdhx0FRV5UskGSZbAKDdCizMyMN2/aI20Y5k04GyzEwEAgBBmGIbqvD5V1jeozuNTndeneo9PtV6f6r2+pn11Xp88DX41+Az5/IZ8htGKd3eq+y3/1HUzi6SZXzTtjXDaFBvuUEyYI3AfbldM4+P4CKfSY8OUEReu9LgwZcSGK9xpC943AKYJ+dL99ttva9myZVq8eHGrjne73XK73U2PKysrgxUNnZlhSD/OC2ynD5Mik0yNgxZ0Gxko3UVrpd78YqQry83NVUlJidkxDsrtdsvlcpkd46CSkpKUlZVldgwAOGR1Hp/Kaj2qqm9QZb1XlfVeVdUFtqvqG9Tgb02BbpnVItmtVlmtkgzJb0h+w5Df75fP75fF2rw013p8qvX4VFBR36r3j3ZalBRhU3KETYkRNmVE2ZUZa1f3GLviw6yyHOGpjjk5OUf0ehyekC7deXl5uuOOO/T5558rLCysVa+ZOnWqHn744SAnQ6dXtkWq3BFYqbzHiWanQUuiM6SoNKm6UCpYKSnT7EQwQW5urgYMHKi62lqzo7SCRdKR/YOvPYRHRGhdTg7FG0BIMgxDtR6fdtV4tKvGo9LG+101HtV5fQd9fZTLrginTeEOm8Ia73ffwpxWRTjsctqtstssslstslktslutslstslr3X3rXLpqnvz9wY+CBxSpZbbI6wmQNi5Q1LCpwczVuuxofR8TIHp0kW0yS7NHJsroiVOUxVOVp0Jbyfa/O4qurkrckt/G2Td7SPHmKt8pfW3HI38Pq6upDfg0OX0iX7qVLl6qoqEijRo1q2ufz+TR//nw9//zzcrvdstma/zbp3nvv1ZQpU5oeV1ZWKjOTf4jjEBiGtPXrwHbGSMkVZW4etMxiCYx2r/9Uyl8mxXczOxFMUFJSorraWl1+zx+VmtXb7Dgtyvn+K82a8YzOvvF+9R826uAvMMnO3M1648m7VVJSQukGYDq/Ycie0F25NVZt3lCsosp6ldZ45G5o+Xzp6DC7YsIcigmzKzo8cB8T5lB0mF3RYQ7ZWijOR6KuOjC79nD/G28YktfwqK7BolqfVNtgUZ3PoiqvRZVei6obJFt4tGyZgxWWObjZayNshhJcfiU4DSW6DMU6Ddla+BJ3/11UX9+6kXe0jZAu3aeccopWrVrVbN+1116rAQMG6J577tmncEuSy+XqEFP3EMJ2bQ4szGV1SJnHmJ0GB5M8UNo8V3JXKta9w+w0MFFqVm917zv44AeaZGfuZklSYkaPkM4JAGYxDENbSmq0akeFVm2v0ModFVqZV6Zu1/9Vi0sllZY3HWuRFBPuUGKkUwmRzqb7+EinHDbz1ooO1n/jG3x+ldV6VVoTWMCttDowwl9R51Wtz6LaWpu2N074slksSo52KS02TGkxYeoeH65IV6D27f67CO0rpEt3dHS0hgwZ0mxfZGSkEhMT99kPtIm9R7m7jQws1oXQZnNI6cOlvIVKrllndhoAANBKXp9fq3dUaPHWXVq8tUxLtu5SWa13n+P83nolRzqVmZKglBiXkqJcio9wyG5iuW5vdptVydEuJUc3H1x0N/i0s9Ktwop6FVbWq7CiXnVeX2C7cs9odmKkU1kJEXIrUhYHA5TtLaRLN9DuSjdK1Tslm5NR7o4kY4SUt0gxnkINSOo6fwEDANCR1Lgb9ENuub7fukuLt+zSD3llqvc2nybutFs1KD1Gw7rHami3WNkr83XBqWP1s+ffVfe+ySYlD10uu01ZCRHKSoiQFJgtUFHnbSrg+RX1Kq5yq7Tx3HcpS5l3vK3l9X55tuxSVkKEUmJcsh7hAm04sA5XuufNm2d2BHRWhiFt/SawnTFKckSYmwetFxYnJfaRSjfq5jFOs9MAAAAFpkSv2F6hbzeV6JuNJVqWW7bP6uGx4Q6NyY7X6OwEjclO0NBusXLa9/wCfdmyYsngetetZbFYFBfhVFyEUwPSYiQFVnTPK6tV7q5abcovldvmUIVfWvBjqRb8WKowh1W9kqLUOyVSWfERXWoGQXvpcKUbCJqS9VJNUeMo99Fmp8Gh6jZKKt2oa4Y7tNlbY3YaAAC6nN3nZH/TWLIX/Fiqqvrmq3BnxIZpTM9AwT66Z4L6JEe1uCI42ka406Z+qdHqlxqtuPxFeuflpzXulqdkxHVT3q461Xv9WltQqbUFlXLYLOqZGKneKVHKToxs9gsQHD5KNyAFRrm3fRvY7jZacoSbmweHLq6H6m0xinZVKnH759IxXOoNAIBgq/P49N3mEn25rkjz1hdrR3lds+djwx0a2ztRJ/RN0gl9ktQjkfVyzGSR1FCWr26OWo0YliG/39CO8jptLq7W5uIaVbsbtKGoWhuKqmWzWpQZH64+KVHqnRylMMe+i1ijdSjdgCSVbpBqiiWbS+rOKHeHZLGoOLK/MisXK3nLh5LxSOCSYgAAoE3tKK/Tl+uKNHddkb7dVNLs8l1Om1WjesQ3lewh3WKDcokutA2r1aLMhAhlJkRoXD9DOyvd2lRcrc1F1Sqv82praa22ltZq7vpi9UyK1MC0aPVIjOTP9BBRugHDkLYtCGx3Gyk5wszNg8NWGt5LccXfK1q50pavpF7jzY4EAECH5/cbWr69XP9bu1NfrivSusKqZs93iwvXKQNTNKF/io7tlahwJyOiHZHFYglcZiw2TMf3TtSuGo82FVdr485qldZ4tKmoWpuKqhXusKl/arQGpEcrJdolC4McB0XpBsq2StWFgetydxtjdhocAb/VqX+u9OqWMU7p+1co3QAAHCavz6/vt+zS7NWF+mxNoYqq3E3PWS3SqB7xOnlAqk4ekKJ+qVEUr07GYrEoMcqlxCiXjs5OUEm1RzkFlVpXWKU6r0/Lt5dr+fZyJUQ6NSAtWgPTYhQVRrVsCd8ZIPe7wH36cMnJiuUd3QvfewKle/2nUnmeFJdpdiQAADqEeq9PX28s0WdrCvW/nJ0q3+ua2dEuu8YPSNGpA1N0Ut9kxUdytZCuwmKxNF4jPFkn9EnStl21WldYqc3FNdpV49F3mwOroPdKitTQbrHKSojglzA/QelG11axXarIkyxWVizvJHJK/KpMOkoxJT9IS16VTv292ZEAAAhZ9V6f5q4r0icrCzR3fZFqPb6m5xIjnTptUKomDknT2N6JctmZNt7VWa0W9UyKVM+kSLkbfNpYVK2cgkrll9drc3GNNhfXKDbcoWHdYzUoPYbF1xpRutG15Taey502VHLFmJsFbaYk+7xA6V42Qxp3D+fpAwCwF0+DX99sKtbHKwr0+ZpC1exVtDNiwzRxSJrOGJym0dkJLJiFFrnsNg3JiNWQjFiVVru1akeFcgqqVFHn1dcbS/Td5lL1S43SsG5xSo3p2ud+U7rRdVUVSrs2S7JImceanQZtqDzteCmmm1S5Q1r7oTT8ErMjAQBgKp/f0KIfS/XxynzNWl3YbOp4t7hwTRqWrrOHpWtot9guXY5weBKjXBrfP0Vjeydp/c4qrdxe3ngeeJVyCqqUEu3SUZlx6psa3SV/kUPpRteVtzBwnzJQCo83NwvaltUmjb5W+vLRwIJqlG4AQBfk9xv6Ia9MH68o0H9XFah4r8XQkqNdOntouiYPz9DIrDiKNtqE027V0G6xGpIRo8LKeq3cXqGNO6tVVOXWZ2t36tvNpToqM06Du8V0qdMVKN3ommpLpeJ1ge2s48zNguAYeY301VPSjiXSjmWBy8EBANDJGYahtQWVmrkiX5+sKNCO8rqm52LDHTpraJomD8vQMb0Su+SII9qHxWJRemy40mPDdVJfn1btqNCK7eWqdjfo600lWrRll4Z2i9XwzFhFhznMjht0lG50TXmLAveJfaTIZHOzIDiikqVB50mr3pEW/13q9qLZiQAACJqdlfX6aPkOvb9sR7PraEc6bTp9cJomD0/XCX2S5bRbTUyJrijcadPRPRM0MitO63ZWadm2MpXVerU0t0w/5JWpX2q0RmbFKznaZXbUoKF0o+txV0k71wS2Mxnl7tSOviFQule9K532Byky0exEAAC0mTqPT5+vLdR7y3bom43F8huB/U6bVacMTNE5wzM0YUAKK0gjJNhtVg3JiNXg9BhtKa3Rsm3l2lFep3WFVVpXWKUeiREak52gbnHhZkdtc5RudD07lkiGT4rpLsV2MzsNgqn76MD11wtWSD/8SzrhTrMTAQBwRPx+Q4u27NL7y7br01UFzVYeH90jXheM7K6zh6YrNqLzT9lFx2SxWNQrKUq9kqJUWFmvZdvKtKmoWttKa7WttFbd4sLV09m5Tn2gdKNraaiX8pcHtrNYsbzTs1gCo90f3SIt/oc09rbAImsAAHQwm4ur9cGyHfrghx3NztPOTAjXBUd11/lHdVN2UqSJCYFDlxYTprOGpquizqslW3dpbUGldpTXaYccSrvyz8qt8KozrMpD6UbXkr9c8rmliCQpobfZadAehlwoff47qSJX2vCZNOAssxMBANAqFXVefbwiX+8u3a7leeVN+6Nddp09LF0Xjuqu0T3iWXkcHV5suEOnDEzV0T0TtGxbuVbuKJMjqYdiXZ1jDQJKN7oOf4O0Y3FgO/OYwCgoOj9HuHTUldJ3z0qLX6F0AwBCmmEYWvjjLr2zJE+friqQu8EvSbJZLTqpb5IuGNldpw1K5TxtdErRYQ6N65+sbkaRXnvmScVe8VezI7UJSje6jp2rJU+N5IqWUgaZnQbtacwvpO+ekzZ/KZVskpL6mJ0IAIBmCivq9d6y7XpnSZ62ldY27e+bEqWLR2fq3KMylBIdZmJCoP2E2aS6zYvNjtFmKN3oGgy/lPd9YLv7GM7r7Wris6V+E6UNswOXDzvzCbMTAQAgr8+vOTlFemdJnuatL2pafTzSadPk4Rm6eEymjsqMY/o40MFRutE1lGyU6nZJ9jApfYTZaWCGo68PlO7lb0gn/05yRZmdCADQRW0qqtY7S/L0/rLtKqn2NO0fkx2vi0dn6qyh6Yp08c90oLPg/83o/AxDylsY2M4YKdmc5uaBOXqdLCX0knb9GLh29+jrzE4EAOhCatwN+mRlvt5Zsl1Lt5U17U+KcunCUd108ehM9U7mF8JAZ0TpRudXkStVFUhWu9RtlNlpYBarVRpzvfTZvdL3r0ijrmUxPQBAUBmGoWW5Zfr34jx9srJAtY3X1LZZLZrQP1kXj87UhAEpctg6xwrNAPaP0o3OL29R4D5tqOTk+pVd2ojLpC//IBWtlbZ9K2WfYHYiAEAnZI2I1YfrqnX33K+0ubimaX/PpEj9bHR3XTSyu1JiWBQN6Coo3ejUwr1lgenEskjdjzE7DswWHicN+7m09DVp4UuUbgBAm/H7DW3bVaslxXZ1v3mG/rmySpIU7rDprKHp+vmYTI3J5praQFdE6Uanllq9JrCRPCBQuIBj/i9Qutf9V9q1RUroaXYiAEAHVl7r0Zr8SuUUVqrG7ZNklcVmVd8Eh64dN0CTh6crOsxhdkwAJqJ0o9PqEWtRfP3WwINMRrnRKGWA1PsUafOcwLndZzxudiIAQAfj9fm1qahaa/IrtaO8rml/mMOq7mFezZ92u97/7H2NHJllYkoAoYLSjU5rynFOWWRIcdlSdJrZcRBKjr0pULp/+Jc04V7JFW12IgBAiDMMQ0VVbq3Jr9T6wip5fP6m53okRmhweox6JkeqcHOO5pRsMzEpgFBD6UanZHNX6JcjA5cG22jto6oNO0xOtH9bCssOfhDaXu9TpMS+UulGafmb0jE3tnuE3NxclZSUtPvnHiq32y2Xy2V2jAPKyckxOwKATqzO69P6wiqtya9odk3tmDC7BmXEaFB6DNPHARwQpRudUviqfynCYdHSfJ9GP/y+2XEOqqi85uAHoe1YrdKx/yf99y5p0V8DlxKztt/lWnJzczVg4EDV1da222cePoskw+wQrVJdXW12BACdhN8wlLerVmvzK7W5uEY+I/DfQZvVot7JkRqcEavM+HAWRQPQKpRudD7uavUonC1J+sJ/tKbcf6LJgVq2ZGWO5n/8H1XUus2O0vUMv1Sa80hgdfuNn0v9z2i3jy4pKVFdba0uv+ePSs3q3W6fe6hyvv9Ks2Y8o7NvvF/9h4XuNe5356yvrzc7CoAOrqLOq7X5lVpbUKlqd0PT/uQolwZnxKh/WrTCHDYTEwLoiCjd6HyWviaXv0YbSn1aFz5cw3v0MDtRizbuCP3pxZ2WM1IaebX03bPSwhfbtXTvlprVW937Dm73z22tnbmbJUmJGT06RE4AOBy7F0VbW1Cp7WV7FkVz2a3qnxatwRkxSonmmtoADh+lG52Lt1767nlJ0hPfeGSc0H5ThtEBHX2DtOAFactX0s41UmroFksAQNsxDEM7K91ak1+hDTurmy2KlpUQocEZMeqVFCm7jX9HADhylG50LsvfkKoLVWOP1+srK3XpCWYHQkiLy5QGTpLWfiQtfEk693mzEwEAgqjG3aB1hVVaW1CpXTV7FkWLDXdoUHqMBqRHK4ZF0QC0MUo3Og9fg/TtNEnS2vhT5fX/w9w86BiOvTlQule+I536kBSZZHYiAEAb8vkNbSut0Zr8Sm0trZG/cW1Iu9WiPilRGpwRo25xLIoGIHgo3eg8Vr8nledKEUnaHHO8JEo3WiHzGCnjKCn/B2npa9JJd5udCADQBnbVeLQ2v1I5hZWq9fia9qfFhGlwRoz6pkbJZWdRNADBR+lG5+D3S9/8JbB93C3y5TrNzYOOw2KRjrlJ+uAG6fu/S2PvkOz8/ABAR1TradCGndXKKahUUdWeK4NEOG0akBatQekxSoxymZgQQFdE6UbnsP6/UvE6yRUrjfmFlPuJ2YnQkQw+X/riAam6MDDVfNjPzE4EAGilBp9fW0pqlFNYpW17TR+3WqTsxEgNzohRj8RI2axMHwdgDko3Oj7DkOb/KbB9zA1SWKy5edDx2J3SmOuluY9KC1+Qhl4UGAEHAIQkwzBUUFGvnIJKbSyqlrthz+rjKdEuDUyPUb/UKEU4+acuAPPxXyJ0fOtnSQXLJUekdMz/mZ0GHdXoa6X5fwyc2533vZR1jNmJAAA/YY9L09pym/63YJsq6rxN+6Ncdg1Ii9bA9BglRHKKEIDQQulGx+b3S3MfD2wfcwMrT+PwRSYFppX/8Lq06CVKNwCEiNJqt2atLtTr35So241/V06lJHnlsAVWHx+YFqPu8aw+DiB0UbrRsa37WNq5SnJGS2NvNzsNOrpjbgqU7rUzpfK8wHW8AQDtrrLeq8/X7NTMFfn6dlOJfI0naht+n9IiLBrRO129k6PksFlNTgoAB0fpRsfl90tzpwa2j71JikgwNw86vrQhUvaJ0tavpe9flk7/g9mJAKDLqPU0aE5OkT5eka9564vl8e05T3tot1iNTPLrsevP00VP/UPd02JMTAoAh4bSjY5rzftScU5g4bTjbjE7DTqL424JlO6lM6Rxv5Fc0WYnAoBOy93g0/wNJfp4Rb7+l7Oz2fW0+6ZE6ZzhGZo0PEM9kyK1bNkyPVJTZmJaADg8lG50TL4Gad4Tge3jbpPC40yNg06k70QpqZ9UsiFQvMfeanYiAOhUvD6/Fv5YqpnL8zV7TaGq6huanstKiNDk4emaPDxD/VOjOU8bQKdA6UbHtPpdqXSjFB4vHXOj2WnQmVit0nG3Sh/fLi18MfDzZXOYnQoAOjR3g0/fbCzR7NWF+iJnp8pr96w8nhrj0qRhGTpneIaGdY+laAPodCjd6Hh83j2j3MffIYVxXhfa2LCfS18+KlXukFa/Jw2/xOxEANDh1HoaNG99sWavLtSX64pU7d4zop0Q6dSZQ9J0zvAMjclOkNVK0QbQeVG60fEsnS6VbZEikqQx15udBp2RI0w69v+kOY9I3z4bKOGMvADAQZXVeDR3fZFmry7UVxuK5W7YsxhaaoxLZwxO0xlD0jUmO152Vh4H0EVQutGx1JXvuS73hHslV5SpcdCJjb5Omv9nqWiNtHmO1OdUsxMBQEjaXFytOTk79b+1RVqybZcar+4lKXCO9plD0jRxSJpGdI9jRBtAl0TpRsfy9Z+kul1SUn9p5DVmp0FnFh4vjbo6cF73t89SugGgUYPPr6XbyvS/nJ2ak1OkH0tqmj0/IC1apw1K1RlD0jQoPYZztAF0eZRudBy7tkiL/hbYPv1RycaPL4Ls2JsCP3NbvpLyl0sZI8xOBACmKKqs11cbijV/Y4m+3ljcbCE0h82iY3sl6tSBqTplYIq6x0eYmBQAQg+tBR3H/x6SfB6p1wSp72lmp0FXEJclDblQWvWO9N2z0kWvmp0IANqFp8GvJdt2BYr2hhLlFFQ2ez4uwqGT+6fo1EGpOrFvkqLDuMoDALSE0o2OIXehtPZDyWKVJj7GolZoP8ffHijdaz6QTn5ASuhpdiIAaHOGYWhjUbUWbC7V1xuL9d3mUtV6fE3PWyzSsG6xOqlfsk7ql6yjMuNYCA0AWonSjdDn90uf3RfYPuoKKXWwuXnQtaQNlfqcJm36Qvr2GWnyNLMTAcARMwxDW0trtWBzqb7bXKKFP+5SSbW72TFJUS6d1C9J4/ol68S+yUqIdJqUFgA6Nko3Qt/Kt6UdSyVHpDThd2anQVd04l2B0r38DWncPVJMutmJ2oRhGPL5DXl9hjw+v7yNtwZfYH+pohQx4EQVNoRr9Y4K+fyGfI2vaXYzDBnGnveUJEPas0+GGv8nY/eTFslqkawWS+NNslgsslkssuzeb23+vM1qkd1mlaPx3m61yG6zqEYu2ePS5fZbVe/1yW7b/T7MiAF2212yl2zdpQU/lmrB5lIVVNQ3OybMYdXoHgka2ydR4/ola2BaDKuNA0AboHQjtFUX7xnlPunXUnSquXnQNfU4TsoaK+V+Jy14PnCKg8kMI1CU3V6/6ht8ze7dDX7Ve31yN/jlbvDJ6zPkbfDvVaz3lGzDONCnZCr53Hu03iOtX1fUXl/aYeilbje+ooX10sL5P0qSLJLsNoucdqtcNpucdmtge+972+7t5s+HO2wKc9jksFHc0XG5G3xavaNSS7ft0pKtZVqWW6aSak+zY5w2q0ZkxWls70SN7Z2k4ZmxctltJiUGgM6L0o3QNvu3Ul2ZlDpUGnub2WnQlZ14l/TGd9KS1wLbEQlt+vZen191Hp9qvT7VeRpvXp9qPQ2N9z7Ve32q9/rlbizUB+zLh8hutchhs8phC9zbrBbVVZWpOHez0rP7Ki4hUTarJXCzWPZsW/eMTlskySJZAltNSy/svX/3tgzJL0N+Q/L7AyPlfsNovO217W8ckW8cYW/wG2rwGfL6/I2j9H7V1dfL7fbI6grf/WkypMAvG3w+1cinw2GzWORy7CnhYQ5r472tcV/guXCnTRFOu8IdgfIOtDfDMFRQUa+V2yv0Q16Zlm4t08odFfI0+Jsd57RbNaxbrI7plaDjeiVpVI94hTsp2QAQbJRuhK4Nn0ur3w0snnbOM5KNlVFhoj6nSGnDpMKVgcuITbj3oC/x+vwqqXZrZ6VbRZX1Kqpyq6jKrZwt5Uq+8EF9WWhXQ9EW1Xl8avAfXoW2WS0Ks1vlctjksgdKoctuVZjdJpcjMHLraBzV3V2qnbbAvr1LtnU/I7pL5yzXG2/dq4kPv6wRw4ceVr72sHTOTL0x7W5d+dDLGnbsSWrw+5uKuachMPLv2Xu7cQaAZ/d243OehsBsgXqvv2nafK3H12wxqYOxWy2KaCzhEc7dhTzwuFjRcmUOVY3frjqvT2F2KyPpOCxFlYGCvXJHhVZtL9eqHRX7jGJLUmKkU6N6xGtUj3iNzo7XkG6MZAOAGSjdCE3uKumTXwW2j71Z6jbK3DyAxRIY4f7P1TIW/lXlI25Ufp1NBeX1KqioU2FlvYoq3dpZFSjYxVVu7ar1tDh9O6LP0SrzSFJD0z6b1aJwR6Ck7R5BDW/c3r0v7CflmtWD97A0nvdts9rkOoK/3QwjMKJe590zu6De62v2eM92YFZCbeMvThr8hirrG1RZ37Cfd+6utMumakm9tGT+j7Ja1Phna1eEa085j9x979pT3l0U9C7J6/Prx+IarSus1PrCKq0vrNLq/ArtrHTvc6zdalG/1GgN6x7bWLITlJ0Ywc8NAISAkC7dU6dO1fvvv69169YpPDxcY8eO1ZNPPqn+/fubHQ3B9uWjUuX2wHWSJ9xndhp0MVX1XhVU1Cu/vE4FFfUqKK9TfkW9CsrTVNDwrArqo1T35IJWvZfdalFytEsp0S4lR4cpNcYlX/UuvfDnqZp0xf8pM7tnU/HiHOLQYLFYmmYAxLTy2sOGEViQrtbT0DQ6HijjjY+9PhUVFam0dJfCEzPUIKv8hlTj8anG45OqD/z+Notlv8V8977IxnIe6bLLwS9iOpwGn1/by+q0ubha63dWNRXszcXV8vr2/c2d1SL1TYnW0O6xGtY9VkO7xWpgeozCHIxiA0AoCunS/dVXX+mWW27RmDFj1NDQoPvvv1+nn3661q5dq8jISLPjIVjyFgem70rSpGmSkz9rtB3DMFRc7VberjptL6vV9rLAfX7jiHVBeb2q3PsbpdwtqWkrIcKh9LhwpceGKz02UKhTYsKUEu1SSnSYUmJcSohw7rP677Jly/Tkis+UccONSo8ND9JXivZksVjktFvktDsVF7H/Y5bOWaw3/n63rnr4ZQ055sSmEfLavcu526eapuLeoBpPYBq8zzBUVd+gqvoGSfuOcu7NYbM0jZBH7qeYR7gCpT3caZPdSkFvL36/ocLKem0tqdGPJTXaWlKjLY233F21LZ5iEu2yq19atPqnRat/arQGZcRocEaMIpwh/U84AMBeQvq/2LNnz272+LXXXlNKSoqWLl2qk046yaRUCKq6cum9X0gypOGXBs6jBQ5RlduvldvLm4p1XmO5ztsVuHf/ZHGh/YkJsysjLlCm0+PClREbFijXMQ6lf3ix0qvXKGziY9IxN7bDV4TOxm61KjrMquhWjKQ3+PxN5bzG07BPMa/1+FTjbmia4u71Gaqo86qiznvQ93bZrc2KeYTTroYqqyKHnKxlBfWyby9XfIRTcREORbnszMQ4gHqvr2mGzI7yOu0oq2vazm+cLfPThc32FuawKjsxMlCuGwt2/7RodYsL5/sOAB1cSJfun6qoqJAkJSS07arBCBGGIc28VSrfFphWfsZUsxMhRNX7LNpe59TWWqe21bqUV+fU9jqnNpZnK/POcbr6o52Sdrb4eotFSo8JU/eECHWPD1f3+Ah1iwuU6ozG+8gDnRQ84erAmgNf/0UaebXkCGv7LxJoZLdZFRNuVUz4gQv67inuu4t5UyH/STHfXdb9hhovK+fRrtpmn6iks6fo0a/LpK+/3bPXalFchENxEU7F73UfH+FUbON9XLhDUWF2Rbkab43bkU57h7res2EYcjf4VVnnVWW9VxV1DSqr8aik2q3iKrdKqt0qqfaouLpxu8rdwnn8zdmtFmUlRCg7KVI9G2+9kiKVnRSptJiwDvU9AgC0Xocp3YZhaMqUKTrhhBM0ZMiQFo9zu91yu/dMvausrGyPeG0iNzdXJSUlZsc4qKSkJGVlZbX9G3//spTzsWR1SD+bLoXHt/1nhKi84kot27DD7Bgt2lJYJknamL9Lye2Us85vU6E3QoUNESrwRjZtF3ojVOoLk6H9/+PU6grcx4dZlRJp2+tmV0qkTamRNiWGB67BHOBX4ITaaqlaqqwOLCdwIBYN1uDwFDmrC5X30aMq7nXBIX1tOTk5h3Q80Bp7T3GPb2GK+26GYai+wa9ad/NiXuv2qbi0ROtXr9CAEUfLbdhVVuuRu8GvBr+hkmrPflfJbo1Ip01RYXZFuuyKdgXuo1yBKe+7r5fuslsbV91v3G5cfd9mscjaeHk6q1WyWva+XF3gGnQ+v+QzDPkbF7Tz+/e61JzPr/qGwGX56ht8qvc0XxCvzutTVX2DKuu9gaJd1yCP7+AzYn4q3GFTt/hwZcSFq1tcuLrFhSkjbs/jtNgwzrnvQjrCf+vdbrdcLpfZMQ6oI3wfgYPpMKX71ltv1cqVK/XNN98c8LipU6fq4YcfbqdUbSc3N1cDBw5QbW2d2VEOKiIiXDk569q2eO9YKn12f2D79Ee7zGrltdVVkqSn/rNIT/1nkclpDu62F7+Q9EWbvZ81LEr2+AzZ49LliE+XPS5d9vh0OeLSZYs68C9d/O5aecvy1VBeGLhV7Gy8FclXWaRtDYdXDFrrhlEO/W1SuGwLntHYSx6T+zAuBV1dfZDVs4AgsVgCK+WHO2xK/Mlz27VTX7/zoGbds1QjR46UJNV5fCqr9ais1qOKWq/Kar0qq/WovNaz13ZgSnuNO3DueY2nQdX1DU3nKjctGneQc9JDidUiRYc5FBvuUFyEQ0lRLiVFOZUU5VJytKvxsUvJ0YF9seEOpoJDlbuKJUlXXHGFyUlaI/BLq46AvzPRkXWI0n3bbbdp5syZmj9/vrp3737AY++9915NmTKl6XFlZaUyMzODHfGIlZSUqLa2Tq/fd7EGZiWbHadFObnFuuLxd1RSUtJ2pbuuTPrPNZLfKw2c3KXOkfW46yVJx55xrsaOGm5ympbNnf+dfvj6f4eV02dYVCOXqoxwVStMVUaYqo0wVSlMHh14uqxTXkXJrUhL/Z57i1tRqpczokGWSEndnZKyJGVpycoczf94me752bG6+JTg/uLGYvjkKfpQGdG12vjUKSqOHNDq1376/QY98OoXqq+vD2JCoO0ELl8XGLE9FLunaVe7AwW82h241TTeV9U3qN7ra5zmHrh+utu713bj9dP9fkN+w5DP0J5tvyHDCIxuW6SmkfDAZeMCt8CIeGCKfpjdpnBn4D6s8ZJ8LrtV4U6bwuw2RYfZFRvuUMzuW1jHmxaP0FBXHZhlefaN96v/sNAdRMj5/ivNmvFMh8nJ35noyEK6dBuGodtuu00ffPCB5s2bp549ex70NS6XK+SnyRzIwKxkjezXzewY7cfXIL1/o1SeK8X1kM55PnDCbRcTk5Ck7j16mB2jRVFxgaldLeU0DKnGZ1WZ16Yyjz1w77Wr3GNTpc/W4lRwSYqy+RTrCNziHA2N9z7F2n1y2fb+7btdUlTjbf827gicntE9Obp9/n8UfaK08TNl1ucoc/g4ydq6/6Tm5BYHORgQGiwWi8Iary+fFNVx/24GDkdiRg917zvY7Bgt2pm7WVLHyQl0ZCFdum+55Ra9+eab+uijjxQdHa3CwkJJUmxsrMLDucxOh2cY0id3SBs/k2yuxvO448xOhQPwW+wqctv3KdZlXpu8RsvnKTotfsU5fYp3NCje4VO8M3Af52iQoyOf3pg2TMpdILkrpYLlUrfRZicCAABAiAnp0v3SSy9JksaPH99s/2uvvaZrrrmm/QOhbX35B+mH1yWLVbroVanbSLMToVGdz6JdHnvg5rWrKOs0dbv5bG2MTtLGFhYZs8hoGqWOdzQofq+SHWHzd84JDFablHVc4BdHuQul9BGtHu0GAABA1xDS/zo0jI6xsAMOw8K/Sl//ObA9aZo0cJKpcboiw5BqfVaVeuza5bXtKdkeu+r8Pxl+jopo+o9FuNXfbKR6d7mOdfhk64zF+mD2Hu3O/0HqPsbsRAAAAAghIV260Umtelea/dvA9sm/k0ZdbW6eTs4wpKoGq3Z57XsVa5t2ee1y/7Rc7yXG7lOCs0EJjgZtzVmuNXM+0IkTxuvscZTKZqw2qcfx0oZZUu53gRJu59xVAAAABFC60b6W/Uv6+A5JhnT0jdKJvzY7UadS57Oo1GNXqceuksb7Uo9dnhbK9e4p4QmOBiU4fUp0Nii+sWjvfa51SfkmefLXyWYc305fSQeTNlTKWyTV7ZK2L5ayTzA7EQAAAEIEpRvtwzCk+X+S5j4aeDzicumMJ7rkSuVtweuXdu2nXNf4bPs93iqjaQGzBGeDEp0NSmicHm7vyAuZhQqLVco+Ucr5SNr+fWB9AkeE2akAAAAQAijdCD6/T/r019KSVwOPT5ginfIghbsV/IZU4bWp5Cflutxrk1q4DFeMPTBineT0KtHpU6LTq3hnFz3fuj0lD5DyFkrVOwPnePc+xexEAAAACAGUbgSXu0r64P+kdZ9IskhnPiUdc4PZqUKSxx+YGl7stqvYY1eJ264Sj0MNxv7bcrjVHyjXrsDI9e6b08oChKawWKSe46RV70g7lkndxkhhMWanAgAAgMko3QieHcukd6+TyrYErsN94SvSoHPNTmU6w5BqfFYVu+2qSBqqpHN76ce0o7R+S6T2N3pttxhNhTppr3Idafe3f3gcWHxPKTZTqsiTtn0j9T/L7EQAAAAwGaUbbc/vlxY8L815WPI3BErIRa9KmUebnazd+QypzLNn5LrYY1ex26H63QubpcQrMkXyNh4fafMpydWgZGeDkl1eJTsDl+KyMjW8Y9g92r38dalwlZR5jBSRaHYqAAAAmIjSjbZVsUOaeZu0eU7g8cBzpHOelcLjzc3VDnyGVOqxq8jtUJE7cF/iscu3n+nhFhlKcPhUV7xNO36Yp6GD++vMMf0UYWdqeIcX211K6C3t2iz9OE8acqHZiQAAAGAiSjfahs8rLXxJmveE5K2R7OHSmU9II6/ulAumNfilksaCXbxXwfbvZ3q40+pXkrNBya4GJTu9gXOwG1cN/2DFN8r5/gNF9vmFIux9TfhKEBS9xku7fpRKN0rluVJcltmJAAAAYBJKN47ctu+kT6ZIxTmBx5nHSJOflVIGmJurjTT4pWLPntHrIrddu1oo2C6rXykur1JcDU33sXZfZ/y9Aw4kMllKHyEV/BCY9THymk75yycAAAAcHKUbh690s/Tlo9Ka9wOPwxOk0/8gDb9MsnbMiz/7DKnEbddOt0OFexVsYz8FO7yxYCc3FuxUl1fRdj/dCgHZJ0hFawKXENu5WkobanYiAAAAmIDSjUOWFmVR5oqnpU8+DSyUJos06mrplN9LEQlmx2s1w5DKvDbtdDu0sz5Qskvcdvn2V7BtPqW4GpTaOHqd7KRg4yCckVLWWGnLPGnLfCm5v2Rzmp0KAAAA7YzSjdZrqFdG5Q/afHuUIrbNDOzre7p08gNS+jBzsx2EYUjVPmtTud7ZOFXc4993RN5l9SvN5VVqmFepjaPYkTYKNg5D99GBKeb1FVLe94HRbwAAAHQplG4cnM8r7Vgq5S1UWkO95LCoOn6wos79o5R9vNnp9qvOZ1FYz5Ha5shWbkGcdrrtqvXZ9jnObjGU7PIGSrarQalhXs7BRtux2qWe46Wcj6S8RVL6cMkVbXYqAAAAtCNKN1pm+KXCldLWbyRPtSSpzh6rn/+rQA+9+ZxGZo8yOWCAz29ow84qLcst0w+55foht0ybi2OVevEj2ipJtYHjLDKU5GxoGsFOdXmV6GzgGtgIruQB0o4lUuUOactX0oBJZicCAABAO6J0Y1+GIZWsD5yHWrcrsM8VI2WfqJyKOH284SU9ZOJQcGm1O1Cu88q0bFu5Vm4vV43Ht89x3l356hZj1YDUCKWGBc7DdnTM9d3QkVksUu9TpB/+GVhQLX2E2YkAAADQjijdaK5sq/TjPKm6MPDYER5YDCrjqMBU2cod7RrH6/NrXcHuUewy/ZBXrm2ltfscF+Wya3hmrEZmxeuorDhtWjRHN15zg069dYpGxA1u18zAPmIypLThUuEKaeNnsugosxMBAACgnVC6EVBXFriecOmmwGObU+p+tNR9jGR3tVuMnZX1gXKdW65luWVaub1C7gb/Psf1SYnSyKw4HZUVr5FZ8eqTEiXbXvPEC5Ya7ZYZaJVe4wIzSGqK1c+aa3YaAAAAtBNKd1fn80q5CwKLPBk+yWINjGpnjQ1c8iiIvD6/1uZXaum2Mi3NLdPy3HLtKK/b57iYMLuOahzBHpkVr+GZcYoNdwQ1G9DmHBFSrwnShlkabt2o9CgWEwAAAOgKKN1dWclGadMXkrsy8Dg+W+p9qhSZFJSPq6jzallumZZuLdOSbbu0Iq9Cdd7m52JbLVK/1OjGEezASHavpEhZWe0MnUHaMKlghRxV+frz6WGabXYeAAAABB2luyvy1gXKdtHawGNXjNTnFCmxn9rqWlmGYSh3V62WbC3Tkm1lWratTBuKqmT8ZNZ3TJhdo3rEa1SPwDTxYZlxinLxY4lOymKR+p4u/9LpunSoQ7nGRknjzE4FAACAIKLddDXF66SNn0veWkkWKfNoqccJku3Ipmt7Gvxak1+hpdvKmop2SbV7n+N6JEZoVI94je6RoNHZ8eqTHMUoNrqW6DRt8GdpgC1XVxrv613/lfJZ22/dBAAAALQvSndX0VAvbfhMKs4JPI5IkvqfLcWkH9bbVbn9+nLdzqaCvSKvfJ8Fzxw2i4Z0i9XoHvEa1SNBo3rEKzmacgGs9PdVbO1WZUQX69jcV/Rt9q1mRwIAAECQULq7gsodUs5Mqb4isFBa5rFSj7GBS4C1gmFIW2udWlIeqc+K45X+ixd19Uc7Je1sdlxchEOjsuI1Kjswkj2se6zCHLYgfEFAx+aVQzd+Uq+Zl0Zo9I5/aVPiBO2M5tJ2AAAAnRGluzMzDClvobRlviRDCouVBp4buGbwAbj9Fq2uCNfS8ggtKY/UsvIIlXj2TD93Nq6z1ispMjBVPDswks2CZ0DrfbyhQd/pKI3VDzp90yN6c/i/5LM6zY4FAACANkbp7qy8tdLamVL51sDjlEFS39Mle9g+h+7y2LS0PFJLyiK0tDxSKyvD5fFbmx3jtPg1NLZOmcZOvfzqG/rvjOc0YeyYdvhCgM7rdct5Gm7fpqTaH3VM3j/0XY+bzI4EAACANkbp7oyqCqU17wcuBWZ1SH1Pk1KHShaLDEP6sdalpWWBUewl5RH6sWbfIp7gaNCo+BqNjqvV6LgaDYmtk8tqaNmGHXpm0yLFhjFtHDhSNZZIfdn7Hk1ed4/GbJ+hTYkTVBQ1wOxYAAAAaEOU7hCTk1t8RK9PqN2srIqFssqvelu01sWdrDVFWVqX69I6d7zW18er0r/vFNZujmoNcJVpQFiZBoaVKd1eG7h6mFdSsbSmuHm+nJycI8oZbFu2bDE7AtAqmxJP1vqk09S/5AudvvFhvTV8BtPMgU4kNzdXJSUlZsc4KLfbLZcrtBc7DfV/ewBASyjdIaKgoECSdMXj7xzW6+1WadoZYbpkdKK+8I/UOyV99FlNX9lS+shib345ML/XLU/hRrm358i9I3DbVl+l7w7h86644orDytneat0NZkcADmpur7uVWbFEybWbdPy2FzS/56/MjgSgDeTm5mrAwIGqq601O0orWCQZZodolerqarMjAMAhoXSHiPLycknS2Rdfof59e7XqNYYhVSlMlUaYYlWpd41u+qO78RJgsZI9NrDpkleJliolWqqVaKlSvK1W1p6G1LOHpB6Szmh1zu+/X6xvvpilky67XaOPH9/q17W37+d8om/ef1VuL6Uboa/OEa8v+vxO5+bcpVH5byo39mhtTTje7FgAjlBJSYnqamt1+T1/VGpWb7PjtCjn+680a8YzOvvG+9V/2Ciz47Rod876+nqzowDAIaF0h5jElBR179Fjv881+KWdbofy6x0qqHeqoN6h+p8seCYFzsfOCPMoPcyrjHCvYu2+wFRxuRpvh2/9xs2SpNjU7ureN3QvcbR+5VKzIwCH5MeEk/RD+s91VMG/NXHjQ3p9xJuqcSWbHQtAG0jN6h3Sf2fuzA383Z6Y0aND5ASAjobSHcJqGyzKbyzX+fUOFbkd8qv5Jblc8mi4ZbOG2rfJHddHkZExCrN1jOlhAJr7Ovt2dav8QSk1G3TGxgf1/uDnZVhYtBAAAKAjo3SHCL8hORIzVWDPUFFRjPLrHarw7vvHE2HzKT3Mq6Osm3Wp+z8aatmsXc5umpl4nWps0eoo52MB2JfP6tSn/R7TZSuuUlbFEo3ZPkPfZ15ndiwAAAAcAUp3CPixuFqP58Qo45cvaYMkVe1+xlCisyEwTTzMq/Qwr2JtXp1Q9amOrp4jWaUN4cM1O/4y+Sysdgx0BmUR2Zrb+zeauPFhHZf7snbEjNCO2JFmxwIAAMBhonSHgO7xEfL6LfJ76xVvrVO/REdTyXbtNVXc7nfrjLI31bd+pSRpYfRpWhB9hmTZ97xuAB3X2uSzlVX+vQYWz9Kk9b/Vm8NmqCos3exYAAAAOAy0tRDgtFt1a58q5U37uUbU/6CxiTXKjvQ0K9yRvgpdXPK8+tavVINsmh1/mRbEnEXhBjoji0X/632vdkb2V4S3TOfm3CWHryNccggAAAA/RWMLEclhfsnv2+9zKZ48XVb0tFK921VrjdR7STcrJ2JMOycE0J4abOH6eOCfVONIUHLtRk3c+LBk+M2OBQAAgENE6Q5xfeuW6+KS5xTlr1CpPVVvJ9+pfFfrruMNoGOrcqXp4wFPyWexq2/plzo27+9mRwIAAMAhonSHKsPQ0ZWfa9KuGXIYXm1xDdDbyXeowp5kdjIA7aggZrj+1/teSdJxea+oX/HnJicCAADAoWAhtRBkMzw6vezfGlC3TJK0LPIkzY89h+v1Al3U2tRzlFS7WaPy39QZG38vtz1a2+KPMzsWAAAAWoGR7hATa6nVz4pf1IC6ZfLJqv/F/UxfxZ1P4Qa6uK+zb9eGxFNlMxo0ed3dyqhcYXYkAAAAtAKlO4QMT7Xq97EfKd27TfWWCL2f9H9aFTnW7FgAQoBhsWlWv0e0Je44Ofxunbv2TiVXrzc7FgAAAA6C0h0iulcv17fXRSrRVqNd9hS9lXKntrv6mh0LQAjxWx36ZMBT2hEzQmG+al2w9jbF1W0zOxYAAAAOgNIdCrYt0EkFryjSadFqTze9nXynyu3JZqcCEIIabGH6cODTTdfw/tmq/1NizSazYwEAAKAFlO5QkHmMcqOO0vPfe/TnqolyW8PNTgQghHnsUfpg8HMqieitKG+JLl51g9I5xxsAACAkUbpDgdWqb9Ou1W2z6uXnjwRAK9Q54vXOkL8pP3qYwnxVunDNLcre9a3ZsQAAAPATNLwQwerkAA6V2xGr9wa/oC3xY+Xwu3XOurs0oGiW2bEAAACwF0o3AHRgDbYwzRzwZ+UknyGb4dOZGx/UiVuflcVoMDsaAAAAROkGgA7Pb7Vrdt+HtaTblZKk0Tv+pQtX36oIT6nJyQAAAEDpBoDOwGLV19m365P+T8hjjVBm5VJdvuJKFlgDAAAwGaUbADqRjUmn6M3hM1Qa3lNRnmL9bPWNOm7bS7L5PWZHAwAA6JIo3QDQyZRFZOut4dO1Lul02Qyfjt3+qi5ffrkyGPUGAABod5RuAOiEvLYIzer/mD7u/6RqHAlKrNuqn6/6pSZsflKuhiqz4wEAAHQZlG4A6MQ2JZ2sGSP/o9Up50iSRhS+q+uWnKsx26fL7qs3OR0AAEDnR+kGgE7ObY/RF30f0HuDn1dpeE+F+ap0wrYXdN3S8zS84B1Z/V6zIwIAAHRalG4A6CJy447Rv456S7P7PqwKV4YivaU6+cc/6pdLJum4bS8pyr3T7IgAAACdjt3sAACA9mNYbMpJOUvrk07TkJ0f6ejtrynaU6Rjt7+qo7fP0ObEk7Qq9TzlxR5tdlQAAIBOgdINAF2Q3+rQyvSLtDr1PPXe9ZWGF7yjzMpl6ls6V31L56reHqOj7D1V1tcuu9FgdlwAAIAOq0NML3/xxRfVs2dPhYWFadSoUfr666/NjgQAnYLfatfGpFP07tC/6Z8j3tLytJ+pxpGgsIZKnWRfof9eFqEXjQd0/prbNGb7a0qvXCmrnxIOAADQWiE/0v3vf/9bd955p1588UUdf/zx+tvf/qYzzzxTa9euVVZWltnxAKDTKI3so7m9f6N5ve5SRuUKxS7/u4bULlK3GK+yyxcqu3yhJMlrdakkoq+KI/upOLKfiqL6qSwsS25HrMlfAQAAQOgJ+dL9l7/8Rb/4xS/0y1/+UpI0bdo0ffbZZ3rppZc0depUk9MBQOdjWGzaETtSMxvO0JtPz9G9Dz2sU7Mt6l65VN0rlim8oULp1auVXr262evq7TEqD+umirDuqnKmqsaZpBpnkqqdSap3xMlti5LbFiWvLUKyWEz66gAAANpXSJduj8ejpUuX6re//W2z/aeffrq+++47k1IBQNdhSNpuSdfyjHFanvFzyfArvi5XyTUb9txqNynKU6ywhkqlVVcqrTrngO/pl1UeW6Tc9ih5bFGN95HyWZ1qsDjkszoDt93bFod8Vof8FrsMWWVYLDJklSwWGbIowbZGMaMdOtr4Tt0LSxuPscqQ5Sf3R3BG1WH8ksBQ89fYrGvlHmTXGGOFsksOdJm2I/+sVtvPy+Lr83T+ALvi8udLYdsP730hSYrL/1HnD7BraP0SJZaG7tUBLNYc1Q6wa5SxSj1LfWbHaRE52xY52xY529buv4ssPo/ZUdpESJfukpIS+Xw+paamNtufmpqqwsLC/b7G7XbL7XY3Pa6oqJAkVVZWBi9oG6itrZUkbdr0ozwe90GONk9e3o7A/fpV+j7MZXKaluVtXhe437ZV3ztDd0RtZ36+JCk/L0/fL1lmcpqWdZScedu2SpK+W7tDrv8uNjfMASxamytJ2rR6qTz1dSanadnWtSskHShnn8ab5DQ8StIuJWuXklSmeFUoTlWKUZXiVKVI1Spcbtnkl+STVCmLKuWSdKT/JRkl6fxTw6T696S1R/hmQXSSpGvOCZfq/ymtNDvNgV1wXrj07YOq/NbsJB1bkqTp54VLxc9JxWanadk4SdedFy7VT5f+v707D4qy/uMA/l5WjkUEEQpXUUhFDi0PyFxJsXDELAczlGkMMY9ypMTMMwfTZpwGMzXzGmrJYyjLA6dGTclBDo9UBpsERUUMyEVGzfHA8NjP7w/H/bUtEIs8u6y8XzP7x36f59nnvfieHT486+5v9k5TP+ZsXszZvJiz+Y0ZrcGp65db9Bz3KJuINLifSv5rDzu6dOkSOnfujMOHD0On05nWly5dii1btuDMmTMWxyxevBhLliyxZUwiIiIiIiJqpSoqKuDv71/v9hZ9pdvX1xdqtdriqnZ1dbXF1e9HFixYgFmzZpnuG41GXLt2DT4+PlDV8/bAGzduoEuXLqioqICnp2fzPQEihbG75IjYW3JE7C05KnaXHJGj9FZEcPPmTXTq1KnB/Vr00O3i4oLw8HBkZWXh9ddfN61nZWUhNja2zmNcXV3h6mr+ZsX27ds36nyenp4t+h+VqD7sLjki9pYcEXtLjordJUfkCL318vrvb29p0UM3AMyaNQsJCQmIiIiATqdDWloaysvLMW3aNHtHIyIiIiIiImpQix+64+PjcfXqVXzyyScwGAzo3bs39uzZg4CAAHtHIyIiIiIiImpQix+6AWD69OmYPn26Yo/v6uqKjz/+2OJt6UQtHbtLjoi9JUfE3pKjYnfJET1pvW3Rn15ORERERERE5Mic7B2AiIiIiIiI6EnFoZuIiIiIiIhIIRy6iYiIiIiIiBTSaobudevW4ZlnnoGbmxvCw8ORl5dX774HDx6ESqWyuJ05c8aGiYkesqa7AFBbW4uFCxciICAArq6u6N69O9LT022Ulugha3o7ceLEOl9ze/XqZcPERNa/3mZkZKBPnz5wd3eHVqvF22+/jatXr9ooLdH/WdvdtWvXIjQ0FBqNBsHBwdi8ebONkhI9lJubi1GjRqFTp05QqVTYtWvXfx6Tk5OD8PBwuLm5oVu3btiwYYPyQZtJqxi6v//+e8ycORMLFy5EYWEhBg8ejFdeeQXl5eUNHldSUgKDwWC6BQUF2Sgx0UNN6e64ceNw4MAB6PV6lJSU4LvvvkNISIgNU1NrZ21vv/jiC7PX2oqKCnTo0AFjx461cXJqzaztbX5+PiZMmIDJkyejqKgI27Ztw/HjxzFlyhQbJ6fWztrurl+/HgsWLMDixYtRVFSEJUuWICkpCT/99JONk1Nrdvv2bfTp0wdr1qxp1P5lZWUYOXIkBg8ejMLCQnz00UeYMWMGduzYoXDSZiKtwIABA2TatGlmayEhITJ//vw698/OzhYA8tdff9kgHVH9rO3u3r17xcvLS65evWqLeER1sra3/5aZmSkqlUouXryoRDyiOlnb288++0y6detmtrZ69Wrx9/dXLCNRXaztrk6nk9mzZ5utJScnS2RkpGIZiRoCQDIzMxvcZ+7cuRISEmK29u6778rAgQMVTNZ8nvgr3Xfv3kVBQQGGDx9utj58+HAcPny4wWP79esHrVaL6OhoZGdnKxmTyEJTuvvjjz8iIiICy5YtQ+fOndGzZ0/Mnj0bd+7csUVkosd6zX1Er9dj2LBhCAgIUCIikYWm9HbQoEGorKzEnj17ICK4fPkytm/fjldffdUWkYkANK27tbW1cHNzM1vTaDQ4duwY7t27p1hWosdx5MgRi57HxMTgxIkTDtHbJ37ovnLlCh48eAA/Pz+zdT8/P1RVVdV5jFarRVpaGnbs2IGdO3ciODgY0dHRyM3NtUVkIgBN6+6FCxeQn5+PU6dOITMzE6tWrcL27duRlJRki8hETertPxkMBuzdu5dv0SWbakpvBw0ahIyMDMTHx8PFxQUdO3ZE+/bt8eWXX9oiMhGApnU3JiYGX3/9NQoKCiAiOHHiBNLT03Hv3j1cuXLFFrGJrFZVVVVnz+/fv+8QvW1j7wC2olKpzO6LiMXaI8HBwQgODjbd1+l0qKiowPLlyzFkyBBFcxL9mzXdNRqNUKlUyMjIgJeXFwBgxYoViIuLw9q1a6HRaBTPSwRY19t/2rhxI9q3b4/Ro0crlIyoftb0tri4GDNmzMCiRYsQExMDg8GAOXPmYNq0adDr9baIS2RiTXdTUlJQVVWFgQMHQkTg5+eHiRMnYtmyZVCr1baIS9QkdfW8rvWW6Im/0u3r6wu1Wm3x177q6mqLv5Y0ZODAgTh37lxzxyOqV1O6q9Vq0blzZ9PADQChoaEQEVRWViqalwh4vNdcEUF6ejoSEhLg4uKiZEwiM03p7aefforIyEjMmTMHzz33HGJiYrBu3Tqkp6fDYDDYIjZRk7qr0WiQnp6OmpoaXLx4EeXl5QgMDES7du3g6+tri9hEVuvYsWOdPW/Tpg18fHzslKrxnvih28XFBeHh4cjKyjJbz8rKwqBBgxr9OIWFhdBqtc0dj6heTeluZGQkLl26hFu3bpnWzp49CycnJ/j7+yualwh4vNfcnJwcnD9/HpMnT1YyIpGFpvS2pqYGTk7mv0Y9ukr46OoLkdIe5zXX2dkZ/v7+UKvV2Lp1K1577TWLThO1FDqdzqLn+/fvR0REBJydne2Uygr2+fw229q6das4OzuLXq+X4uJimTlzprRt29b0ybjz58+XhIQE0/4rV66UzMxMOXv2rJw6dUrmz58vAGTHjh32egrUSlnb3Zs3b4q/v7/ExcVJUVGR5OTkSFBQkEyZMsVeT4FaIWt7+8hbb70lL7zwgq3jEomI9b395ptvpE2bNrJu3TopLS2V/Px8iYiIkAEDBtjrKVArZW13S0pKZMuWLXL27Fn59ddfJT4+Xjp06CBlZWV2egbUGt28eVMKCwulsLBQAMiKFSuksLBQ/vjjDxGx7O2FCxfE3d1dPvjgAykuLha9Xi/Ozs6yfft2ez0Fq7SKoVtEZO3atRIQECAuLi7Sv39/ycnJMW1LTEyUqKgo0/3U1FTp3r27uLm5ibe3t7z44ouye/duO6Qmsq67IiKnT5+WYcOGiUajEX9/f5k1a5bU1NTYODW1dtb29vr166LRaCQtLc3GSYn+z9rerl69WsLCwkSj0YhWq5Xx48dLZWWljVMTWdfd4uJi6du3r2g0GvH09JTY2Fg5c+aMHVJTa/boK5r/fUtMTBSRul9zDx48KP369RMXFxcJDAyU9evX2z54E6lE+B4oIiIiIiIiIiXwP24QERERERERKYRDNxEREREREZFCOHQTERERERERKYRDNxEREREREZFCOHQTERERERERKYRDNxEREREREZFCOHQTERERERERKYRDNxEREREREZFCOHQTERE9wWpqavDGG2/A09MTKpUK169fR2BgIFatWtXgcSqVCrt27bJJRiIioidZG3sHICIiIuVs2rQJeXl5OHz4MHx9feHl5YXjx4+jbdu29o5GRETUKnDoJiIieoKVlpYiNDQUvXv3Nq099dRTdkxERETUuvDt5URERHZkNBqRmpqKHj16wNXVFV27dsXSpUsBAL///jtefvllaDQa+Pj44J133sGtW7dMx06cOBGjR4/G8uXLodVq4ePjg6SkJNy7dw8AMHToUHz++efIzc2FSqXC0KFDAcDi7eXnzp3DkCFD4ObmhrCwMGRlZVnk/PPPPxEfHw9vb2/4+PggNjYWFy9ebHQWAKitrcXcuXPRpUsXuLq6IigoCHq93rS9uLgYI0eOhIeHB/z8/JCQkIArV640x4+ZiIjIbjh0ExER2dGCBQuQmpqKlJQUFBcX49tvv4Wfnx9qamowYsQIeHt74/jx49i2bRt++eUXvPfee2bHZ2dno7S0FNnZ2di0aRM2btyIjRs3AgB27tyJqVOnQqfTwWAwYOfOnRbnNxqNGDNmDNRqNY4ePYoNGzZg3rx5ZvvU1NTgpZdegoeHB3Jzc5Gfnw8PDw+MGDECd+/ebVQWAJgwYQK2bt2K1atX4/Tp09iwYQM8PDwAAAaDAVFRUejbty9OnDiBn3/+GZcvX8a4ceOa6SdNRERkJ0JERER2cePGDXF1dZWvvvrKYltaWpp4e3vLrVu3TGu7d+8WJycnqaqqEhGRxMRECQgIkPv375v2GTt2rMTHx5vuJycnS1RUlNljBwQEyMqVK0VEZN++faJWq6WiosK0fe/evQJAMjMzRUREr9dLcHCwGI1G0z61tbWi0Whk3759jcpSUlIiACQrK6vOn0VKSooMHz7cbK2iokIASElJSZ3HEBEROQJe6SYiIrKT06dPo7a2FtHR0XVu69Onj9kHnkVGRsJoNKKkpMS01qtXL6jVatN9rVaL6upqqzJ07doV/v7+pjWdTme2T0FBAc6fP4927drBw8MDHh4e6NChA/7++2+UlpY2KsvJkyehVqsRFRVVZ46CggJkZ2ebHt/DwwMhISEAYHYOIiIiR8MPUiMiIrITjUZT7zYRgUqlqnPbP9ednZ0tthmNxkZnEJEGHx94+Bb08PBwZGRkWOz7zw9layhLQ8/10TlGjRqF1NRUi21arbbBY4mIiFoyXukmIiKyk6CgIGg0Ghw4cMBiW1hYGE6ePInbt2+b1g4dOgQnJyf07Nmz2TKEhYWhvLwcly5dMq0dOXLEbJ/+/fvj3LlzePrpp9GjRw+zm5eXV6PO8+yzz8JoNCInJ6fO7f3790dRURECAwMtzsGvNyMiIkfGoZuIiMhO3NzcMG/ePMydOxebN29GaWkpjh49Cr1ej/Hjx8PNzQ2JiYk4deoUsrOz8f777yMhIQF+fn7NlmHYsGEIDg7GhAkT8NtvvyEvLw8LFy4022f8+PHw9fVFbGws8vLyUFZWhpycHCQnJ6OysrJR5wkMDERiYiImTZqEXbt2oaysDAcPHsQPP/wAAEhKSsK1a9fw5ptv4tixY7hw4QL279+PSZMm4cGDB832fImIiGyNQzcREZEdpaSk4MMPP8SiRYsQGhqK+Ph4VFdXw93dHfv27cO1a9fw/PPPIy4uDtHR0VizZk2znt/JyQmZmZmora3FgAEDMGXKFNNXlj3i7u6O3NxcdO3aFWPGjEFoaCgmTZqEO3fuwNPTs9HnWr9+PeLi4jB9+nSEhIRg6tSppiv5nTp1wqFDh/DgwQPExMSgd+/eSE5OhpeXF5yc+OsKERE5LpXU9Z+5iIiIiIiIiOix8U/HRERERERERArh0E1ERERERESkEA7dRERERERERArh0E1ERERERESkEA7dRERERERERArh0E1ERERERESkEA7dRERERERERArh0E1ERERERESkEA7dRERERERERArh0E1ERERERESkEA7dRERERERERArh0E1ERERERESkkP8BKhxlvfzmLQMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_evaluation_pipeline(config, model = deep_model, model_type = 'deep_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running prediction on evaluation videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 80/80 [19:11<00:00, 14.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to output/evaluations\\vit_model\\predictions.csv\n",
      "Summary: 80 videos processed\n",
      "Real: 2 (2.5%)\n",
      "Fake: 78 (97.5%)\n",
      "Generating result visualizations...\n",
      "Evaluation pipeline complete.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_evaluation_pipeline(config, model = vit_model, model_type = 'vit_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running prediction on evaluation videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 80/80 [18:53<00:00, 14.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to output/evaluations\\fine_tuned_vit_model\\predictions.csv\n",
      "Summary: 80 videos processed\n",
      "Real: 59 (73.8%)\n",
      "Fake: 21 (26.2%)\n",
      "Generating result visualizations...\n",
      "Evaluation pipeline complete.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_evaluation_pipeline(config, model = fine_tuned_vit_model, model_type = 'fine_tuned_vit_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "\n",
    "model = vit_model\n",
    "model.load_state_dict(torch.load('output/models/vit/best_model.pt', map_location='cpu'))\n",
    "model.eval()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "features_dir = os.path.join(config['output_dir'], 'features')\n",
    "real_data = np.load(os.path.join(features_dir, '1_features.npz'))\n",
    "fake_data = np.load(os.path.join(features_dir, '0_features.npz'))\n",
    "\n",
    "real_features = real_data['features']\n",
    "fake_features = fake_data['features']\n",
    "\n",
    "X = np.vstack((real_features, fake_features))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "\n",
    "def gradio_predict(video_file):\n",
    "    try:\n",
    "        features = process_video(\n",
    "            video_file,\n",
    "            sample_rate=config['sample_rate'],\n",
    "            max_frames=config['max_frames'],\n",
    "            resize_shape=(config['resize_width'], config['resize_height'])\n",
    "        )\n",
    "        if features is None:\n",
    "            return \"Error extracting features\", 0.0\n",
    "\n",
    "        feature_values = np.array(list(features.values())).reshape(1, -1)\n",
    "        feature_values = scaler.transform(feature_values)\n",
    "\n",
    "        feature_tensor = torch.tensor(feature_values, dtype=torch.float32).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(feature_tensor)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            pred_label = torch.argmax(probs, dim=1).item()\n",
    "            confidence = probs[0, pred_label].item()\n",
    "\n",
    "        pred_class = 'Real' if pred_label == 1 else 'Fake'\n",
    "        return f\"Prediction: {pred_class}\", float(f\"{confidence:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\", 0.0\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=gradio_predict,\n",
    "    inputs=gr.Video(label=\"Upload a video\"),\n",
    "    outputs=[gr.Textbox(label=\"Prediction\"), gr.Number(label=\"Confidence\")],\n",
    "    title=\"Deepfake Video Detector\",\n",
    "    description=\"Upload a short video to check if it's Real or Fake.\"\n",
    ")\n",
    "\n",
    "interface.launch(share=False, debug=False, prevent_thread_lock=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
